{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 14:44:45.675711: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/openmpi/lib\n",
      "2022-04-30 14:44:45.675745: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import data_processing as dp\n",
    "import betaVAE_shapes3d as betaVAE\n",
    "import get_latents_given_factor as gdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = 330\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(sd)\n",
    "rn.seed(sd)\n",
    "np.random.seed(sd)\n",
    "tf.random.set_seed(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow_datasets as tfds\n",
    "#ds = tfds.load(\n",
    "#        'shapes3d',\n",
    "#        split='train',\n",
    "#        data_dir='/share/data1/dpiras',\n",
    "#        download=True,\n",
    "#        with_info=True,\n",
    "#        as_supervised=False,\n",
    "#        shuffle_files=False\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {'floor_hue': 10,\n",
    "         'object_hue': 10,\n",
    "         'orientation': 15,\n",
    "         'scale': 8,\n",
    "         'shape': 4,\n",
    "         'wall_hue': 10}\n",
    "\n",
    "def preprocess(features):\n",
    "    image = tf.image.convert_image_dtype(features['image'], tf.float32)\n",
    "    return image\n",
    "\n",
    "def extract_labels(features):\n",
    "    labels_value = []#np.empty(6)\n",
    "    for i, factor in enumerate(dict_labels.keys()):\n",
    "        label = 'label_' + factor\n",
    "        label_value = features[label]\n",
    "        labels_value.append(label_value)\n",
    "    return labels_value\n",
    "    \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "data_dir = '/share/data1/dpiras'\n",
    "train_ds, val_ds, test_ds, metadata = dp.DataPreparation(data_dir=data_dir).train_val_test_split('shapes3d', data_dir=data_dir, split_at=[80, 90])\n",
    "subds = train_ds.take(1).map(preprocess, num_parallel_calls=AUTOTUNE).batch(1) # if this throws error, copy preprocess() from dp file and directly define it in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = 2\n",
      "using seed 330, latent_dim = 6\n",
      "encoder summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 32)        1568      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        16416     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 64)          32832     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 64)          65600     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                3084      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 185,292\n",
      "Trainable params: 185,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "decoder summary\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 256)               1792      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 8, 8, 64)         65600     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 32)       32800     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 32)       16416     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 3)        1539      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 381,315\n",
      "Trainable params: 381,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "loading weights from:  weights-training-ep60-beta=2-zdim=6-final.h5\n",
      "mse shape  Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "kl_loss shape  Tensor(\"Shape_1:0\", shape=(2,), dtype=int32)\n",
      "1/1 [==============================] - 1s 976ms/step - total_loss: 1688.6835 - reconstruction_loss: 1688.6488 - kl_loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 6\n",
    "beta =  2\n",
    "num_trials = 1000\n",
    "epoch = 60\n",
    "\n",
    "print(f'beta = {beta}')\n",
    "tf.keras.backend.clear_session()\n",
    "model = betaVAE.betaVAE(latent_dim, beta, batch_size=1000)\n",
    "\n",
    "weights_filename = f'weights-training-ep{epoch}-beta={beta}-zdim={latent_dim}-final.h5'\n",
    "print('loading weights from: ', weights_filename)\n",
    "    \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model.evaluate(subds)\n",
    "model.load_weights(weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_set = test_ds.take(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numpy = np.array(list(all_test_set.map(preprocess, num_parallel_calls=AUTOTUNE).as_numpy_iterator()))\n",
    "latent_means_and_stds = model.encode(test_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_test_set.map(extract_labels)\n",
    "\n",
    "all_labels = np.array(list(all_test_set.map(extract_labels, num_parallel_calls=AUTOTUNE).as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  3, 13,  1,  0,  0],\n",
       "       [ 4,  1, 10,  7,  2,  2],\n",
       "       [ 9,  0,  3,  5,  3,  9],\n",
       "       ...,\n",
       "       [ 5,  6,  0,  6,  0,  6],\n",
       "       [ 6,  9, 12,  1,  1,  5],\n",
       "       [ 5,  6,  2,  1,  2,  8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_means_and_stds[0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.3845493 , -1.7926698 ,  0.69978315, -0.10331669,  1.644395  ,\n",
       "         -0.7225574 ],\n",
       "        [-0.5640063 ,  1.1521658 ,  1.0989418 ,  0.828569  , -1.0567416 ,\n",
       "         -1.8896945 ],\n",
       "        [ 0.72350097, -1.4067838 , -0.36762276, -0.7434684 , -0.7545973 ,\n",
       "         -0.38959956],\n",
       "        ...,\n",
       "        [ 1.7845685 , -0.48801848,  0.6806236 ,  1.7137874 ,  0.39083007,\n",
       "          0.40228546],\n",
       "        [-1.0427899 ,  0.7490751 ,  0.4263998 , -0.43666318, -0.40123376,\n",
       "          0.6686886 ],\n",
       "        [ 1.0277547 , -0.25283536,  0.6889079 , -0.77352566,  0.39805293,\n",
       "         -0.13918954]], dtype=float32),\n",
       " array([[0.18503612, 0.33128443, 0.04612737, 0.13190652, 0.21126184,\n",
       "         0.05307809],\n",
       "        [0.08741339, 0.16218977, 0.07452913, 0.14912441, 0.08058663,\n",
       "         0.191702  ],\n",
       "        [0.10864212, 0.07380977, 0.04403514, 0.38181266, 0.04908057,\n",
       "         0.04745859],\n",
       "        ...,\n",
       "        [0.3345761 , 0.5701178 , 0.04483068, 0.28624254, 0.04458302,\n",
       "         0.04435949],\n",
       "        [0.15361355, 0.146699  , 0.04058016, 0.14632899, 0.05428102,\n",
       "         0.04886134],\n",
       "        [0.15063435, 0.13553056, 0.04390976, 0.16704422, 0.05658799,\n",
       "         0.0405275 ]], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = latent_means_and_stds[0].numpy()\n",
    "stds = np.exp(latent_means_and_stds[1].numpy()/2)\n",
    "\n",
    "#for latent in range(6):\n",
    "#    samples = np.random.default_rng(42).normal(lmean[:, latent_number], lstd[:, latent_number], len(lmean[:, latent_number]))\n",
    "z_samples = np.random.default_rng(42).normal(means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5,  3, 13,  1,  0,  0],\n",
       "        [ 4,  1, 10,  7,  2,  2],\n",
       "        [ 9,  0,  3,  5,  3,  9],\n",
       "        ...,\n",
       "        [ 5,  6,  0,  6,  0,  6],\n",
       "        [ 6,  9, 12,  1,  1,  5],\n",
       "        [ 5,  6,  2,  1,  2,  8]]),\n",
       " array([[-1.32816559, -2.13720032,  0.73439949,  0.02074994,  1.23221571,\n",
       "         -0.79167463],\n",
       "        [-0.55283137,  1.10087446,  1.09768963,  0.70135932, -0.98587388,\n",
       "         -1.74059019],\n",
       "        [ 0.73067468, -1.3235824 , -0.34703592, -1.07155715, -0.73649881,\n",
       "         -0.43510677],\n",
       "        ...,\n",
       "        [ 1.68768887, -0.74081057,  0.73721287,  2.19284867,  0.4083426 ,\n",
       "          0.46045534],\n",
       "        [-1.01627759,  0.82975403,  0.42322734, -0.66943965, -0.33584805,\n",
       "          0.68945725],\n",
       "        [ 1.02182295, -0.04000615,  0.74913957, -0.73955026,  0.32550202,\n",
       "         -0.1896403 ]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels, z_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./labels.npy', all_labels)\n",
    "np.save('./latents.npy', z_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignored\n",
    "# Get list of means and stds for every factor, as well as sampled latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns dicts where the key is the factor that is systematically varied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually I'm not sure if here I'm only using 1000 samples in total... if this is the case you might want to add an extra loop in gdist.get_samples() so you enumerate through the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_means = dict()\n",
    "dict_logvars = dict() # this is the natural log of the variance\n",
    "dict_samples = dict()\n",
    "\n",
    "for factor in gdist.shapes3d_factors_dict().keys():\n",
    "    print(f'factor = {factor}')\n",
    "    means_ls, logvar_ls, latent_samples_arr = gdist.get_samples(factor, model, test_ds, latent_dim, repeats_per_image_batch=10)\n",
    "    # above should be returning a list for mean and a list for logvariance, where each element are sampled latents when factor value is fixed to i=1, 2, ...\n",
    "    # plus an array where one dimension is the number of samples, and the other dimension is the number of latents\n",
    "    dict_means[factor] = means_ls\n",
    "    logvar_ls[factor] = logvar_ls\n",
    "    dict_samples[factor]  = latent_samples_arr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
