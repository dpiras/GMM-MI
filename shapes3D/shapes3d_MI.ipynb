{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3143428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "from scipy import linalg\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import gamma\n",
    "import time\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.mixture._gaussian_mixture import _estimate_log_gaussian_prob, _compute_precision_cholesky, _estimate_gaussian_covariances_full\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cb9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GMM(GMM):\n",
    "    \"\"\"\n",
    "    Custom GMM class based on the sklearn GMM class.\n",
    "    This allows to work with a GMM with fixed parameters, without fitting it.\n",
    "    It also allows to estimate MI with a certain number of MC samples.\n",
    "    The different initialisation types are dealt with separately.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_components=1,\n",
    "                 covariance_type=\"full\",\n",
    "                 tol=1e-5,\n",
    "                 reg_covar=1e-6,\n",
    "                 max_iter=100,\n",
    "                 n_init=1,\n",
    "                 init_params=\"random\",\n",
    "                 random_state=None,\n",
    "                 warm_start=False,\n",
    "                 verbose=0,\n",
    "                 verbose_interval=10,\n",
    "                 weights_init=None,\n",
    "                 means_init=None,\n",
    "                 precisions_init=None,\n",
    "                 covariances_init=None\n",
    "                 ):\n",
    "        super(my_GMM, self).__init__(n_components=n_components,\n",
    "                 covariance_type=covariance_type,\n",
    "                 tol=tol,\n",
    "                 reg_covar=reg_covar,\n",
    "                 max_iter=max_iter,\n",
    "                 n_init=n_init,\n",
    "                 init_params=init_params,\n",
    "                 random_state=random_state,\n",
    "                 warm_start=warm_start,\n",
    "                 verbose=verbose,\n",
    "                 verbose_interval=verbose_interval,\n",
    "                 weights_init=weights_init,\n",
    "                 means_init=means_init,\n",
    "                 precisions_init=precisions_init,\n",
    "                )\n",
    "\n",
    "        self.means_ = means_init\n",
    "        self.covariances_ = covariances_init\n",
    "        self.covariances_init = covariances_init\n",
    "        self.weights_ = weights_init\n",
    "        #self.random_state = random_state\n",
    "        #self.covariance_type = covariance_type\n",
    "        #self.precisions_cholesky_ = _compute_precision_cholesky(\n",
    "        #        self.covariances_, self.covariance_type\n",
    "        #    )\n",
    "\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        \"\"\"Compute the log-likelihood of each sample.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : array, shape (n_samples,)\n",
    "            Log-likelihood of each sample in `X` under the current model.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self)\n",
    "        #X = self._validate_data(X, reset=False)\n",
    "\n",
    "        return logsumexp(self._estimate_weighted_log_prob(X), axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for the data samples in X using trained model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : array, shape (n_samples,)\n",
    "            Component labels.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self)\n",
    "        #X = self._validate_data(X, reset=False)\n",
    "        return self._estimate_weighted_log_prob(X).argmax(axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Evaluate the components' density for each sample.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        Returns\n",
    "        -------\n",
    "        resp : array, shape (n_samples, n_components)\n",
    "            Density of each Gaussian component for each sample in X.\n",
    "        \"\"\"\n",
    "        # copied here to remove the fitting check\n",
    "        #check_is_fitted(self)\n",
    "        #X = self._validate_data(X, reset=False)\n",
    "        _, log_resp = self._estimate_log_prob_resp(X)\n",
    "        return np.exp(log_resp)\n",
    "\n",
    "    def sample(self, n_samples=1):\n",
    "        \"\"\"Generate random samples from the fitted Gaussian distribution.\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int, default=1\n",
    "            Number of samples to generate.\n",
    "        Returns\n",
    "        -------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Randomly generated sample.\n",
    "        y : array, shape (nsamples,)\n",
    "            Component labels.\n",
    "        \"\"\"\n",
    "        # copied here to remove the fitting check\n",
    "        # check_is_fitted(self)\n",
    "\n",
    "        if n_samples < 1:\n",
    "            raise ValueError(\n",
    "                \"Invalid value for 'n_samples': %d . The sampling requires at \"\n",
    "                \"least one sample.\" % (self.n_components)\n",
    "            )\n",
    "\n",
    "        _, n_features = self.means_.shape\n",
    "        rng = check_random_state(self.random_state)\n",
    "        n_samples_comp = rng.multinomial(n_samples, self.weights_)\n",
    "\n",
    "        if self.covariance_type == \"full\":\n",
    "            X = np.vstack(\n",
    "                [\n",
    "                    rng.multivariate_normal(mean, covariance, int(sample))\n",
    "                    for (mean, covariance, sample) in zip(\n",
    "                        self.means_, self.covariances_, n_samples_comp\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        elif self.covariance_type == \"tied\":\n",
    "            X = np.vstack(\n",
    "                [\n",
    "                    rng.multivariate_normal(mean, self.covariances_, int(sample))\n",
    "                    for (mean, sample) in zip(self.means_, n_samples_comp)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            X = np.vstack(\n",
    "                [\n",
    "                    mean + rng.randn(sample, n_features) * np.sqrt(covariance)\n",
    "                    for (mean, covariance, sample) in zip(\n",
    "                        self.means_, self.covariances_, n_samples_comp\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        y = np.concatenate(\n",
    "            [np.full(sample, j, dtype=int) for j, sample in enumerate(n_samples_comp)]\n",
    "        )\n",
    "\n",
    "        return (X, y)\n",
    "\n",
    "    def score_samples_marginal(self, X, index=0):\n",
    "        \"\"\"Compute the log-likelihood of each sample for the marginal model, indexed by either 0 (x) or 1 (y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        index: integer\n",
    "            Either 0 (marginal x) or 1 (marginal y).\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : array, shape (n_samples,)\n",
    "            Log-likelihood of each sample in `X` under the current model.\n",
    "        \"\"\"\n",
    "\n",
    "        oned_cholesky = np.sqrt(1/self.covariances_[:, index, index]).reshape(-1, 1, 1)\n",
    "        marginal_logprob = _estimate_log_gaussian_prob(\n",
    "            X, self.means_[:, index].reshape(-1, 1), oned_cholesky, self.covariance_type\n",
    "        )\n",
    "\n",
    "        return logsumexp(np.log(self.weights_) + marginal_logprob, axis=1)\n",
    "\n",
    "\n",
    "    def estimate_MI_MC(self, MC_samples=100):\n",
    "        \"\"\"\n",
    "        Compute the mutual information (MI) associated with a particular GMM model, using MC integration\n",
    "        Parameters\n",
    "        ----------\n",
    "        MC_samples : integer\n",
    "            Number of Monte Carlo samples to perform numerical integration of the MI integral.\n",
    "        Returns\n",
    "        ----------\n",
    "        MI : integer\n",
    "            The value of mutual information.\n",
    "        -------\n",
    "        \"\"\"\n",
    "        # sample MC samples\n",
    "        points, clusters = self.sample(MC_samples)\n",
    "        \n",
    "        # we first evaluate the log-likelihood for the joint probability\n",
    "        joint = self.score_samples(points)\n",
    "\n",
    "        # we then evaluate the marginals; index=0 corresponds to x, index=y corresponds to y\n",
    "        marginal_x = self.score_samples_marginal(points[:, :1], index=0)\n",
    "        marginal_y = self.score_samples_marginal(points[:, 1:], index=1)\n",
    "\n",
    "        MI = np.mean(joint - marginal_x - marginal_y)\n",
    "        return MI\n",
    "    \n",
    "    def fit_predict(self, X, y=None):\n",
    "        \"\"\"Estimate model parameters using X and predict the labels for X.\n",
    "        The method fits the model n_init times and sets the parameters with\n",
    "        which the model has the largest likelihood or lower bound. Within each\n",
    "        trial, the method iterates between E-step and M-step for `max_iter`\n",
    "        times until the change of likelihood or lower bound is less than\n",
    "        `tol`, otherwise, a :class:`~sklearn.exceptions.ConvergenceWarning` is\n",
    "        raised. After fitting, it predicts the most probable label for the\n",
    "        input data points.\n",
    "        .. versionadded:: 0.20\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        y : Ignored\n",
    "            Not used, present for API consistency by convention.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : array, shape (n_samples,)\n",
    "            Component labels.\n",
    "        \"\"\"\n",
    "        X = self._validate_data(X, dtype=[np.float64, np.float32], ensure_min_samples=2)\n",
    "        if X.shape[0] < self.n_components:\n",
    "            raise ValueError(\n",
    "                \"Expected n_samples >= n_components \"\n",
    "                f\"but got n_components = {self.n_components}, \"\n",
    "                f\"n_samples = {X.shape[0]}\"\n",
    "            )\n",
    "        self._check_initial_parameters(X)\n",
    "\n",
    "        # if we enable warm_start, we will have a unique initialisation\n",
    "        do_init = not (self.warm_start and hasattr(self, \"converged_\"))\n",
    "        n_init = self.n_init if do_init else 1\n",
    "\n",
    "        max_lower_bound = -np.inf\n",
    "        self.converged_ = False\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "        n_samples, _ = X.shape\n",
    "        for init in range(n_init):\n",
    "            self._print_verbose_msg_init_beg(init)\n",
    "\n",
    "            if do_init:\n",
    "                self._initialize_parameters(X, random_state)\n",
    "\n",
    "            lower_bound = -np.inf if do_init else self.lower_bound_\n",
    "\n",
    "            for n_iter in range(1, self.max_iter + 1):\n",
    "                #if n_iter==179:\n",
    "                #    try:\n",
    "                #        #print(n_iter)\n",
    "                #        print(np.linalg.eig(self.covariances_[2]))\n",
    "                #        #print(self.means_[2])\n",
    "                #        #ind = np.argsort(log_resp[:, 2])[-5:]\n",
    "                #        #print(X[ind])\n",
    "                #        #print(log_resp[np.argmax(log_resp[:, 2])])\n",
    "                #        #plt.hist(log_resp[:, 4])\n",
    "                #    except:\n",
    "                #        pass\n",
    "\n",
    "                prev_lower_bound = lower_bound\n",
    "\n",
    "                log_prob_norm, log_resp = self._e_step(X)\n",
    "                self._m_step(X, log_resp)\n",
    "                lower_bound = self._compute_lower_bound(log_resp, log_prob_norm)\n",
    "\n",
    "                change = lower_bound - prev_lower_bound\n",
    "                self._print_verbose_msg_iter_end(n_iter, change)\n",
    "\n",
    "                if abs(change) < self.tol:\n",
    "                    self.converged_ = True\n",
    "                    break\n",
    "\n",
    "            self._print_verbose_msg_init_end(lower_bound)\n",
    "\n",
    "            if lower_bound > max_lower_bound or max_lower_bound == -np.inf:\n",
    "                max_lower_bound = lower_bound\n",
    "                best_params = self._get_parameters()\n",
    "                best_n_iter = n_iter\n",
    "\n",
    "        if not self.converged_:\n",
    "            warnings.warn(\n",
    "                \"Initialization %d did not converge. \"\n",
    "                \"Try different init parameters, \"\n",
    "                \"or increase max_iter, tol \"\n",
    "                \"or check for degenerate data.\" % (init + 1),\n",
    "                ConvergenceWarning,\n",
    "            )\n",
    "\n",
    "        self._set_parameters(best_params)\n",
    "        self.n_iter_ = best_n_iter\n",
    "        self.lower_bound_ = max_lower_bound\n",
    "\n",
    "        # Always do a final e-step to guarantee that the labels returned by\n",
    "        # fit_predict(X) are always consistent with fit(X).predict(X)\n",
    "        # for any value of max_iter and tol (and any random_state).\n",
    "        _, log_resp = self._e_step(X)\n",
    "\n",
    "        return log_resp.argmax(axis=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3dfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we also focus on initialising the GMM parameters\n",
    "# we provide four different initialisation types, which return weights, means and covs\n",
    "# these will go as input into the GMM class, so that we can ignore whatever happens there\n",
    "\n",
    "  \n",
    "def initialize_parameters(X, random_state, n_components=1, s=None, reg_covar=1e-6, init_type='random'):\n",
    "    \"\"\"Initialize the model parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape  (n_samples, n_features)\n",
    "    random_state : RandomState\n",
    "        A random number generator instance that controls the random seed used for the method chosen to initialize the parameters.\n",
    "    n_components: int\n",
    "        Number of components of the GMM to fit.\n",
    "    s : float\n",
    "        If set, sets component variances in the 'random' and 'minmax' cases. \n",
    "        If s is not given, it will be set such that the volume of all components\n",
    "        completely fills the space covered by data.\n",
    "    init_type : {'random', 'minmax', 'kmeans', 'random_sklearn', 'kmeans_sklearn'}, default='random'\n",
    "        The method used to initialize the weights, the means and the\n",
    "        precisions.\n",
    "        Must be one of:\n",
    "            'random': weights are set uniformly, covariances are proprtional to identity (with prefactor s^2). \n",
    "            For each mean, a data sample is selected at random, and a multivariant Gaussian with variance s^2 offset is added.\n",
    "            'minmax': same as above, but means are distributed randomly over the range that is covered by data.\n",
    "            'kmeans': k-means clustering run as in Algorithm 1 from Bloemer & Bujna (arXiv:1312.5946), as implemented by Melchior & Goulding (arXiv:1611.05806)\n",
    "             WARNING: The result of this call are not deterministic even if rng is set because scipy.cluster.vq.kmeans2 uses its own initialization. \n",
    "             TO DO: require scipy > 1.7, and include \"seed=random_state\" in the kmeans call\n",
    "            'kmeans_sklearn' : responsibilities are initialized using kmeans.\n",
    "            'random_sklearn' : responsibilities are initialized randomly.\n",
    "    reg_covar : float\n",
    "        The regularization added to the diagonal of the covariance matrices.\n",
    "    Returns\n",
    "    ----------\n",
    "    weights : array, shape (n_components, 1)\n",
    "        The initial weights of the GMM model.\n",
    "    means : array, shape (n_components, n_features)\n",
    "        The initial means of the GMM model.        \n",
    "    covariances : array, shape (n_components, n_features, n_features)\n",
    "        The initial covariance matrices of the GMM model.        \n",
    "    \"\"\"\n",
    "    n_samples, n_dim = X.shape\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "    if s is None and (init_type=='random' or init_type=='minmax'):\n",
    "        min_pos = X.min(axis=0)\n",
    "        max_pos = X.max(axis=0)\n",
    "        vol_data = np.prod(max_pos-min_pos)\n",
    "        s = (vol_data / n_components * gamma(n_dim*0.5 + 1))**(1/n_dim) / np.sqrt(np.pi)\n",
    "        print(f\"Scale s set to s={s:.2f}...\")\n",
    "\n",
    "    if init_type == \"random\":\n",
    "\n",
    "        weights = np.repeat(1/n_components, n_components)\n",
    "        # initialize components around data points with uncertainty s\n",
    "        refs = random_state.randint(0, n_samples, size=n_components)\n",
    "\n",
    "        means = X[refs] + random_state.multivariate_normal(np.zeros(n_dim), s**2 * np.eye(n_dim), size=n_components)\n",
    "        \n",
    "        covariances = np.repeat(s**2 * np.eye(n_dim)[np.newaxis, :, :], n_components, axis=0)\n",
    "\n",
    "    elif init_type == \"minmax\":\n",
    "\n",
    "        weights = np.repeat(1/n_components, n_components)\n",
    "\n",
    "        min_pos = X.min(axis=0)\n",
    "        max_pos = X.max(axis=0)\n",
    "        means = min_pos + (max_pos-min_pos)*random_state.rand(n_components, n_dim)\n",
    "        \n",
    "        covariances = np.repeat(s**2 * np.eye(n_dim)[np.newaxis, :, :], n_components, axis=0)\n",
    "\n",
    "    elif init_type == 'kmeans':\n",
    "        from scipy.cluster.vq import kmeans2\n",
    "        center, label = kmeans2(X, n_components)\n",
    "        weights = np.zeros(n_components)\n",
    "        means = np.zeros((n_components, n_dim))\n",
    "        covariances = np.zeros((n_components, n_dim, n_dim))\n",
    "\n",
    "        for k in range(n_components):\n",
    "            mask = (label == k)\n",
    "            weights[k] = mask.sum() / len(X)\n",
    "            means[k,:] = X[mask].mean(axis=0)\n",
    "            d_m = X[mask] - means[k,:] \n",
    "            # funny way of saying: for each point i, do the outer product\n",
    "            # of d_m with its transpose and sum over i\n",
    "            covariances[k,:,:] = (d_m[:, :, None] * d_m[:, None, :]).sum(axis=0) / len(X)\n",
    "\n",
    "    elif init_type == \"random_sklearn\":\n",
    "        resp = random_state.rand(n_samples, n_components)\n",
    "        resp /= resp.sum(axis=1)[:, np.newaxis]\n",
    "        nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "        \n",
    "        weights = nk/n_samples\n",
    "        means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "        covariances = _estimate_gaussian_covariances_full(resp, X, nk, means, reg_covar)\n",
    "\n",
    "    elif init_type == \"kmeans_sklearn\":\n",
    "        resp = np.zeros((n_samples, n_components))\n",
    "        label = (\n",
    "            cluster.KMeans(\n",
    "                n_clusters=n_components, n_init=1, random_state=random_state\n",
    "            )\n",
    "            .fit(X)\n",
    "            .labels_\n",
    "        )\n",
    "        resp[np.arange(n_samples), label] = 1\n",
    "        nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "        \n",
    "        weights = nk/n_samples\n",
    "        means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "        covariances = _estimate_gaussian_covariances_full(resp, X, nk, means, reg_covar)\n",
    "\n",
    "    else:\n",
    "        # TO DO: raise error instead of just priting it\n",
    "        print(\"Error: initalisation type not specified or not known; it should be one of 'random', 'minmax', 'kmeans', 'random_sklearn', 'kmeans_sklearn'\")\n",
    "        \n",
    "    precisions = np.empty_like(covariances)\n",
    "    for i in range(n_components):\n",
    "        precisions[i] = np.linalg.inv(covariances[i])\n",
    "        \n",
    "    return weights, means, covariances, precisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd4edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI_procedure_diffconvergence(X, n_components=1, n_folds=5, n_inits=5, init_type='random', reg_covar=1e-6, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Docstring TO DO\n",
    "    \"\"\"\n",
    "    initial_time = time.time()\n",
    "    # this will be used to store mean validation log-likelihood \n",
    "    val_scores_seeds = np.zeros(n_inits)\n",
    "    train_scores_seeds = np.zeros(n_inits)\n",
    "\n",
    "    # prepare the folds; note the splitting will be the same for all initialisations\n",
    "    # the random seed is fixed here, but results should be independent of the exact split\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # fix the random seed first\n",
    "    for r in range(n_inits):\n",
    "\n",
    "        w_init, m_init, c_init, p_init = initialize_parameters(X, r, n_components=n_components, init_type=init_type)\n",
    "        validation_scores = []\n",
    "        training_scores = []\n",
    "        \n",
    "        for train_indices, valid_indices in kf.split(X):\n",
    "            X_training = X[train_indices]\n",
    "            X_validation = X[valid_indices]\n",
    "            \n",
    "            fitted_gmm = my_GMM(n_components=n_components, reg_covar=reg_covar, \n",
    "                            tol=tol, max_iter=10000, \n",
    "                            random_state=r, weights_init=w_init, \n",
    "                            means_init=m_init, precisions_init=p_init).fit(X_training)\n",
    "\n",
    "            # we take the mean logL per sample, since folds might have slightly different sizes\n",
    "            val_score = fitted_gmm.score_samples(X_validation).mean()\n",
    "            train_score = fitted_gmm.score_samples(X_training).mean()\n",
    "\n",
    "            #print(val_score)\n",
    "            validation_scores.append(np.copy(val_score))\n",
    "            training_scores.append(np.copy(train_score))\n",
    "\n",
    "\n",
    "        # take mean of current seed's val scores\n",
    "        val_scores_seeds[r] = np.mean(validation_scores)\n",
    "        train_scores_seeds[r] = np.mean(training_scores)\n",
    "\n",
    "        #print()\n",
    "        \n",
    "    # select seed with highest val score\n",
    "    best_seed = np.argmax(val_scores_seeds)\n",
    "    best_val_score = np.max(val_scores_seeds)\n",
    "    best_train_score = np.max(train_scores_seeds)\n",
    "    \n",
    "    return best_seed, best_val_score, best_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466d301",
   "metadata": {},
   "source": [
    "### Let's look at MI between first latent and first factor of variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "85bd287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = np.load('./labels.npy')\n",
    "all_latents = np.load('./latents.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0552834",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {'floor_hue': [10, 0],\n",
    "         'object_hue': [10, 1],\n",
    "         'orientation': [15, 2],\n",
    "         'scale': [8,3],\n",
    "         'shape': [4, 4],\n",
    "         'wall_hue': [10, 5]}\n",
    "\n",
    "latent_id = 3\n",
    "label_id = 'scale'\n",
    "label_values = dict_labels[label_id][0]\n",
    "label_number = dict_labels[label_id][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "74ab0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inits = 5\n",
    "n_folds = 3\n",
    "init_type = 'random_sklearn'\n",
    "n_bootstrap = 100\n",
    "MC_samples = 1e5\n",
    "tol = 1e-5\n",
    "reg_covar = 1e-15\n",
    "components_range = 15\n",
    "patience = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adc4ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -0.9225725943635975\n",
      "2 -0.872994249281602\n",
      "3 -0.8321391906262585\n",
      "4 -0.8311610133708109\n",
      "Convergence reached at 4 components\n",
      "1 -0.8083382910562578\n",
      "2 -0.7885373212853821\n",
      "3 -0.7882585784567695\n",
      "4 -0.7614027289823787\n",
      "Convergence reached at 4 components\n",
      "1 -0.8326579785064778\n",
      "2 -0.7620893425803016\n",
      "Convergence reached at 2 components\n",
      "1 -0.9233398813296141\n",
      "2 -0.8265421218357178\n",
      "Convergence reached at 2 components\n",
      "1 -1.0214874337539877\n",
      "2 -0.9080152775853855\n",
      "3 -0.8772289751526117\n",
      "4 -0.8723631583496928\n",
      "5 -0.8623213742366582\n",
      "Convergence reached at 5 components\n",
      "1 -1.1582618172226533\n",
      "2 -1.0604359380570296\n",
      "3 -0.9613187116535062\n",
      "Convergence reached at 3 components\n",
      "1 -1.2758897339915867\n",
      "2 -1.1467730469207205\n",
      "3 -1.0940507376391382\n",
      "Convergence reached at 3 components\n",
      "1 -1.3914381284494821\n",
      "2 -1.3255693795169412\n",
      "3 -1.297369495848088\n",
      "Convergence reached at 3 components\n"
     ]
    }
   ],
   "source": [
    "# first identify all initialisations for all needed models (1x10 in this case)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "first_labels = all_labels[:, label_number]\n",
    "first_latents = all_latents[:, latent_id]\n",
    "\n",
    "init_params_ = []\n",
    "for label_value in range(label_values):\n",
    "    # select latents corresponding to those labels\n",
    "    current_ids = np.where(first_labels == label_value)\n",
    "    current_latents = first_latents[current_ids]\n",
    "    # we need to fit the current latents; this is p(z1|f1 = label_value)\n",
    "    best_val = -np.inf\n",
    "    pat_counter = 0\n",
    "    X = np.reshape(current_latents, (-1, 1))\n",
    "    for n_components in range(1, components_range+1):\n",
    "        current_seed, current_val, _ = MI_procedure_diffconvergence(X, n_components=n_components, n_folds=n_folds, \n",
    "                                                           init_type=init_type, n_inits=n_inits, tol=tol, reg_covar=reg_covar)\n",
    "\n",
    "        # check if convergence has been reached based on val score\n",
    "        if current_val > best_val:\n",
    "            best_val = current_val\n",
    "            best_seed = current_seed\n",
    "            best_components = n_components\n",
    "            print(n_components, best_val)\n",
    "        else:\n",
    "            pat_counter += 1\n",
    "            if pat_counter >= patience:\n",
    "                \n",
    "                print(f'Convergence reached at {best_components} components') \n",
    "                w_init, m_init, c_init, p_init = initialize_parameters(X, best_seed, n_components=best_components, init_type=init_type)\n",
    "                init_params_.append({'w': w_init, 'm': m_init, 'c': c_init, 'p': p_init, 'bc': best_components, 'seed': best_seed})\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76a017bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then bootstrap and calculate MI\n",
    "\n",
    "n_bootstrap = 100\n",
    "MC_samples = 1e5\n",
    "MI_estimates = np.zeros(n_bootstrap)\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    # we use i to change the seed so that the results will be fully reproducible\n",
    "    rng = np.random.default_rng(i)\n",
    "\n",
    "    all_gmms = []\n",
    "    for label_value in range(label_values):\n",
    "        # select latents corresponding to those labels\n",
    "        current_ids = np.where(first_labels == label_value)\n",
    "        current_latents = first_latents[current_ids]\n",
    "        X = np.reshape(current_latents, (-1, 1))\n",
    "\n",
    "        n_components = init_params_[label_value]['bc']\n",
    "        w_init = init_params_[label_value]['w']\n",
    "        m_init = init_params_[label_value]['m']\n",
    "        p_init = init_params_[label_value]['p']\n",
    "        seed = init_params_[label_value]['seed']\n",
    "\n",
    "        X_bs = rng.choice(X, X.shape[0])\n",
    "        gmm = my_GMM(n_components=n_components, reg_covar=reg_covar, \n",
    "                    tol=tol, max_iter=10000, \n",
    "                    random_state=seed, weights_init=w_init, \n",
    "                    means_init=m_init, precisions_init=p_init).fit(X_bs)\n",
    "        \n",
    "        all_gmms.append(gmm)\n",
    "        \n",
    "    # estimate MI using MC\n",
    "    MI = 0 \n",
    "    for label_value in range(label_values):\n",
    "        samples = all_gmms[label_value].sample(MC_samples)[0]\n",
    "        log_p = all_gmms[label_value].score_samples(samples)\n",
    "        p_ = 0\n",
    "        for inner_label_value in range(label_values):\n",
    "            p_ += np.exp(all_gmms[inner_label_value].score_samples(samples))\n",
    "        p = np.log(p_/label_values)\n",
    "        \n",
    "        MI += np.mean(log_p - p)\n",
    "    \n",
    "    MI_estimates[i] = MI/label_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ed91562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497.16844725608826"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - tic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c1b10e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48360447744050394, 0.008677881488270743)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MI_estimates), np.std(MI_estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02cd92",
   "metadata": {},
   "source": [
    "### Now do all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0bfcce66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1.4278538146226774\n",
      "2 -1.4278538135308911\n",
      "Convergence reached at 2 components\n",
      "1 -1.4046774618230098\n",
      "Convergence reached at 1 components\n",
      "1 -1.4325455522509278\n",
      "Convergence reached at 1 components\n",
      "1 -1.424767729705979\n",
      "Convergence reached at 1 components\n",
      "1 -1.4283032917651177\n",
      "Convergence reached at 1 components\n",
      "1 -1.4125616410525061\n",
      "Convergence reached at 1 components\n",
      "1 -1.4122224524532392\n",
      "2 -1.4122222038837862\n",
      "Convergence reached at 2 components\n",
      "1 -1.4246574684293973\n",
      "2 -1.4246572975602465\n",
      "Convergence reached at 2 components\n",
      "1 -1.4149368854946884\n",
      "Convergence reached at 1 components\n",
      "1 -1.437017648937302\n",
      "2 -1.4370175583514921\n",
      "Convergence reached at 2 components\n",
      "144.1802794933319\n",
      "0 0 0.0003306559476049711 0.00010236223990093201\n",
      "1 -1.4015621613883826\n",
      "Convergence reached at 1 components\n",
      "1 -1.4110030157116442\n",
      "Convergence reached at 1 components\n",
      "1 -1.4039307835017414\n",
      "2 -1.4039302951910182\n",
      "Convergence reached at 2 components\n",
      "1 -1.4203862852613272\n",
      "2 -1.4203862837339727\n",
      "Convergence reached at 2 components\n",
      "1 -1.4119444990842476\n",
      "Convergence reached at 1 components\n",
      "1 -1.4207856092423778\n",
      "Convergence reached at 1 components\n",
      "1 -1.4185416712934107\n",
      "2 -1.4185416634158858\n",
      "Convergence reached at 2 components\n",
      "1 -1.416742270106442\n",
      "2 -1.416742222852729\n",
      "Convergence reached at 2 components\n",
      "1 -1.4287095848430964\n",
      "Convergence reached at 1 components\n",
      "1 -1.4058824284350913\n",
      "Convergence reached at 1 components\n",
      "144.79546570777893\n",
      "0 1 0.0003525829594648127 0.00010546573733085884\n",
      "1 1.5759631324899852\n",
      "2 1.5759763469344652\n",
      "Convergence reached at 2 components\n",
      "1 1.2573965941405731\n",
      "2 1.2573969196301127\n",
      "Convergence reached at 2 components\n",
      "1 0.22618703469650972\n",
      "2 0.22618737712231426\n",
      "3 0.22618787654318226\n",
      "4 0.22618788012718313\n",
      "Convergence reached at 4 components\n",
      "1 0.23466035907831573\n",
      "2 0.23466065652151458\n",
      "Convergence reached at 2 components\n",
      "1 1.185604500474147\n",
      "2 1.1856083994952542\n",
      "3 1.1856115630071653\n",
      "Convergence reached at 3 components\n",
      "1 1.616685513072736\n",
      "2 1.6166893292576485\n",
      "Convergence reached at 2 components\n",
      "1 1.7351243058898245\n",
      "2 1.735124309896359\n",
      "Convergence reached at 2 components\n",
      "1 1.7760099872450217\n",
      "2 1.7760113098539019\n",
      "3 1.7760128423997161\n",
      "Convergence reached at 3 components\n",
      "1 1.7310668158844147\n",
      "2 1.7310723811107194\n",
      "Convergence reached at 2 components\n",
      "1 1.689561279556945\n",
      "2 1.689562100691404\n",
      "3 1.6895635436717962\n",
      "Convergence reached at 3 components\n",
      "247.95212602615356\n",
      "0 2 2.2950078371825238 0.000253718333405579\n",
      "1 -1.4330045065941768\n",
      "2 -1.4330000691107962\n",
      "3 -1.4330000237766205\n",
      "Convergence reached at 3 components\n",
      "1 -1.4148116389416323\n",
      "2 -1.4148007732483265\n",
      "Convergence reached at 2 components\n",
      "1 -1.4382089607583814\n",
      "2 -1.438207296955315\n",
      "3 -1.438206673138205\n",
      "Convergence reached at 3 components\n",
      "1 -1.4178482490684783\n",
      "2 -1.4178481156563822\n",
      "3 -1.4178407409600844\n",
      "Convergence reached at 3 components\n",
      "1 -1.4278205762396052\n",
      "2 -1.4278200969603898\n",
      "3 -1.4278155507619212\n",
      "Convergence reached at 3 components\n",
      "1 -1.4251484694924548\n",
      "2 -1.4251441934750224\n",
      "3 -1.4251423218881805\n",
      "Convergence reached at 3 components\n",
      "1 -1.4252647651085077\n",
      "2 -1.4252496081247639\n",
      "Convergence reached at 2 components\n",
      "1 -1.4115076271898428\n",
      "2 -1.4114975435218333\n",
      "3 -1.4114968697790882\n",
      "Convergence reached at 3 components\n",
      "1 -1.4275100745269516\n",
      "2 -1.4275050054785412\n",
      "3 -1.4275030218446487\n",
      "4 -1.4274993432871692\n",
      "Convergence reached at 4 components\n",
      "1 -1.4307799364890688\n",
      "2 -1.4307697784982523\n",
      "Convergence reached at 2 components\n",
      "268.7146062850952\n",
      "0 3 0.00045045221433511585 0.00012042245845939421\n",
      "1 -1.4194853237640803\n",
      "2 -1.4194853015511566\n",
      "Convergence reached at 2 components\n",
      "1 -1.435429691689399\n",
      "Convergence reached at 1 components\n",
      "1 -1.451878654130671\n",
      "Convergence reached at 1 components\n",
      "1 -1.4394328915298151\n",
      "2 -1.4394328340459996\n",
      "Convergence reached at 2 components\n",
      "1 -1.4526157772175627\n",
      "2 -1.4526157623428488\n",
      "Convergence reached at 2 components\n",
      "1 -1.4587836548160966\n",
      "Convergence reached at 1 components\n",
      "1 -1.4458371051825687\n",
      "Convergence reached at 1 components\n",
      "1 -1.4425752120224908\n",
      "Convergence reached at 1 components\n",
      "1 -1.4385044151385469\n",
      "Convergence reached at 1 components\n",
      "1 -1.4285567169050852\n",
      "Convergence reached at 1 components\n",
      "130.8980941772461\n",
      "0 4 0.0005443912747496054 0.00013192955283613622\n",
      "1 -1.4348465082014445\n",
      "Convergence reached at 1 components\n",
      "1 -1.4367559546672908\n",
      "Convergence reached at 1 components\n",
      "1 -1.4653566756677145\n",
      "Convergence reached at 1 components\n",
      "1 -1.4649767471101918\n",
      "2 -1.4649764348483192\n",
      "Convergence reached at 2 components\n",
      "1 -1.451007232609853\n",
      "Convergence reached at 1 components\n",
      "1 -1.4482252225678163\n",
      "Convergence reached at 1 components\n",
      "1 -1.4415994863475678\n",
      "Convergence reached at 1 components\n",
      "1 -1.4602720058887784\n",
      "Convergence reached at 1 components\n",
      "1 -1.4441034891401625\n",
      "2 -1.4441030645713377\n",
      "Convergence reached at 2 components\n",
      "1 -1.4336258105631854\n",
      "Convergence reached at 1 components\n",
      "117.23402380943298\n",
      "0 5 0.0005351976280509709 0.00011985680196598007\n",
      "1 -1.4213748402640147\n",
      "Convergence reached at 1 components\n",
      "1 -1.4198303097445262\n",
      "Convergence reached at 1 components\n",
      "1 -1.4318382869737298\n",
      "Convergence reached at 1 components\n",
      "1 -1.410679954676855\n",
      "2 -1.4106799534320726\n",
      "Convergence reached at 2 components\n",
      "1 -1.4240016088205592\n",
      "Convergence reached at 1 components\n",
      "1 -1.4103080804595904\n",
      "2 -1.4103078950434116\n",
      "Convergence reached at 2 components\n",
      "1 -1.4312181002081548\n",
      "Convergence reached at 1 components\n",
      "1 -1.424940748245602\n",
      "Convergence reached at 1 components\n",
      "1 -1.4286437696975287\n",
      "Convergence reached at 1 components\n",
      "1 -1.4141955473773606\n",
      "2 -1.4141955402811697\n",
      "3 -1.4141954779896355\n",
      "Convergence reached at 3 components\n",
      "137.22554183006287\n",
      "1 0 0.0003198950685061581 9.118317653966234e-05\n",
      "1 -1.4119258505360524\n",
      "2 -1.4119242401681233\n",
      "3 -1.4119192270186598\n",
      "Convergence reached at 3 components\n",
      "1 -1.4236963134727454\n",
      "2 -1.423687612245023\n",
      "3 -1.423686792213051\n",
      "Convergence reached at 3 components\n",
      "1 -1.4245355400092752\n",
      "2 -1.424531840042344\n",
      "3 -1.4245152685952005\n",
      "Convergence reached at 3 components\n",
      "1 -1.4324612214846253\n",
      "2 -1.4270411554485891\n",
      "Convergence reached at 2 components\n",
      "1 -1.435607076836784\n",
      "2 -1.4356034472386885\n",
      "Convergence reached at 2 components\n",
      "1 -1.4107810402552838\n",
      "2 -1.4107763803656903\n",
      "Convergence reached at 2 components\n",
      "1 -1.4223492124129526\n",
      "2 -1.4223475433315567\n",
      "Convergence reached at 2 components\n",
      "1 -1.395563860939139\n",
      "2 -1.3955621724564384\n",
      "3 -1.3955614773800908\n",
      "Convergence reached at 3 components\n",
      "1 -1.3855798426851706\n",
      "2 -1.3855785569965573\n",
      "3 -1.3855777746957099\n",
      "4 -1.385577052063238\n",
      "Convergence reached at 4 components\n",
      "1 -1.3935636355960443\n",
      "2 -1.3935626850393679\n",
      "Convergence reached at 2 components\n",
      "264.9410057067871\n",
      "1 1 0.0012555540785963168 0.00039735218863716975\n",
      "1 -1.4245058266082928\n",
      "Convergence reached at 1 components\n",
      "1 -1.4390339480668848\n",
      "Convergence reached at 1 components\n",
      "1 -1.4444953187636222\n",
      "Convergence reached at 1 components\n",
      "1 -1.4311898281854354\n",
      "2 -1.4311897766189088\n",
      "Convergence reached at 2 components\n",
      "1 -1.4468314738028047\n",
      "Convergence reached at 1 components\n",
      "1 -1.4545807174270795\n",
      "2 -1.4545806996001829\n",
      "Convergence reached at 2 components\n",
      "1 -1.4358533088653262\n",
      "Convergence reached at 1 components\n",
      "1 -1.4444541269781686\n",
      "2 -1.4444541042486436\n",
      "Convergence reached at 2 components\n",
      "1 -1.4185097567144658\n",
      "Convergence reached at 1 components\n",
      "1 -1.435584927164536\n",
      "Convergence reached at 1 components\n",
      "130.95785331726074\n",
      "1 2 0.0003530572438750938 9.606742940080434e-05\n",
      "1 -1.4283910202627659\n",
      "2 -1.4283888552538635\n",
      "3 -1.4283797857437426\n",
      "Convergence reached at 3 components\n",
      "1 -1.4241912464437574\n",
      "2 -1.4241854125876943\n",
      "3 -1.4241851953523295\n",
      "Convergence reached at 3 components\n",
      "1 -1.4460105851927347\n",
      "2 -1.446007809869812\n",
      "3 -1.4460067087379278\n",
      "4 -1.4460055860885825\n",
      "Convergence reached at 4 components\n",
      "1 -1.4396471659675114\n",
      "2 -1.4396420484874781\n",
      "3 -1.439641559095169\n",
      "4 -1.4396415483157539\n",
      "Convergence reached at 4 components\n",
      "1 -1.4199820704125263\n",
      "2 -1.4199786681073843\n",
      "3 -1.4199755317450293\n",
      "4 -1.419974367450581\n",
      "Convergence reached at 4 components\n",
      "1 -1.432095283510953\n",
      "2 -1.4320911525059221\n",
      "3 -1.4320852406299325\n",
      "4 -1.4320820394805305\n",
      "Convergence reached at 4 components\n",
      "1 -1.400491052786461\n",
      "2 -1.4004910246970086\n",
      "3 -1.4004851211937475\n",
      "4 -1.4004780193376203\n",
      "Convergence reached at 4 components\n",
      "1 -1.4262335963892825\n",
      "2 -1.4262322839810533\n",
      "3 -1.4262318636091111\n",
      "4 -1.4262268871980346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence reached at 4 components\n",
      "1 -1.4216620745122215\n",
      "2 -1.421661089920449\n",
      "Convergence reached at 2 components\n",
      "1 -1.4142816477857867\n",
      "2 -1.4142788947002385\n",
      "3 -1.4142781441638632\n",
      "Convergence reached at 3 components\n",
      "310.7913281917572\n",
      "1 3 0.0004720170854559289 0.00013773354353362158\n",
      "1 1.2084234382091399\n",
      "2 1.2084234759043824\n",
      "Convergence reached at 2 components\n",
      "1 0.8775035817313525\n",
      "Convergence reached at 1 components\n",
      "1 -0.053926999987213155\n",
      "2 -0.05391001451392313\n",
      "Convergence reached at 2 components\n",
      "1 -0.04888620565854201\n",
      "2 -0.048885129692210955\n",
      "Convergence reached at 2 components\n",
      "1 0.8816826899658352\n",
      "2 0.8816854760484963\n",
      "Convergence reached at 2 components\n",
      "1 1.267984973192198\n",
      "2 1.2679870476356925\n",
      "Convergence reached at 2 components\n",
      "1 1.335510741790392\n",
      "2 1.3355123195954979\n",
      "Convergence reached at 2 components\n",
      "1 1.3648887237557394\n",
      "2 1.36488899800387\n",
      "3 1.3648892619598294\n",
      "Convergence reached at 3 components\n",
      "1 1.3537729231313358\n",
      "2 1.353785919078345\n",
      "Convergence reached at 2 components\n",
      "1 1.3197329106036413\n",
      "2 1.3197499225151663\n",
      "Convergence reached at 2 components\n",
      "215.8644576072693\n",
      "1 4 2.2226739630586976 0.0013766004665941149\n",
      "1 -1.448683541589384\n",
      "2 -1.4486831583990962\n",
      "Convergence reached at 2 components\n",
      "1 -1.4391444807919516\n",
      "Convergence reached at 1 components\n",
      "1 -1.4204049210608982\n",
      "2 -1.420404868665489\n",
      "3 -1.420404850216207\n",
      "4 -1.4204047223048317\n",
      "Convergence reached at 4 components\n",
      "1 -1.445503449659787\n",
      "Convergence reached at 1 components\n",
      "1 -1.4627445540434258\n",
      "2 -1.4627440278163804\n",
      "3 -1.462743937430692\n",
      "Convergence reached at 3 components\n",
      "1 -1.4712453879427552\n",
      "2 -1.471245073348279\n",
      "3 -1.4712445900750428\n",
      "Convergence reached at 3 components\n",
      "1 -1.442129987372593\n",
      "Convergence reached at 1 components\n",
      "1 -1.4541736014138245\n",
      "2 -1.4541735976412085\n",
      "Convergence reached at 2 components\n",
      "1 -1.4472224767840192\n",
      "Convergence reached at 1 components\n",
      "1 -1.453112866217498\n",
      "Convergence reached at 1 components\n",
      "182.03676199913025\n",
      "1 5 0.0003391528088042935 9.449333309990194e-05\n",
      "1 -0.32716642644428046\n",
      "2 -0.32716116615491186\n",
      "Convergence reached at 2 components\n",
      "1 0.02773854604125581\n",
      "2 0.027744984385488603\n",
      "Convergence reached at 2 components\n",
      "1 0.4200891172913151\n",
      "2 0.420098786169152\n",
      "Convergence reached at 2 components\n",
      "1 0.7504230869718317\n",
      "2 0.7504334317132718\n",
      "3 0.7504380506071602\n",
      "4 0.750450841139039\n",
      "Convergence reached at 4 components\n",
      "1 1.0188263082945361\n",
      "2 1.0188491628015788\n",
      "Convergence reached at 2 components\n",
      "1 0.9175784627192701\n",
      "2 0.9175861992299174\n",
      "Convergence reached at 2 components\n",
      "1 0.8169817894810135\n",
      "2 0.8169901025984833\n",
      "3 0.8169955732205046\n",
      "4 0.8170027895852338\n",
      "Convergence reached at 4 components\n",
      "1 0.7869784298423897\n",
      "2 0.7869789665083905\n",
      "Convergence reached at 2 components\n",
      "1 0.8504964029655863\n",
      "Convergence reached at 1 components\n",
      "1 0.9695857069740955\n",
      "2 0.9695918193434868\n",
      "Convergence reached at 2 components\n",
      "1 1.0470796859414466\n",
      "2 1.047084444407612\n",
      "3 1.047089866800286\n",
      "4 1.0470904244535113\n",
      "5 1.0470917827600152\n",
      "Convergence reached at 5 components\n",
      "1 0.7859614995601018\n",
      "2 0.7859652105985685\n",
      "3 0.7859773789725107\n",
      "Convergence reached at 3 components\n",
      "1 0.4550248812596225\n",
      "2 0.4550395630263991\n",
      "Convergence reached at 2 components\n",
      "1 0.015060694290872268\n",
      "2 0.015068395202724669\n",
      "Convergence reached at 2 components\n",
      "1 -0.3587188189901945\n",
      "2 -0.3587144965306614\n",
      "Convergence reached at 2 components\n",
      "518.799557685852\n",
      "2 0 1.955009886875589 0.0031253278057519563\n",
      "1 -1.4054203468081339\n",
      "Convergence reached at 1 components\n",
      "1 -1.422853736556928\n",
      "Convergence reached at 1 components\n",
      "1 -1.4113973082364621\n",
      "2 -1.411397241196451\n",
      "Convergence reached at 2 components\n",
      "1 -1.4189580707573632\n",
      "Convergence reached at 1 components\n",
      "1 -1.4022992093148836\n",
      "2 -1.4022989471855378\n",
      "Convergence reached at 2 components\n",
      "1 -1.3941103716924885\n",
      "2 -1.3941101937160134\n",
      "Convergence reached at 2 components\n",
      "1 -1.4132752337014507\n",
      "Convergence reached at 1 components\n",
      "1 -1.4309955425116947\n",
      "Convergence reached at 1 components\n",
      "1 -1.4163979748066522\n",
      "Convergence reached at 1 components\n",
      "1 -1.403651033473982\n",
      "Convergence reached at 1 components\n",
      "1 -1.3981375512071956\n",
      "2 -1.3981374953955372\n",
      "Convergence reached at 2 components\n",
      "1 -1.4174429353665399\n",
      "Convergence reached at 1 components\n",
      "1 -1.4319628854134436\n",
      "2 -1.431962883102595\n",
      "3 -1.43196279961377\n",
      "Convergence reached at 3 components\n",
      "1 -1.4094550178143042\n",
      "Convergence reached at 1 components\n",
      "1 -1.4336507631355413\n",
      "2 -1.433650519147082\n",
      "Convergence reached at 2 components\n",
      "311.65956115722656\n",
      "2 1 0.0005758350889765542 0.00012239392073879287\n",
      "1 -1.4383901203842395\n",
      "Convergence reached at 1 components\n",
      "1 -1.435227513364035\n",
      "Convergence reached at 1 components\n",
      "1 -1.444249197142925\n",
      "Convergence reached at 1 components\n",
      "1 -1.4415684128201243\n",
      "Convergence reached at 1 components\n",
      "1 -1.4400751367837923\n",
      "Convergence reached at 1 components\n",
      "1 -1.4454544827512612\n",
      "Convergence reached at 1 components\n",
      "1 -1.4261866263932517\n",
      "Convergence reached at 1 components\n",
      "1 -1.4471744302245064\n",
      "Convergence reached at 1 components\n",
      "1 -1.4420812873881017\n",
      "Convergence reached at 1 components\n",
      "1 -1.4264717619515233\n",
      "Convergence reached at 1 components\n",
      "1 -1.4238928696454742\n",
      "Convergence reached at 1 components\n",
      "1 -1.443702313198173\n",
      "Convergence reached at 1 components\n",
      "1 -1.431177650017788\n",
      "Convergence reached at 1 components\n",
      "1 -1.4471591886589075\n",
      "Convergence reached at 1 components\n",
      "1 -1.4347247504732852\n",
      "Convergence reached at 1 components\n",
      "182.77217364311218\n",
      "2 2 0.00040851052280711976 9.202448099886361e-05\n",
      "1 -1.4263363840837648\n",
      "2 -1.426310080957683\n",
      "Convergence reached at 2 components\n",
      "1 -1.4245213078765504\n",
      "2 -1.4245033358601835\n",
      "Convergence reached at 2 components\n",
      "1 -1.4341236256998642\n",
      "2 -1.4341033244838883\n",
      "Convergence reached at 2 components\n",
      "1 -1.433443623355675\n",
      "Convergence reached at 1 components\n",
      "1 -1.4128942019415962\n",
      "2 -1.4128850497736425\n",
      "Convergence reached at 2 components\n",
      "1 -1.4175974169662122\n",
      "2 -1.417593144641381\n",
      "Convergence reached at 2 components\n",
      "1 -1.4197407558241306\n",
      "2 -1.4197401679241761\n",
      "Convergence reached at 2 components\n",
      "1 -1.4291940667248817\n",
      "2 -1.429190889845619\n",
      "Convergence reached at 2 components\n",
      "1 -1.421899609300773\n",
      "Convergence reached at 1 components\n",
      "1 -1.416224284751044\n",
      "2 -1.4162231919477966\n",
      "3 -1.4162225024806885\n",
      "Convergence reached at 3 components\n",
      "1 -1.4216030824521202\n",
      "2 -1.4215897407511118\n",
      "3 -1.4215779629330083\n",
      "Convergence reached at 3 components\n",
      "1 -1.4211989781380396\n",
      "2 -1.4211977770725364\n",
      "3 -1.421196598088203\n",
      "Convergence reached at 3 components\n",
      "1 -1.4214274894024508\n",
      "2 -1.4214150689298022\n",
      "3 -1.4214143175412761\n",
      "4 -1.4213937460781934\n",
      "Convergence reached at 4 components\n",
      "1 -1.4432022874211958\n",
      "2 -1.4431825115433117\n",
      "3 -1.4431806997161392\n",
      "Convergence reached at 3 components\n",
      "1 -1.437216215797088\n",
      "2 -1.4291170596256155\n",
      "Convergence reached at 2 components\n",
      "501.73519825935364\n",
      "2 3 0.0011194024067060877 0.0005251330287793483\n",
      "1 -1.434329576568026\n",
      "Convergence reached at 1 components\n",
      "1 -1.4489785246279174\n",
      "Convergence reached at 1 components\n",
      "1 -1.4234850836599904\n",
      "2 -1.423485076712246\n",
      "Convergence reached at 2 components\n",
      "1 -1.4422957993930636\n",
      "Convergence reached at 1 components\n",
      "1 -1.444507810269933\n",
      "Convergence reached at 1 components\n",
      "1 -1.4455505501484032\n",
      "Convergence reached at 1 components\n",
      "1 -1.4420999252961397\n",
      "Convergence reached at 1 components\n",
      "1 -1.4317133039611079\n",
      "Convergence reached at 1 components\n",
      "1 -1.4474782930969292\n",
      "Convergence reached at 1 components\n",
      "1 -1.4554156445599478\n",
      "2 -1.4554156212251843\n",
      "Convergence reached at 2 components\n",
      "1 -1.4420561066928104\n",
      "Convergence reached at 1 components\n",
      "1 -1.4491124526313166\n",
      "Convergence reached at 1 components\n",
      "1 -1.429824678981902\n",
      "2 -1.4298245932576055\n",
      "Convergence reached at 2 components\n",
      "1 -1.443918787801086\n",
      "Convergence reached at 1 components\n",
      "1 -1.440489289575285\n",
      "2 -1.4404892440237729\n",
      "3 -1.4404888947096772\n",
      "Convergence reached at 3 components\n",
      "271.141215801239\n",
      "2 4 0.0005012701028098913 0.00013237121434621447\n",
      "1 -1.4321773143068472\n",
      "Convergence reached at 1 components\n",
      "1 -1.4457297151656359\n",
      "Convergence reached at 1 components\n",
      "1 -1.4539960869243107\n",
      "Convergence reached at 1 components\n",
      "1 -1.4467876882264898\n",
      "Convergence reached at 1 components\n",
      "1 -1.4612124838392517\n",
      "Convergence reached at 1 components\n",
      "1 -1.4598363023480996\n",
      "2 -1.4598362954305566\n",
      "Convergence reached at 2 components\n",
      "1 -1.4567834855079462\n",
      "Convergence reached at 1 components\n",
      "1 -1.452233132065271\n",
      "Convergence reached at 1 components\n",
      "1 -1.4492590256555011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence reached at 1 components\n",
      "1 -1.433899498551363\n",
      "Convergence reached at 1 components\n",
      "1 -1.43550651315188\n",
      "2 -1.4355061923665395\n",
      "Convergence reached at 2 components\n",
      "1 -1.445844014652316\n",
      "Convergence reached at 1 components\n",
      "1 -1.45596831225422\n",
      "2 -1.4559682499512345\n",
      "Convergence reached at 2 components\n",
      "1 -1.442023564396135\n",
      "Convergence reached at 1 components\n",
      "1 -1.4537502470369275\n",
      "Convergence reached at 1 components\n",
      "244.18999767303467\n",
      "2 5 0.0004907757482120115 0.00013123776522044176\n",
      "1 -1.4261821793131622\n",
      "Convergence reached at 1 components\n",
      "1 -1.4163259982863392\n",
      "Convergence reached at 1 components\n",
      "1 -1.4283071348251133\n",
      "Convergence reached at 1 components\n",
      "1 -1.4275667029348487\n",
      "Convergence reached at 1 components\n",
      "1 -1.40889240249167\n",
      "Convergence reached at 1 components\n",
      "1 -1.4336732205697222\n",
      "Convergence reached at 1 components\n",
      "1 -1.408945293606255\n",
      "Convergence reached at 1 components\n",
      "1 -1.423650919913966\n",
      "Convergence reached at 1 components\n",
      "60.357749938964844\n",
      "3 0 0.00029810367514393146 9.18456783197718e-05\n",
      "1 -1.5022471351777595\n",
      "Convergence reached at 1 components\n",
      "1 -1.2810659888804443\n",
      "Convergence reached at 1 components\n",
      "1 -1.1118377365395584\n",
      "2 -1.1118360587868004\n",
      "Convergence reached at 2 components\n",
      "1 -1.0911051987019296\n",
      "Convergence reached at 1 components\n",
      "1 -1.1923929970980092\n",
      "Convergence reached at 1 components\n",
      "1 -1.3412346962331672\n",
      "Convergence reached at 1 components\n",
      "1 -1.5417661615040597\n",
      "Convergence reached at 1 components\n",
      "1 -1.801711537375321\n",
      "Convergence reached at 1 components\n",
      "72.48370814323425\n",
      "3 1 0.04785045308339952 0.0008742917959713373\n",
      "1 -1.4494953910602166\n",
      "Convergence reached at 1 components\n",
      "1 -1.4494775936640483\n",
      "Convergence reached at 1 components\n",
      "1 -1.4381636164709672\n",
      "Convergence reached at 1 components\n",
      "1 -1.4459667820811652\n",
      "Convergence reached at 1 components\n",
      "1 -1.4390626193608238\n",
      "Convergence reached at 1 components\n",
      "1 -1.431539001872424\n",
      "Convergence reached at 1 components\n",
      "1 -1.420265731549806\n",
      "Convergence reached at 1 components\n",
      "1 -1.4258789709577842\n",
      "Convergence reached at 1 components\n",
      "60.36424803733826\n",
      "3 2 0.00027314668976867365 9.32229309208936e-05\n",
      "1 -0.9225725943635975\n",
      "2 -0.872994249281602\n",
      "3 -0.8321391906262585\n",
      "4 -0.8311610133708109\n",
      "Convergence reached at 4 components\n",
      "1 -0.8083382910562578\n",
      "2 -0.7885373212853821\n",
      "3 -0.7882585784567695\n",
      "4 -0.7614027289823787\n",
      "Convergence reached at 4 components\n",
      "1 -0.8326579785064778\n",
      "2 -0.7620893425803016\n",
      "Convergence reached at 2 components\n",
      "1 -0.9233398813296141\n",
      "2 -0.8265421218357178\n",
      "Convergence reached at 2 components\n",
      "1 -1.0214874337539877\n",
      "2 -0.9080152775853855\n",
      "3 -0.8772289751526117\n",
      "4 -0.8723631583496928\n",
      "5 -0.8623213742366582\n",
      "Convergence reached at 5 components\n",
      "1 -1.1582618172226533\n",
      "2 -1.0604359380570296\n",
      "3 -0.9613187116535062\n",
      "Convergence reached at 3 components\n",
      "1 -1.2758897339915867\n",
      "2 -1.1467730469207205\n",
      "3 -1.0940507376391382\n",
      "Convergence reached at 3 components\n",
      "1 -1.3914381284494821\n",
      "2 -1.3255693795169412\n",
      "3 -1.297369495848088\n",
      "Convergence reached at 3 components\n",
      "491.3436710834503\n",
      "3 3 0.48360447744050394 0.008677881488270743\n",
      "1 -1.3647346274229237\n",
      "Convergence reached at 1 components\n",
      "1 -1.3943421463571208\n",
      "Convergence reached at 1 components\n",
      "1 -1.4208847632190127\n",
      "2 -1.4208847226770507\n",
      "Convergence reached at 2 components\n",
      "1 -1.4570716597295472\n",
      "Convergence reached at 1 components\n",
      "1 -1.447644372531287\n",
      "Convergence reached at 1 components\n",
      "1 -1.4581598429314786\n",
      "Convergence reached at 1 components\n",
      "1 -1.4757878514218488\n",
      "Convergence reached at 1 components\n",
      "1 -1.49823408764587\n",
      "Convergence reached at 1 components\n",
      "72.46855020523071\n",
      "3 4 0.0018724320245455334 0.0002541614464396015\n",
      "1 -1.4513891095073344\n",
      "2 -1.4513891064238669\n",
      "Convergence reached at 2 components\n",
      "1 -1.4616039167535233\n",
      "Convergence reached at 1 components\n",
      "1 -1.4615437060241827\n",
      "Convergence reached at 1 components\n",
      "1 -1.4620660183495202\n",
      "Convergence reached at 1 components\n",
      "1 -1.4573262042681858\n",
      "Convergence reached at 1 components\n",
      "1 -1.4504602468831695\n",
      "Convergence reached at 1 components\n",
      "1 -1.4279446579344393\n",
      "Convergence reached at 1 components\n",
      "1 -1.4112628486023837\n",
      "Convergence reached at 1 components\n",
      "71.73449158668518\n",
      "3 5 0.00045812990408572224 0.00011706139533238168\n",
      "1 -1.4301870411834559\n",
      "Convergence reached at 1 components\n",
      "1 -1.4211069007133554\n",
      "Convergence reached at 1 components\n",
      "1 -1.4236695127673358\n",
      "Convergence reached at 1 components\n",
      "1 -1.4110066274162112\n",
      "2 -1.411006615484693\n",
      "Convergence reached at 2 components\n",
      "27.461752891540527\n",
      "4 0 7.908457963039898e-05 4.7279197307931955e-05\n",
      "1 -1.5610467283613823\n",
      "Convergence reached at 1 components\n",
      "1 -0.9970434490534492\n",
      "2 -0.9970433247733089\n",
      "Convergence reached at 2 components\n",
      "1 -1.0960992642596026\n",
      "Convergence reached at 1 components\n",
      "1 -1.6754554439827498\n",
      "Convergence reached at 1 components\n",
      "27.681143522262573\n",
      "4 1 0.06901571233117633 0.0011096825269693235\n",
      "1 -1.4183569506808122\n",
      "Convergence reached at 1 components\n",
      "1 -1.4366111062988374\n",
      "Convergence reached at 1 components\n",
      "1 -1.4567981271667632\n",
      "Convergence reached at 1 components\n",
      "1 -1.4371648284365943\n",
      "Convergence reached at 1 components\n",
      "20.340872049331665\n",
      "4 2 0.0002465223276022762 9.405795897529219e-05\n",
      "1 -1.3270980300980735\n",
      "Convergence reached at 1 components\n",
      "1 -1.1989674360164455\n",
      "2 -1.1989674358674303\n",
      "Convergence reached at 2 components\n",
      "1 -1.0328032547519939\n",
      "2 -1.0328032504554414\n",
      "Convergence reached at 2 components\n",
      "1 -0.9581867100199117\n",
      "2 -0.9581862355894746\n",
      "3 -0.9581727850285794\n",
      "Convergence reached at 3 components\n",
      "45.4848198890686\n",
      "4 3 0.2923300209830591 0.0025404946612328657\n",
      "1 -1.4284833811391104\n",
      "Convergence reached at 1 components\n",
      "1 -1.4381801747012186\n",
      "Convergence reached at 1 components\n",
      "1 -1.448414545774931\n",
      "Convergence reached at 1 components\n",
      "1 -1.4501510665493489\n",
      "Convergence reached at 1 components\n",
      "20.369789838790894\n",
      "4 4 0.00017496648744056635 7.541176061080794e-05\n",
      "1 -1.438158052469723\n",
      "2 -1.4381580346071559\n",
      "Convergence reached at 2 components\n",
      "1 -1.4477545107650736\n",
      "Convergence reached at 1 components\n",
      "1 -1.4564956080162272\n",
      "Convergence reached at 1 components\n",
      "1 -1.450024782571301\n",
      "Convergence reached at 1 components\n",
      "27.667482614517212\n",
      "4 5 0.0001154253892466724 5.014120713375708e-05\n",
      "1 -1.426163281686432\n",
      "Convergence reached at 1 components\n",
      "1 -1.4114991859067045\n",
      "2 -1.4114988602789575\n",
      "Convergence reached at 2 components\n",
      "1 -1.447009303375608\n",
      "2 -1.4470089820696146\n",
      "Convergence reached at 2 components\n",
      "1 -1.4506005034106544\n",
      "2 -1.4505997894831217\n",
      "Convergence reached at 2 components\n",
      "1 -1.4145625315191965\n",
      "Convergence reached at 1 components\n",
      "1 -1.4241067706622828\n",
      "2 -1.4241061845494902\n",
      "Convergence reached at 2 components\n",
      "1 -1.4294795526792148\n",
      "Convergence reached at 1 components\n",
      "1 -1.4204167469258222\n",
      "Convergence reached at 1 components\n",
      "1 -1.3933171392232342\n",
      "Convergence reached at 1 components\n",
      "1 -1.3961906970057203\n",
      "Convergence reached at 1 components\n",
      "145.00321340560913\n",
      "5 0 0.0006287299300458106 0.00015108321605081669\n",
      "1 -1.4097952823209703\n",
      "2 -1.4097952068606194\n",
      "Convergence reached at 2 components\n",
      "1 -1.406727167371302\n",
      "2 -1.406715697831572\n",
      "Convergence reached at 2 components\n",
      "1 -1.4387961961270188\n",
      "2 -1.4387917116532165\n",
      "3 -1.438789182906971\n",
      "Convergence reached at 3 components\n",
      "1 -1.4367397958099246\n",
      "2 -1.4367371378973761\n",
      "Convergence reached at 2 components\n",
      "1 -1.420842494693846\n",
      "2 -1.420839707052813\n",
      "Convergence reached at 2 components\n",
      "1 -1.411640403504826\n",
      "Convergence reached at 1 components\n",
      "1 -1.4047717283839363\n",
      "Convergence reached at 1 components\n",
      "1 -1.4098619351353863\n",
      "Convergence reached at 1 components\n",
      "1 -1.4087300242316365\n",
      "Convergence reached at 1 components\n",
      "1 -1.387313359546603\n",
      "2 -1.3873115864411327\n",
      "3 -1.387310987000702\n",
      "Convergence reached at 3 components\n",
      "182.7932231426239\n",
      "5 1 0.0006131526212988285 0.0001462065885970537\n",
      "1 -1.4295354666861897\n",
      "Convergence reached at 1 components\n",
      "1 -1.4581586847486354\n",
      "Convergence reached at 1 components\n",
      "1 -1.4607294073025259\n",
      "Convergence reached at 1 components\n",
      "1 -1.4524442329578757\n",
      "Convergence reached at 1 components\n",
      "1 -1.4392294546360016\n",
      "2 -1.43922929811818\n",
      "Convergence reached at 2 components\n",
      "1 -1.4250319601222419\n",
      "Convergence reached at 1 components\n",
      "1 -1.4366538575952201\n",
      "Convergence reached at 1 components\n",
      "1 -1.414257848694448\n",
      "Convergence reached at 1 components\n",
      "1 -1.4140086100749738\n",
      "2 -1.4140086077929597\n",
      "Convergence reached at 2 components\n",
      "1 -1.4419646988750436\n",
      "Convergence reached at 1 components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.44382071495056\n",
      "5 2 0.0004858506047150676 0.00010568306644996125\n",
      "1 -1.4037691984553218\n",
      "2 -1.403757503964939\n",
      "Convergence reached at 2 components\n",
      "1 -1.4197695240850214\n",
      "2 -1.419764260987395\n",
      "Convergence reached at 2 components\n",
      "1 -1.4173963157391352\n",
      "2 -1.4173892233247922\n",
      "Convergence reached at 2 components\n",
      "1 -1.4357218425588218\n",
      "2 -1.4357149878054996\n",
      "3 -1.435713296895356\n",
      "4 -1.4357126499975357\n",
      "Convergence reached at 4 components\n",
      "1 -1.4414778357411553\n",
      "2 -1.4414734010588648\n",
      "3 -1.4414727669259235\n",
      "Convergence reached at 3 components\n",
      "1 -1.4173764079529942\n",
      "2 -1.4173739474900116\n",
      "3 -1.4173729204842764\n",
      "4 -1.417363785611747\n",
      "Convergence reached at 4 components\n",
      "1 -1.4332013166342243\n",
      "2 -1.433190972921446\n",
      "Convergence reached at 2 components\n",
      "1 -1.4176276576209974\n",
      "2 -1.4176248604547574\n",
      "Convergence reached at 2 components\n",
      "1 -1.4366282844644591\n",
      "Convergence reached at 1 components\n",
      "1 -1.4283205064983155\n",
      "2 -1.428318164804302\n",
      "3 -1.4283062186428916\n",
      "Convergence reached at 3 components\n",
      "249.73053812980652\n",
      "5 3 0.0006073411466321145 0.0001352204252935129\n",
      "1 -1.4493872498582787\n",
      "Convergence reached at 1 components\n",
      "1 -1.4420780146487264\n",
      "Convergence reached at 1 components\n",
      "1 -1.4391572425766481\n",
      "2 -1.4391572400111636\n",
      "3 -1.4391568495341787\n",
      "Convergence reached at 3 components\n",
      "1 -1.4607674074618142\n",
      "2 -1.4607670761481337\n",
      "Convergence reached at 2 components\n",
      "1 -1.4337480341316011\n",
      "Convergence reached at 1 components\n",
      "1 -1.44322767660695\n",
      "2 -1.4432273955261739\n",
      "Convergence reached at 2 components\n",
      "1 -1.430896233036524\n",
      "2 -1.4308962091435682\n",
      "Convergence reached at 2 components\n",
      "1 -1.4398266082807423\n",
      "Convergence reached at 1 components\n",
      "1 -1.4372519027815962\n",
      "Convergence reached at 1 components\n",
      "1 -1.4370356260665915\n",
      "Convergence reached at 1 components\n",
      "151.83138632774353\n",
      "5 4 0.00045773277364625955 0.0001308203747400146\n",
      "1 1.4844849188409857\n",
      "2 1.4844907856639538\n",
      "3 1.4844917940584084\n",
      "Convergence reached at 3 components\n",
      "1 1.1656246549300973\n",
      "2 1.1656356460403734\n",
      "Convergence reached at 2 components\n",
      "1 0.21180548696466528\n",
      "2 0.2118294115436544\n",
      "Convergence reached at 2 components\n",
      "1 0.25438937596102956\n",
      "2 0.25440168985351225\n",
      "3 0.2544177937516008\n",
      "4 0.25442111633786263\n",
      "5 0.2550900589683251\n",
      "Convergence reached at 5 components\n",
      "1 1.1306276367102528\n",
      "2 1.1306300245786172\n",
      "3 1.1306373593147712\n",
      "Convergence reached at 3 components\n",
      "1 1.5001156597482155\n",
      "2 1.50011570738707\n",
      "Convergence reached at 2 components\n",
      "1 1.6143832441923092\n",
      "2 1.6143981194302413\n",
      "Convergence reached at 2 components\n",
      "1 1.6192854804603616\n",
      "2 1.6192855016185919\n",
      "Convergence reached at 2 components\n",
      "1 1.6140669076458962\n",
      "2 1.6140678966800286\n",
      "3 1.6140682668039592\n",
      "4 1.6140698161688016\n",
      "Convergence reached at 4 components\n",
      "1 1.559124739803467\n",
      "Convergence reached at 1 components\n",
      "252.29496669769287\n",
      "5 5 2.289336098076703 0.0004132096712048805\n"
     ]
    }
   ],
   "source": [
    "label_list = ['floor_hue', 'object_hue', 'orientation', 'scale', 'shape', 'wall_hue']\n",
    "n_bootstrap = 10\n",
    "0\n",
    "n_inits = 5\n",
    "n_folds = 3\n",
    "init_type = 'random_sklearn'\n",
    "n_bootstrap = 100\n",
    "MC_samples = 1e5\n",
    "tol = 1e-5\n",
    "reg_covar = 1e-15\n",
    "components_range = 15\n",
    "patience = 1\n",
    "MC_samples = 1e5\n",
    "\n",
    "all_MI_estimates = np.zeros((len(label_list), 6, n_bootstrap))\n",
    "for label_id in label_list:\n",
    "    for latent_id in range(6):\n",
    "        \n",
    "        label_values = dict_labels[label_id][0]\n",
    "        label_number = dict_labels[label_id][1]\n",
    "\n",
    "        # first identify all initialisations for all needed models (1x10 in this case)\n",
    "\n",
    "        tic = time.time()\n",
    "\n",
    "        first_labels = all_labels[:, label_number]\n",
    "        first_latents = all_latents[:, latent_id]\n",
    "\n",
    "        init_params_ = []\n",
    "        for label_value in range(label_values):\n",
    "            # select latents corresponding to those labels\n",
    "            current_ids = np.where(first_labels == label_value)\n",
    "            current_latents = first_latents[current_ids]\n",
    "            # we need to fit the current latents; this is p(z1|f1 = label_value)\n",
    "            best_val = -np.inf\n",
    "            pat_counter = 0\n",
    "            X = np.reshape(current_latents, (-1, 1))\n",
    "            for n_components in range(1, components_range+1):\n",
    "                current_seed, current_val, _ = MI_procedure_diffconvergence(X, n_components=n_components, n_folds=n_folds, \n",
    "                                                                   init_type=init_type, n_inits=n_inits, tol=tol, reg_covar=reg_covar)\n",
    "\n",
    "                # check if convergence has been reached based on val score\n",
    "                if current_val > best_val:\n",
    "                    best_val = current_val\n",
    "                    best_seed = current_seed\n",
    "                    best_components = n_components\n",
    "                    print(n_components, best_val)\n",
    "                else:\n",
    "                    pat_counter += 1\n",
    "                    if pat_counter >= patience:\n",
    "\n",
    "                        print(f'Convergence reached at {best_components} components') \n",
    "                        w_init, m_init, c_init, p_init = initialize_parameters(X, best_seed, n_components=best_components, init_type=init_type)\n",
    "                        init_params_.append({'w': w_init, 'm': m_init, 'c': c_init, 'p': p_init, 'bc': best_components, 'seed': best_seed})\n",
    "                        break\n",
    "\n",
    "\n",
    "        # then bootstrap and calculate MI\n",
    "\n",
    "        MI_estimates = np.zeros(n_bootstrap)\n",
    "\n",
    "        for i in range(n_bootstrap):\n",
    "            # we use i to change the seed so that the results will be fully reproducible\n",
    "            rng = np.random.default_rng(i)\n",
    "\n",
    "            all_gmms = []\n",
    "            for label_value in range(label_values):\n",
    "                # select latents corresponding to those labels\n",
    "                current_ids = np.where(first_labels == label_value)\n",
    "                current_latents = first_latents[current_ids]\n",
    "                X = np.reshape(current_latents, (-1, 1))\n",
    "\n",
    "                n_components = init_params_[label_value]['bc']\n",
    "                w_init = init_params_[label_value]['w']\n",
    "                m_init = init_params_[label_value]['m']\n",
    "                p_init = init_params_[label_value]['p']\n",
    "                seed = init_params_[label_value]['seed']\n",
    "\n",
    "                X_bs = rng.choice(X, X.shape[0])\n",
    "                gmm = my_GMM(n_components=n_components, reg_covar=reg_covar, \n",
    "                            tol=tol, max_iter=10000, \n",
    "                            random_state=seed, weights_init=w_init, \n",
    "                            means_init=m_init, precisions_init=p_init).fit(X_bs)\n",
    "\n",
    "                all_gmms.append(gmm)\n",
    "\n",
    "            # estimate MI using MC\n",
    "            MI = 0 \n",
    "            for label_value in range(label_values):\n",
    "                samples = all_gmms[label_value].sample(MC_samples)[0]\n",
    "                log_p = all_gmms[label_value].score_samples(samples)\n",
    "                p_ = 0\n",
    "                for inner_label_value in range(label_values):\n",
    "                    p_ += np.exp(all_gmms[inner_label_value].score_samples(samples))\n",
    "                p = np.log(p_/label_values)\n",
    "\n",
    "                MI += np.mean(log_p - p)\n",
    "\n",
    "            MI_estimates[i] = MI/label_values\n",
    "\n",
    "        print(time.time() - tic )\n",
    "        print(label_number, latent_id, np.mean(MI_estimates), np.std(MI_estimates))\n",
    "        all_MI_estimates[label_number, latent_id] = MI_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9ef0544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.30655948e-04, 3.52582959e-04, 2.29500784e+00, 4.50452214e-04,\n",
       "         5.44391275e-04, 5.35197628e-04],\n",
       "        [3.19895069e-04, 1.25555408e-03, 3.53057244e-04, 4.72017085e-04,\n",
       "         2.22267396e+00, 3.39152809e-04],\n",
       "        [1.95500989e+00, 5.75835089e-04, 4.08510523e-04, 1.11940241e-03,\n",
       "         5.01270103e-04, 4.90775748e-04],\n",
       "        [2.98103675e-04, 4.78504531e-02, 2.73146690e-04, 4.83604477e-01,\n",
       "         1.87243202e-03, 4.58129904e-04],\n",
       "        [7.90845796e-05, 6.90157123e-02, 2.46522328e-04, 2.92330021e-01,\n",
       "         1.74966487e-04, 1.15425389e-04],\n",
       "        [6.28729930e-04, 6.13152621e-04, 4.85850605e-04, 6.07341147e-04,\n",
       "         4.57732774e-04, 2.28933610e+00]]),\n",
       " array([[1.02362240e-04, 1.05465737e-04, 2.53718333e-04, 1.20422458e-04,\n",
       "         1.31929553e-04, 1.19856802e-04],\n",
       "        [9.11831765e-05, 3.97352189e-04, 9.60674294e-05, 1.37733544e-04,\n",
       "         1.37660047e-03, 9.44933331e-05],\n",
       "        [3.12532781e-03, 1.22393921e-04, 9.20244810e-05, 5.25133029e-04,\n",
       "         1.32371214e-04, 1.31237765e-04],\n",
       "        [9.18456783e-05, 8.74291796e-04, 9.32229309e-05, 8.67788149e-03,\n",
       "         2.54161446e-04, 1.17061395e-04],\n",
       "        [4.72791973e-05, 1.10968253e-03, 9.40579590e-05, 2.54049466e-03,\n",
       "         7.54117606e-05, 5.01412071e-05],\n",
       "        [1.51083216e-04, 1.46206589e-04, 1.05683066e-04, 1.35220425e-04,\n",
       "         1.30820375e-04, 4.13209671e-04]]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_MI_estimates, axis=2), np.std(all_MI_estimates, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f6130226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 100)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('./MI_latents_labels.npy', all_MI_estimates)\n",
    "all_MI_estimates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315e180",
   "metadata": {},
   "source": [
    "### Also look at disentanglement between latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5932636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -2.8351839731527075\n",
      "Convergence reached at 1 components\n",
      "Total time to run the procedure: 6.78 s\n",
      "\n",
      "2.1854010013858267e-05 2.8188332567922855e-05\n",
      "1 -2.858851631122507\n",
      "Convergence reached at 1 components\n",
      "Total time to run the procedure: 6.68 s\n",
      "\n",
      "9.105459309968977e-06 1.816437594410711e-05\n",
      "1 -2.8466428486092608\n",
      "2 -2.8466419399345155\n",
      "Convergence reached at 2 components\n",
      "Total time to run the procedure: 16.35 s\n",
      "\n",
      "9.915161717324454e-05 6.702912576368392e-05\n",
      "1 -2.8627978572886206\n",
      "Convergence reached at 1 components\n",
      "Total time to run the procedure: 6.72 s\n",
      "\n",
      "7.275620813958173e-06 1.4821284488435358e-05\n",
      "1 -2.8696041505675383\n",
      "2 -2.8696037266052596\n",
      "Convergence reached at 2 components\n",
      "Total time to run the procedure: 16.23 s\n",
      "\n",
      "1.4595423324363134e-05 3.8313708857700765e-05\n",
      "1 -2.850887724324322\n",
      "Convergence reached at 1 components\n",
      "Total time to run the procedure: 6.77 s\n",
      "\n",
      "1.8293658419239556e-05 2.7888542865517755e-05\n",
      "1 -2.8388687422340992\n",
      "2 -2.838866166058255\n",
      "3 -2.8388636051302023\n",
      "Convergence reached at 3 components\n",
      "Total time to run the procedure: 22.24 s\n",
      "\n",
      "1.707460165127512e-05 2.041340821620842e-05\n",
      "1 -2.854701363740458\n",
      "2 -2.8547007360513903\n",
      "3 -2.8547001331258173\n",
      "Convergence reached at 3 components\n",
      "Total time to run the procedure: 22.05 s\n",
      "\n",
      "0.00030857222741128356 0.00010514447567282977\n",
      "1 -2.861721593695322\n",
      "2 -2.861720781757251\n",
      "Convergence reached at 2 components\n",
      "Total time to run the procedure: 16.44 s\n",
      "\n",
      "1.8059803148309067e-05 2.9048903948825786e-05\n",
      "1 -2.8624112100302423\n",
      "2 -2.862410249864011\n",
      "3 -2.862410132900983\n",
      "Convergence reached at 3 components\n",
      "Total time to run the procedure: 21.92 s\n",
      "\n",
      "2.812213984910001e-05 3.2845460964469694e-05\n",
      "1 -2.878518011429081\n",
      "2 -2.878518006806226\n",
      "Convergence reached at 2 components\n",
      "Total time to run the procedure: 16.30 s\n",
      "\n",
      "5.839094972649309e-05 4.6759107205692177e-05\n",
      "1 -2.8851322600877167\n",
      "Convergence reached at 1 components\n",
      "Total time to run the procedure: 6.63 s\n",
      "\n",
      "0.00013762837057458232 9.210417854394223e-05\n",
      "1 -2.8664092479671814\n",
      "2 -2.8664080748915164\n",
      "Convergence reached at 2 components\n",
      "Total time to run the procedure: 16.11 s\n",
      "\n",
      "1.315096188694932e-05 2.142341626544993e-05\n",
      "1 -2.873172127279646\n",
      "2 -2.873171035094759\n",
      "3 -2.873170946763372\n",
      "Convergence reached at 3 components\n",
      "Total time to run the procedure: 21.20 s\n",
      "\n",
      "5.605896595674054e-05 5.446350222533656e-05\n",
      "1 -2.8891784556638354\n",
      "Convergence reached at 1 components\n",
      "Total time to run the procedure: 6.70 s\n",
      "\n",
      "0.0001570330797589197 7.889932652854572e-05\n"
     ]
    }
   ],
   "source": [
    "# let's look at the disentanglement among latents\n",
    "# we use a simple way to stop adding components, only for the sake of this argument\n",
    "\n",
    "MI_latents = np.zeros((6, 6, n_bootstrap))\n",
    "\n",
    "for latbin1 in range(6):\n",
    "    samples1 = all_latents[:, latbin1]\n",
    "    for latbin2 in range(6):\n",
    "        if latbin2 <= latbin1:\n",
    "            continue\n",
    "        samples2 = all_latents[:, latbin2]\n",
    "\n",
    "        X = np.stack((samples1, samples2), axis=0).T\n",
    "\n",
    "        # now we do this for many components, from 1 to 15\n",
    "        n_inits = 5\n",
    "        n_folds = 3\n",
    "        init_type = 'random_sklearn'\n",
    "        n_bootstrap = 100\n",
    "        MC_samples = 1e5\n",
    "        tol = 1e-5\n",
    "        reg_covar = 1e-15\n",
    "        components_range = 15\n",
    "        all_MI_estimates = np.zeros((components_range, n_bootstrap))\n",
    "\n",
    "        best_val = -np.inf\n",
    "\n",
    "        initial_time = time.time()\n",
    "        for n_components in range(1, components_range+1):\n",
    "            current_seed, current_val, _ = MI_procedure_diffconvergence(X, n_components=n_components, n_folds=n_folds, \n",
    "                                                               init_type=init_type, n_inits=n_inits, tol=tol, reg_covar=reg_covar)\n",
    "\n",
    "            # check if convergence has been reached based on val score\n",
    "            if current_val > best_val:\n",
    "                best_val = current_val\n",
    "                best_seed = current_seed\n",
    "                print(n_components, best_val)\n",
    "            else:\n",
    "                # if val score has not increased, then we should stop and calculate MI with the previous parameters\n",
    "                best_components = n_components-1\n",
    "                print(f'Convergence reached at {best_components} components') \n",
    "                w_init, m_init, c_init, p_init = initialize_parameters(X, best_seed, n_components=best_components, init_type=init_type)\n",
    "                MI_estimates = np.zeros(n_bootstrap)\n",
    "\n",
    "                # bootstrap available samples\n",
    "                for i in range(n_bootstrap):\n",
    "                    # we use i to change the seed so that the results will be fully reproducible\n",
    "                    rng = np.random.default_rng(i)\n",
    "                    X_bs = rng.choice(X, X.shape[0])\n",
    "                    gmm = my_GMM(n_components=best_components, reg_covar=reg_covar, \n",
    "                                tol=tol, max_iter=10000, \n",
    "                                random_state=best_seed, weights_init=w_init, \n",
    "                                means_init=m_init, precisions_init=p_init).fit(X_bs)\n",
    "\n",
    "                    # in case of \"warm start\", uncomment next line\n",
    "                    #w_init, m_init, c_init, p_init = gmm.weights_, gmm.means_, gmm.covariances_, gmm.precisions_\n",
    "\n",
    "                    current_MI_estimate = gmm.estimate_MI_MC(MC_samples=MC_samples)\n",
    "                    MI_estimates[i] = current_MI_estimate\n",
    "                break\n",
    "\n",
    "        print(f'Total time to run the procedure: {time.time()-initial_time:.2f} s')\n",
    "        print()\n",
    "        MI_latents[latbin1, latbin2] = MI_estimates\n",
    "        print(np.mean(MI_estimates), np.std(MI_estimates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "711d09ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 2.18540100e-05, 9.10545931e-06, 9.91516172e-05,\n",
       "         7.27562081e-06, 1.45954233e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.82936584e-05, 1.70746017e-05,\n",
       "         3.08572227e-04, 1.80598031e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.81221398e-05,\n",
       "         5.83909497e-05, 1.37628371e-04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         1.31509619e-05, 5.60589660e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 1.57033080e-04],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]]),\n",
       " array([[0.00000000e+00, 2.81883326e-05, 1.81643759e-05, 6.70291258e-05,\n",
       "         1.48212845e-05, 3.83137089e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 2.78885429e-05, 2.04134082e-05,\n",
       "         1.05144476e-04, 2.90489039e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.28454610e-05,\n",
       "         4.67591072e-05, 9.21041785e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.14234163e-05, 5.44635022e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 7.88993265e-05],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MI_latents, axis=2), np.std(MI_latents, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5ee0a716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6, 100)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('./MI_latents_latents.npy', MI_latents)\n",
    "MI_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821cf17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
