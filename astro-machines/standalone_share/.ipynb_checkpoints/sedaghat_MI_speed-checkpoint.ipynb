{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3143428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "from scipy import linalg\n",
    "import scipy.integrate as integrate\n",
    "from scipy.special import gamma\n",
    "import time\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.mixture._gaussian_mixture import _estimate_log_gaussian_prob, _compute_precision_cholesky, _estimate_gaussian_covariances_full\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import cluster\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pandas as pd\n",
    "from astropy.stats import sigma_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68cb9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_GMM(GMM):\n",
    "    \"\"\"\n",
    "    Custom GMM class based on the sklearn GMM class.\n",
    "    This allows to work with a GMM with fixed parameters, without fitting it.\n",
    "    It also allows to estimate MI with a certain number of MC samples.\n",
    "    The different initialisation types are dealt with separately.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 n_components=1,\n",
    "                 covariance_type=\"full\",\n",
    "                 tol=1e-5,\n",
    "                 reg_covar=1e-6,\n",
    "                 max_iter=100,\n",
    "                 n_init=1,\n",
    "                 init_params=\"random\",\n",
    "                 random_state=None,\n",
    "                 warm_start=False,\n",
    "                 verbose=0,\n",
    "                 verbose_interval=10,\n",
    "                 weights_init=None,\n",
    "                 means_init=None,\n",
    "                 precisions_init=None,\n",
    "                 covariances_init=None\n",
    "                 ):\n",
    "        super(my_GMM, self).__init__(n_components=n_components,\n",
    "                 covariance_type=covariance_type,\n",
    "                 tol=tol,\n",
    "                 reg_covar=reg_covar,\n",
    "                 max_iter=max_iter,\n",
    "                 n_init=n_init,\n",
    "                 init_params=init_params,\n",
    "                 random_state=random_state,\n",
    "                 warm_start=warm_start,\n",
    "                 verbose=verbose,\n",
    "                 verbose_interval=verbose_interval,\n",
    "                 weights_init=weights_init,\n",
    "                 means_init=means_init,\n",
    "                 precisions_init=precisions_init,\n",
    "                )\n",
    "\n",
    "        self.means_ = means_init\n",
    "        self.covariances_ = covariances_init\n",
    "        self.covariances_init = covariances_init\n",
    "        self.weights_ = weights_init\n",
    "        #self.random_state = random_state\n",
    "        #self.covariance_type = covariance_type\n",
    "        #self.precisions_cholesky_ = _compute_precision_cholesky(\n",
    "        #        self.covariances_, self.covariance_type\n",
    "        #    )\n",
    "\n",
    "\n",
    "    def score_samples(self, X):\n",
    "        \"\"\"Compute the log-likelihood of each sample.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : array, shape (n_samples,)\n",
    "            Log-likelihood of each sample in `X` under the current model.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self)\n",
    "        #X = self._validate_data(X, reset=False)\n",
    "\n",
    "        return logsumexp(self._estimate_weighted_log_prob(X), axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for the data samples in X using trained model.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : array, shape (n_samples,)\n",
    "            Component labels.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self)\n",
    "        #X = self._validate_data(X, reset=False)\n",
    "        return self._estimate_weighted_log_prob(X).argmax(axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Evaluate the components' density for each sample.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        Returns\n",
    "        -------\n",
    "        resp : array, shape (n_samples, n_components)\n",
    "            Density of each Gaussian component for each sample in X.\n",
    "        \"\"\"\n",
    "        # copied here to remove the fitting check\n",
    "        #check_is_fitted(self)\n",
    "        #X = self._validate_data(X, reset=False)\n",
    "        _, log_resp = self._estimate_log_prob_resp(X)\n",
    "        return np.exp(log_resp)\n",
    "\n",
    "    def sample(self, n_samples=1):\n",
    "        \"\"\"Generate random samples from the fitted Gaussian distribution.\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int, default=1\n",
    "            Number of samples to generate.\n",
    "        Returns\n",
    "        -------\n",
    "        X : array, shape (n_samples, n_features)\n",
    "            Randomly generated sample.\n",
    "        y : array, shape (nsamples,)\n",
    "            Component labels.\n",
    "        \"\"\"\n",
    "        # copied here to remove the fitting check\n",
    "        # check_is_fitted(self)\n",
    "\n",
    "        if n_samples < 1:\n",
    "            raise ValueError(\n",
    "                \"Invalid value for 'n_samples': %d . The sampling requires at \"\n",
    "                \"least one sample.\" % (self.n_components)\n",
    "            )\n",
    "\n",
    "        _, n_features = self.means_.shape\n",
    "        rng = check_random_state(self.random_state)\n",
    "        n_samples_comp = rng.multinomial(n_samples, self.weights_)\n",
    "\n",
    "        if self.covariance_type == \"full\":\n",
    "            X = np.vstack(\n",
    "                [\n",
    "                    rng.multivariate_normal(mean, covariance, int(sample))\n",
    "                    for (mean, covariance, sample) in zip(\n",
    "                        self.means_, self.covariances_, n_samples_comp\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        elif self.covariance_type == \"tied\":\n",
    "            X = np.vstack(\n",
    "                [\n",
    "                    rng.multivariate_normal(mean, self.covariances_, int(sample))\n",
    "                    for (mean, sample) in zip(self.means_, n_samples_comp)\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            X = np.vstack(\n",
    "                [\n",
    "                    mean + rng.randn(sample, n_features) * np.sqrt(covariance)\n",
    "                    for (mean, covariance, sample) in zip(\n",
    "                        self.means_, self.covariances_, n_samples_comp\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        y = np.concatenate(\n",
    "            [np.full(sample, j, dtype=int) for j, sample in enumerate(n_samples_comp)]\n",
    "        )\n",
    "\n",
    "        return (X, y)\n",
    "\n",
    "    def score_samples_marginal(self, X, index=0):\n",
    "        \"\"\"Compute the log-likelihood of each sample for the marginal model, indexed by either 0 (x) or 1 (y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        index: integer\n",
    "            Either 0 (marginal x) or 1 (marginal y).\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : array, shape (n_samples,)\n",
    "            Log-likelihood of each sample in `X` under the current model.\n",
    "        \"\"\"\n",
    "\n",
    "        oned_cholesky = np.sqrt(1/self.covariances_[:, index, index]).reshape(-1, 1, 1)\n",
    "        marginal_logprob = _estimate_log_gaussian_prob(\n",
    "            X, self.means_[:, index].reshape(-1, 1), oned_cholesky, self.covariance_type\n",
    "        )\n",
    "\n",
    "        return logsumexp(np.log(self.weights_) + marginal_logprob, axis=1)\n",
    "\n",
    "\n",
    "    def estimate_MI_MC(self, MC_samples=100):\n",
    "        \"\"\"\n",
    "        Compute the mutual information (MI) associated with a particular GMM model, using MC integration\n",
    "        Parameters\n",
    "        ----------\n",
    "        MC_samples : integer\n",
    "            Number of Monte Carlo samples to perform numerical integration of the MI integral.\n",
    "        Returns\n",
    "        ----------\n",
    "        MI : integer\n",
    "            The value of mutual information.\n",
    "        -------\n",
    "        \"\"\"\n",
    "        # sample MC samples\n",
    "        points, clusters = self.sample(MC_samples)\n",
    "        \n",
    "        # we first evaluate the log-likelihood for the joint probability\n",
    "        joint = self.score_samples(points)\n",
    "\n",
    "        # we then evaluate the marginals; index=0 corresponds to x, index=y corresponds to y\n",
    "        marginal_x = self.score_samples_marginal(points[:, :1], index=0)\n",
    "        marginal_y = self.score_samples_marginal(points[:, 1:], index=1)\n",
    "\n",
    "        MI = np.mean(joint - marginal_x - marginal_y)\n",
    "        return MI\n",
    "    \n",
    "    def fit_predict(self, X, y=None):\n",
    "        \"\"\"Estimate model parameters using X and predict the labels for X.\n",
    "        The method fits the model n_init times and sets the parameters with\n",
    "        which the model has the largest likelihood or lower bound. Within each\n",
    "        trial, the method iterates between E-step and M-step for `max_iter`\n",
    "        times until the change of likelihood or lower bound is less than\n",
    "        `tol`, otherwise, a :class:`~sklearn.exceptions.ConvergenceWarning` is\n",
    "        raised. After fitting, it predicts the most probable label for the\n",
    "        input data points.\n",
    "        .. versionadded:: 0.20\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            List of n_features-dimensional data points. Each row\n",
    "            corresponds to a single data point.\n",
    "        y : Ignored\n",
    "            Not used, present for API consistency by convention.\n",
    "        Returns\n",
    "        -------\n",
    "        labels : array, shape (n_samples,)\n",
    "            Component labels.\n",
    "        \"\"\"\n",
    "        X = self._validate_data(X, dtype=[np.float64, np.float32], ensure_min_samples=2)\n",
    "        if X.shape[0] < self.n_components:\n",
    "            raise ValueError(\n",
    "                \"Expected n_samples >= n_components \"\n",
    "                f\"but got n_components = {self.n_components}, \"\n",
    "                f\"n_samples = {X.shape[0]}\"\n",
    "            )\n",
    "        self._check_initial_parameters(X)\n",
    "\n",
    "        # if we enable warm_start, we will have a unique initialisation\n",
    "        do_init = not (self.warm_start and hasattr(self, \"converged_\"))\n",
    "        n_init = self.n_init if do_init else 1\n",
    "\n",
    "        max_lower_bound = -np.inf\n",
    "        self.converged_ = False\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "        n_samples, _ = X.shape\n",
    "        for init in range(n_init):\n",
    "            self._print_verbose_msg_init_beg(init)\n",
    "\n",
    "            if do_init:\n",
    "                self._initialize_parameters(X, random_state)\n",
    "\n",
    "            lower_bound = -np.inf if do_init else self.lower_bound_\n",
    "\n",
    "            for n_iter in range(1, self.max_iter + 1):\n",
    "                #if n_iter==179:\n",
    "                #    try:\n",
    "                #        #print(n_iter)\n",
    "                #        print(np.linalg.eig(self.covariances_[2]))\n",
    "                #        #print(self.means_[2])\n",
    "                #        #ind = np.argsort(log_resp[:, 2])[-5:]\n",
    "                #        #print(X[ind])\n",
    "                #        #print(log_resp[np.argmax(log_resp[:, 2])])\n",
    "                #        #plt.hist(log_resp[:, 4])\n",
    "                #    except:\n",
    "                #        pass\n",
    "\n",
    "                prev_lower_bound = lower_bound\n",
    "\n",
    "                log_prob_norm, log_resp = self._e_step(X)\n",
    "                self._m_step(X, log_resp)\n",
    "                lower_bound = self._compute_lower_bound(log_resp, log_prob_norm)\n",
    "\n",
    "                change = lower_bound - prev_lower_bound\n",
    "                self._print_verbose_msg_iter_end(n_iter, change)\n",
    "\n",
    "                if abs(change) < self.tol:\n",
    "                    self.converged_ = True\n",
    "                    break\n",
    "\n",
    "            self._print_verbose_msg_init_end(lower_bound)\n",
    "\n",
    "            if lower_bound > max_lower_bound or max_lower_bound == -np.inf:\n",
    "                max_lower_bound = lower_bound\n",
    "                best_params = self._get_parameters()\n",
    "                best_n_iter = n_iter\n",
    "\n",
    "        if not self.converged_:\n",
    "            warnings.warn(\n",
    "                \"Initialization %d did not converge. \"\n",
    "                \"Try different init parameters, \"\n",
    "                \"or increase max_iter, tol \"\n",
    "                \"or check for degenerate data.\" % (init + 1),\n",
    "                ConvergenceWarning,\n",
    "            )\n",
    "\n",
    "        self._set_parameters(best_params)\n",
    "        self.n_iter_ = best_n_iter\n",
    "        self.lower_bound_ = max_lower_bound\n",
    "\n",
    "        # Always do a final e-step to guarantee that the labels returned by\n",
    "        # fit_predict(X) are always consistent with fit(X).predict(X)\n",
    "        # for any value of max_iter and tol (and any random_state).\n",
    "        _, log_resp = self._e_step(X)\n",
    "\n",
    "        return log_resp.argmax(axis=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3dfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we also focus on initialising the GMM parameters\n",
    "# we provide four different initialisation types, which return weights, means and covs\n",
    "# these will go as input into the GMM class, so that we can ignore whatever happens there\n",
    "\n",
    "  \n",
    "def initialize_parameters(X, random_state, n_components=1, s=None, reg_covar=1e-6, init_type='random'):\n",
    "    \"\"\"Initialize the model parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of shape  (n_samples, n_features)\n",
    "    random_state : RandomState\n",
    "        A random number generator instance that controls the random seed used for the method chosen to initialize the parameters.\n",
    "    n_components: int\n",
    "        Number of components of the GMM to fit.\n",
    "    s : float\n",
    "        If set, sets component variances in the 'random' and 'minmax' cases. \n",
    "        If s is not given, it will be set such that the volume of all components\n",
    "        completely fills the space covered by data.\n",
    "    init_type : {'random', 'minmax', 'kmeans', 'random_sklearn', 'kmeans_sklearn'}, default='random'\n",
    "        The method used to initialize the weights, the means and the\n",
    "        precisions.\n",
    "        Must be one of:\n",
    "            'random': weights are set uniformly, covariances are proprtional to identity (with prefactor s^2). \n",
    "            For each mean, a data sample is selected at random, and a multivariant Gaussian with variance s^2 offset is added.\n",
    "            'minmax': same as above, but means are distributed randomly over the range that is covered by data.\n",
    "            'kmeans': k-means clustering run as in Algorithm 1 from Bloemer & Bujna (arXiv:1312.5946), as implemented by Melchior & Goulding (arXiv:1611.05806)\n",
    "             WARNING: The result of this call are not deterministic even if rng is set because scipy.cluster.vq.kmeans2 uses its own initialization. \n",
    "             TO DO: require scipy > 1.7, and include \"seed=random_state\" in the kmeans call\n",
    "            'kmeans_sklearn' : responsibilities are initialized using kmeans.\n",
    "            'random_sklearn' : responsibilities are initialized randomly.\n",
    "    reg_covar : float\n",
    "        The regularization added to the diagonal of the covariance matrices.\n",
    "    Returns\n",
    "    ----------\n",
    "    weights : array, shape (n_components, 1)\n",
    "        The initial weights of the GMM model.\n",
    "    means : array, shape (n_components, n_features)\n",
    "        The initial means of the GMM model.        \n",
    "    covariances : array, shape (n_components, n_features, n_features)\n",
    "        The initial covariance matrices of the GMM model.        \n",
    "    \"\"\"\n",
    "    n_samples, n_dim = X.shape\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "    if s is None and (init_type=='random' or init_type=='minmax'):\n",
    "        min_pos = X.min(axis=0)\n",
    "        max_pos = X.max(axis=0)\n",
    "        vol_data = np.prod(max_pos-min_pos)\n",
    "        s = (vol_data / n_components * gamma(n_dim*0.5 + 1))**(1/n_dim) / np.sqrt(np.pi)\n",
    "        print(f\"Scale s set to s={s:.2f}...\")\n",
    "\n",
    "    if init_type == \"random\":\n",
    "\n",
    "        weights = np.repeat(1/n_components, n_components)\n",
    "        # initialize components around data points with uncertainty s\n",
    "        refs = random_state.randint(0, n_samples, size=n_components)\n",
    "\n",
    "        means = X[refs] + random_state.multivariate_normal(np.zeros(n_dim), s**2 * np.eye(n_dim), size=n_components)\n",
    "        \n",
    "        covariances = np.repeat(s**2 * np.eye(n_dim)[np.newaxis, :, :], n_components, axis=0)\n",
    "\n",
    "    elif init_type == \"minmax\":\n",
    "\n",
    "        weights = np.repeat(1/n_components, n_components)\n",
    "\n",
    "        min_pos = X.min(axis=0)\n",
    "        max_pos = X.max(axis=0)\n",
    "        means = min_pos + (max_pos-min_pos)*random_state.rand(n_components, n_dim)\n",
    "        \n",
    "        covariances = np.repeat(s**2 * np.eye(n_dim)[np.newaxis, :, :], n_components, axis=0)\n",
    "\n",
    "    elif init_type == 'kmeans':\n",
    "        from scipy.cluster.vq import kmeans2\n",
    "        center, label = kmeans2(X, n_components)\n",
    "        weights = np.zeros(n_components)\n",
    "        means = np.zeros((n_components, n_dim))\n",
    "        covariances = np.zeros((n_components, n_dim, n_dim))\n",
    "\n",
    "        for k in range(n_components):\n",
    "            mask = (label == k)\n",
    "            weights[k] = mask.sum() / len(X)\n",
    "            means[k,:] = X[mask].mean(axis=0)\n",
    "            d_m = X[mask] - means[k,:] \n",
    "            # funny way of saying: for each point i, do the outer product\n",
    "            # of d_m with its transpose and sum over i\n",
    "            covariances[k,:,:] = (d_m[:, :, None] * d_m[:, None, :]).sum(axis=0) / len(X)\n",
    "\n",
    "    elif init_type == \"random_sklearn\":\n",
    "        resp = random_state.rand(n_samples, n_components)\n",
    "        resp /= resp.sum(axis=1)[:, np.newaxis]\n",
    "        nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "        \n",
    "        weights = nk/n_samples\n",
    "        means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "        covariances = _estimate_gaussian_covariances_full(resp, X, nk, means, reg_covar)\n",
    "\n",
    "    elif init_type == \"kmeans_sklearn\":\n",
    "        resp = np.zeros((n_samples, n_components))\n",
    "        label = (\n",
    "            cluster.KMeans(\n",
    "                n_clusters=n_components, n_init=1, random_state=random_state\n",
    "            )\n",
    "            .fit(X)\n",
    "            .labels_\n",
    "        )\n",
    "        resp[np.arange(n_samples), label] = 1\n",
    "        nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "        \n",
    "        weights = nk/n_samples\n",
    "        means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "        covariances = _estimate_gaussian_covariances_full(resp, X, nk, means, reg_covar)\n",
    "\n",
    "    else:\n",
    "        # TO DO: raise error instead of just priting it\n",
    "        print(\"Error: initalisation type not specified or not known; it should be one of 'random', 'minmax', 'kmeans', 'random_sklearn', 'kmeans_sklearn'\")\n",
    "        \n",
    "    precisions = np.empty_like(covariances)\n",
    "    for i in range(n_components):\n",
    "        precisions[i] = np.linalg.inv(covariances[i])\n",
    "        \n",
    "    return weights, means, covariances, precisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd4edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI_procedure_diffconvergence(X, n_components=1, n_folds=5, n_inits=5, init_type='random', reg_covar=1e-6, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Docstring TO DO\n",
    "    \"\"\"\n",
    "    initial_time = time.time()\n",
    "    # this will be used to store mean validation log-likelihood \n",
    "    val_scores_seeds = np.zeros(n_inits)\n",
    "    train_scores_seeds = np.zeros(n_inits)\n",
    "\n",
    "    # prepare the folds; note the splitting will be the same for all initialisations\n",
    "    # the random seed is fixed here, but results should be independent of the exact split\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # fix the random seed first\n",
    "    for r in range(n_inits):\n",
    "\n",
    "        w_init, m_init, c_init, p_init = initialize_parameters(X, r, n_components=n_components, init_type=init_type)\n",
    "        validation_scores = []\n",
    "        training_scores = []\n",
    "        \n",
    "        for train_indices, valid_indices in kf.split(X):\n",
    "            X_training = X[train_indices]\n",
    "            X_validation = X[valid_indices]\n",
    "            \n",
    "            fitted_gmm = my_GMM(n_components=n_components, reg_covar=reg_covar, \n",
    "                            tol=tol, max_iter=10000, \n",
    "                            random_state=r, weights_init=w_init, \n",
    "                            means_init=m_init, precisions_init=p_init).fit(X_training)\n",
    "\n",
    "            # we take the mean logL per sample, since folds might have slightly different sizes\n",
    "            val_score = fitted_gmm.score_samples(X_validation).mean()\n",
    "            train_score = fitted_gmm.score_samples(X_training).mean()\n",
    "\n",
    "            #print(val_score)\n",
    "            validation_scores.append(np.copy(val_score))\n",
    "            training_scores.append(np.copy(train_score))\n",
    "\n",
    "\n",
    "        # take mean of current seed's val scores\n",
    "        val_scores_seeds[r] = np.mean(validation_scores)\n",
    "        train_scores_seeds[r] = np.mean(training_scores)\n",
    "\n",
    "        #print()\n",
    "        \n",
    "    # select seed with highest val score\n",
    "    best_seed = np.argmax(val_scores_seeds)\n",
    "    best_val_score = np.max(val_scores_seeds)\n",
    "    best_train_score = np.max(train_scores_seeds)\n",
    "    \n",
    "    return best_seed, best_val_score, best_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466d301",
   "metadata": {},
   "source": [
    "### Let's look at MI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58c9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_file = 'encoded_harps_unique_128d_e182_i1500000.npy'\n",
    "codes = pd.DataFrame(np.load(codes_file))\n",
    "\n",
    "labels = pd.read_csv('harps_metadata_and_labels.csv')\n",
    "\n",
    "#--- If looking at the 'unique' subset, drop unnecessary rows\n",
    "if \"unique\" in codes_file:\n",
    "    labels.dropna(subset=['unique_subset'],inplace=True)\n",
    "\n",
    "#--- and reindex the codes dataframe accordingly\n",
    "codes.loc[:,'dp_id'] = labels['dp_id'].values\n",
    "labels = labels.set_index('dp_id')\n",
    "codes = codes.set_index('dp_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7231d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n",
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "significant_dimensions = [ 11,  19,  58,  85,  99, 124]\n",
    "stellar_params = ['radvel','Teff','Mass','[M/H]','airmass','snr','vsini']\n",
    "MIs = np.zeros([len(stellar_params), \\\n",
    "                    len(significant_dimensions)])\n",
    "codes_sig = codes.iloc[:, significant_dimensions]\n",
    "                \n",
    "for li,stellar_param in enumerate(stellar_params):        \n",
    "    label = labels.loc[:,stellar_param].values\n",
    "    \n",
    "    ind_mask = ~np.isnan(label)\n",
    "    label_ = sigma_clip(label,sigma=5,masked=True)\n",
    "\n",
    "    ind_mask = ind_mask & (~label_.mask)\n",
    "    label_ = label_.data[ind_mask]      \n",
    "    for i in range(0,codes_sig.shape[1]):                          \n",
    "        codes_ = codes_sig.iloc[:,i].values\n",
    "        codes_ = codes_[ind_mask]\n",
    "        \n",
    "        MIs[li,i] = mutual_info_regression(codes_.reshape(-1, 1),label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e074fa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD5CAYAAACEcub7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABj/0lEQVR4nO2ddVhU6fuH74GxAwwYFRADC2yxXUBdEQu7V9da1LX3a6ytu3Zjy9rdHdjYiqhrK9iASpgISsyc3x/gyEgNMjPA/t7b61wXZ85zzvnM43Oeec+bMkmSJAQCgUBgEIzSW4BAIBD8f0IkXYFAIDAgIukKBAKBARFJVyAQCAyISLoCgUBgQETSFQgEAgMi1/cNfJ5+1PctdE6ZwrnTW0KqyIx9/mTpLeAHMDLKXKoL1hyU3hJSzecbi9N8jRxVBhr0fqlF70lXIBAIDIosY7/Ai6QrEAj+W8gy9htJskl30KBByJL5AgsXLtS5IIFAIEgTmbmka29vbygdAoFAoBsyc0n3119/1diPiIggZ86cehUkEAgEacLIOL0VJItW5fBLly5ha2tL2bJlAbh58ya///67XoUJBALBDyEz0n5LB7S669ChQzl69CgFChQAoFKlSpw9e1avwgQCgeCHkMm039IBrXsvWFlZaewbG2fsIrxAIPh/SmZuSPuKlZUVFy9eRCaTER0djbu7O+XKldO3NoFAIEg9GbwhTaufhOXLl7NkyRICAwOxsLDg33//ZcmSJfrWJhAIBKkng9fpalXSlSSJTZs26VtLotz0uciGZXNRqVQ4ubTEtWOPRO28z5/Cfcoo/l64jhKlbQ2i7eKFc8yZOQ2VSkWr1u3o0fs3jeNRUVFMHDuK+/fvYWJiyvRZ8yhiYcHLwEDat26GdbHiAJSvUIkx4ydpnDts8O8EBvizffcBneqdG6e3ZTJ6H8TpnRanF8DP9yHT/57Ip0+fMDIyYt3mHWTLlo2lixZw6MA+wj5+5OzlazrTGl+zrn3s1rs7oSEhZM+eHYDFy1aSP669QhdcOH+OOTOnolSqaN2mHT37uCXQPH7MKO7fu4upqSkzZs+jiIUld27fYsrkCUDsM9f394E0aNiIyMhI+vT4haioKJRKJQ0bOdN/wGCd6U2K5RO70sShPCFvw7BvPy3B8WHdG9KxaXUA5MZGlC1eCKsGf/LuY4TetSVLBu+9oFXSrVu3LsWKFaNjx460bdsWU1NTPcuKRaVUsnbJLEZPW0z+ggrGD/6VqrUcsLQuoWH3OSIcz71bKVm2vEF0ASiVSmZO+5slK1ahUCjo3qUDDk71KVHSRm2zb89O8uQ1Ye/Boxw9cohFC+YwffZ8ACwsrdi8fU+i1z514pjOu+YplUpmTfubxXF6f01Cb968Juw5eJRj8fTGxMQwYcxIJk+dSekyZXn//h1yeWzo/OToRIdOXWjToolO9X7VrC8fT5k+G1s73ceLUqlk5tS/WOqxGkUhBb90ao9j/QYamvfu3knevHnZf/gYR48cwn3+XGbOmU9Jm1Js3LoTuVxOSEgwndq1wsGxPlmzZmXFqrXkzJmL6Ohoev/albr1HKhYqbLO9cdnw4HLLN92hpV/d0/0+Pz1J5m//iQATR3KM6hr/fRPuJDh63S1Uufr68uUKVO4e/cuVatWpXnz5mzcuFHf2nj88C6KwlaYF7ZEniULtRwbce3SmQR2O9cvp0X77mTNklXvmr5y984trKyKYmlpRZYsWXF2acoZr1MaNmdOn6K5a0sAGjZqjLf3ZVJaki4iIpxNG9bR+7d+etXbKBG9Z0+folmc3gaNGnM1Tu+VSxewKVWG0mViuwyamuZTN6RWqFiZgmbmOtWalGZd+Vif3Ll9C8uiRbG0itXcuElTvE6f1LDxOn2S5q6tgFjNV69cQpIkcuTIof4xi4qMQhY3LZBMJiNnzlwAxMTEEBMTk+xIUV1x4fpj3n7QLol2cLFnu6fu33R+CCOZ9lt6yNPWsEaNGsybNw9vb2/y58+fYOCEPnj7JoQCZgr1fv6CCt69CdGweer3gDchQVSpWU/veuITHByMolAh9b65uYLgoKDvbIJQFCoMgFwuJ3fuPHx4/x6Al4GBdOnQBrde3bhx3Ud9zrIlC/mlew+yZ8+hU70h3+lVmCsI0VLv8+fPkMlgUL8+/NKxDevXrNSptqTQl48BJk8YQ5cOrVm5YqlOk3RIcBCF4vQAmCsKJdAcEhystvmq+X2c5tu3btKuVXM6tHFlzIRJ6iSsVCrp1K4VPzvWpWatOlSoWElnmtNKjuxZaFSnHHtP/pveUmLJ4HW6Wt3148ePrFu3jiZNmlCnTh0KFy6Mt7e3vrWliEqlYpPHfLr+NjS9paSKgmZmHDx6ks3bdzNs+J+M+3MEnz594uGD+wT4+1O/YaP0lqiBUqnk5o3r/D19NivXbsLr1Am8r1xKb1nJkpSPAaZMm822Xfv5Z81Gbly/xqGD+9JZ7TcqVKzEzr0H2bB1B2tWehAZGQnEdtHcunMvnie8uHvnFo/8fNNZ6TeaOVTg0r9PMkbVAui0n26vXr0wNzenfPmkq6K8vLyoXLkydnZ2ODo6pnhNrZJupUqV+Pfff5kwYQK+vr7MnDmTatWqJWnv4eGBvb099vb27N6yRptbJEr+Ama8CflWSngbGkS+Ambq/S+fI/B//pgpI/sxpLsrjx7cYe6k//HE994P31NbzM3NCXr9Wr0fHByEuULxnY2CoNevgNjXwk+fwjAxNSVr1qyYmuYDoJytHRZWVrx4/ozbt/7l/r07tGjSkD49uvLi+XPceiden5ZazL7TGxQchJmWehXmCqpUs8c0Xz6y58hBnXoOPLyfOX0MqK+RK1cuXJo25+7t2zrTbGau4HWcHoDgoNcJNJuZm6ttvmr+vp2kRImS5MiZk8ePNJNrnrx5sa9ek4sXzulMc1pp37gaOzJK1QLENqRpu6VAjx498PT0TPL4+/fv+f3339m/fz93795lx44dKcvT5js8efKE+fPnU7t2bW3McXNzw8fHBx8fH9p07qnVOYlRoowtr1++IPh1IDHR0Vw+c5xqtRzUx3Pmys2K7SdwX78f9/X7sSlbnv9NmmuQ3gu2dhXwf/GcwIAAoqOjOOZ5GAfH+ho2Dk71Obg/thR18vhRqteohUwm493btyiVSgACAvzxf/4cC0tL2nXojOeJsxw4cpKVazdR1Noaj1Xrdab3RTy9xxPR+5NTfQ7F6T0VT2+tuvV45OfLl8+fiYmJ4fq1qxQvUVInulLSrGsfx8TE8P7dOwBioqM5d9aLkjaldKbZrnwF/J9/03z0yGEcnRpo2Dg6NeDg/r0JNAcGBBATEwPAy5eBPHv6hMJFLHn39i1hH2MXA/jy5QuXL1+kWHHNxuT0Im/u7NSrZsMBr1vpLeUbOqxecHBwIH/+/Eke37x5M23atKFo0aJAbEEhJZLtvdCiRYtkK+z379+f4g3SgrGxnB6/j2Tm2MGoVEocnV2xLFaSneuXU7xUOarVTrkory/kcjkjRo9jUP8+KFUqXFu1oaRNKZYvWUg5u/I4OjWgZet2TBg7ilbNG5M3rwnTZs0F4Pp1H1YsWYg8SxZkMhmjx03CxMRU73pHjh7H4BT0Thw7itZxeqfG6c2b14Qu3XrQvUt7ZDIZdX9yoJ6DEwAL58/m6OFDfPnymWaNnGjZph1u/bWfuT8lzbr28eeICAb270NMTAwqpZIaterQum17nej9qnnUmPEM6NcblVKFa+u2lLQpxbLFC7G1K49j/Qa0atOO8aNH4trUGRMTE6bPmgfAjRvXWLvqH+RyOUZGRoweO5F8+fLh+/AhE8f9iVKpRJIkGjm7JPjx0Qfrpvfgp2qlKGiam0eef/P38sNkkceWDlfuPA+Aa/1KnLz8gIgvUXrXozUGHBzh6+tLdHQ0Tk5OhIWFMWTIELp3T/7tVCYl04pw5kxsT4Hdu3fz+vVrfvnlFwC2bNmCQqFg/vz5KYoSy/XoH7Fcj2EQy/XoH50s1+MyT2tb9za58fDwUO+7ubnh5qbZr/rZs2c0b96cO3fuJDh/4MCB+Pj4cPLkST5//kzt2rU5dOgQpUuXTvKeyZZ0v1YK/+9//8PH51vrb4sWLcRcuwKBIGOSipJuYkk2NVhaWlKgQAFy5cpFrly5cHBw4ObNm8kmXa3qdMPDw3ny5Il6/+nTp4SHh/+wUIFAINAbBuwy1rJlS86fP09MTAwRERFcuXIlxXlptBqRNn/+fJycnChRogSSJPH8+XNWrFiRZsECgUCgc3Q4DLhz5854eXkRGhqKpaUlkydPJjo6GoB+/fpRrlw5XFxcqFixIkZGRvTp0yfZ7mWQQp1ufCIjI3nw4AEAZcuWJVu2bFqJFnW6+kfU6RoGUaerf3RSp9tiqfb3O2D4xRi0nk/Xz8+Phw8f8uXLF27evAmQYiudQCAQGJwMPrWjVkl38uTJeHl5ce/ePZo2bcqRI0eoV6+eSLoCgSDj8V+Y8Gbnzp2cPHmSQoUKsWbNGm7evMmHDx/0rU0gEAhSz39huZ7s2bNjZGSEXC7n48ePmJub4+/vr29tAoFAkHoyeEk3xaQrSRIVK1bk/fv3/Pbbb1SrVo3cuXNrPSRYIBAIDInMKJMnXZlMhre3N6ampvTr1w8XFxc+fvxIxYoVDaFPIBAIUoUh5hpOC1r9JFStWpWrV68CUKxYMZFwBQJBxkWWii0d0KpO98qVK2zatAlra2ty5cqFJEnIZDJu3Up5ZiGFiXb9eTMSq64+T28JqaJ+sYLpLSHVtJh1Or0lpJqLfzVObwmp4vrhmektIV3I6CVdrZLu0aNH9a1DIBAIdMJ/IulaW1vrW4dAIBDoBKPM3pAmEAgEmYqMXdAVSVcgEPy3+E9ULwgEAkFmQSRdgUAgMCAi6QoEAoEByehJN8lmvm7dugHg7u5uMDECgUCQVmRGMq239CDJpHvt2jVevnzJ6tWreffuHW/fvtXYBAKBICMik8m03lKiV69emJubp7gaxNWrV5HL5ezcuTPFayZZvdCvXz8aNmzIkydPqFatGvEXmJDJZBprpgkEAkFGQZfVCz169GDgwIHJzh2uVCoZNWoUzs7OWl0zyaTbokULBg8eTP/+/Vm2bFnq1aYB70vnWbpgJiqliiaubejcvbfG8Vs3fFi6YBZPHvsx7q+ZODT49mX/WTKfKxfPAtC1Z1/q/+xiEM0v7vhwfssyJJWKcj+5ULVpR43jF7auIPBh7IobMVGRfP74nt6LdhH64jFnNy4i6ksEMpkR1Zp1xqaGo971/ut9kTVL56BSqWjYpBWtOvfQOH7swE6O7tuBkbEx2bPnoO8fY7G0LkHw65cM69WeIlaxA2ZKlSuP29Axetf7PbO7VKZheQVvwiJpNN0rwfFGFQoxvFlZVJKEUiUxedcdrj4x/Bua96XzLJk/E5VKRdMkYnnJ/LhY/nsmjvFi2WPxt1j+pWdf6jcyTCx/5fqVC6xcPAeVUkmjZq1p27WnxnHPfTs5vHc7RkZG5MiRk9+Hj8OqWAmDakwUHdYaODg48OzZs2RtFi1aRNu2bdXz06REkkm3Xbt2XLt2DV9f31SJTCtKpZJFc6cx090DM3MFA3p1ps5PTlgXL6m2MS9UmJHjp7B901qNcy9fOIvfw/usWLeDqOgo/jegNzVq1yNXLv2ueaZSKTm3aQkt/phGrnwF2TVlMMUq1yJ/kW8j+ep26qv++/bJfYS+eAyAPGs2GvQeganCgvD3b9j590CsylcjW079aVYplaxaNJNxM5dQwEzB6AHdsa/jgKX1twemXgMXnFu0A8Dn4hnWLZvP2BmLAChUxILZKzbrTZ827LjygnVnnzK/W5VEj194GMLx268BKFskL0t7VaPBFMPO96BUKlk4ZxqzFsbG8u89O1P7JyeKxY9lRWws79i8VuPcr7HssT4uln/vTY06+o/l+NpXuM9k8pylFDBTMKLfL9So66iRVB1+dsGlZWyMeF84w+olc5k4e4lB9CWHIRvSAgMD2bNnD6dPn0570lWpVEybNg1fX1/mzZuX4Pgff/zx40qT4eG9OxSxLEoRC0sAnH524cLZ0xpJt1BhCyDhcL/nTx9TsXI1jOVycsjllChZmquXLuD0s34nKgl++hAT88LkNSsMgE0NR579e0kj6cbHz9uL6q6xDZWmhSzVn+cyLUCOPKZ8Dvug16T76OFdChWxQlEk9t51nJy5euGMRtLNGe/h/vLlc4ZrEfZ+/BbL/DmSPB4RpVT/nTOrMdotv6pbHty7g0W8WK7fyIWLZ09rJN1CRWJjWSZLJJarfIvl4jaGieWv+D24Q2ELSwrFxUi9Bo25csFLI+lm1BhJjQ4PDw88PDzU+25ubri5uWl9/tChQ5k5c2aqhh4nmXS3bt3K3r17iYmJISwsTOsLppXQkCDMzRXqfTNzBQ/u3tbq3JKlyrBh1XLadelO5Jcv/HvdG+vi+n/dCX/3hlz5zNT7ufIVJPjJw0Rtw94EERb6GotylRIcC3ryEGVMDCZxyVtfvA0NpkA8HxcwM8fvwZ0Edp77tnNo5yZiYmKYMPtbFVPw65eM7NuFHLly06lnf8pVSLy0md40rliIUa7lKJg7Gz2WXzH4/UNDgjD7LpbvpyKW169cTvu4WL55zRtrA766vw0JoaBZIfV+ATNz/O4ljJHDe7axb8cmYqKj+Xv+CoPpS47UJMDUJtnv8fHxoVOnTgCEhoZy+PBh5HI5rVq1SvKcJJNumTJlGDVqFBUrVqRJkyY/LMqQ2Nesw8P7dxji1h0T03zYlq+U4Sa/eOR9hhLVfsLIyFjj8/D3bzi5ahYNeg3PMDPfu7TsgEvLDpw/6cmuTasYOGoy+fIXZOmmg+QxMeWJ731mTxzO3JXbNEo9GYWjt15z9NZrapTMz/DmZemy+FJ6S9Ia+5p1eHjvDoN/+xbLxsYZIy7i07R1R5q27siZE0fYsWElQ0b/ld6SDDr3wtOnT9V/9+jRg+bNmyebcEGLScyrVq1K79691Yn33r17rFq1KtlzPDw8sLe3x97enk3rVmoh/RsFzRQEBwep90OCgyhgZq71+V17uLFi/Q5mLfRAkiQsixZL1f1/hFz5ChD+LkS9H/4ulFz5CiRq+8j7DKVqOGl8FvU5nMMLJ1CzdQ8KlSynT6kA5C9ozpt4Pn4TEkz+Akn7uE59Z65e8AIgS9as5DExBaBE6XIoClvwKuCFPuWmGe/HbylaICf5cmU16H0LmikI+S6WC6Ymlnu64bFhB7MXeSBhmFj+Sn4zM0JDXqv334QEkz8Z7T81aMyV814GUJYyuuwy1rlzZ2rXrs3Dhw+xtLRk1apVLF++nOXLl/+wvhSTbo8ePWjcuDEvX74EoHTp0ixYsCDZc9zc3PDx8cHHx4euv/ZJlaAy5ewI9H/Oq5cBREdH43XCkzo/OWl1rlKp5MOH9wA8eeTL08e+2NfQ/1pu5sXK8D7oJR9DXqOMieaR9xmKVaqVwO7dK38iI8JQxEusyphoPJf8TenaP1PS/ie9awUoWcaWV4H+BL8KJCY6motex7Cv46BhEz+RXr9ynsKWRQH4+P4dKmVsfWnQywBeBfqjiKtjz0hYF8yl/ru8pQlZ5Ua8C48yqIay38Xy6eM/FsuP/Xx58sgwsfyVUmXseBXgT9CrQKKjozl/6ig16mj2qnkZL0Z8Lp+jsIWVwfQlhy6T7pYtW3j16hXR0dEEBATQu3dv+vXrR79+/RLYrl27lnbt2qV4zSSrF2JiYpDL5YSGhtKhQwemT58ee4JcjrGxcVKnpRljuZxB/xvDn0P7o1IpcWneimIlbFjrsYTS5Wyp81N9Hty7w6Q/h/Ip7COXzp9h3cplrNq8B2VMDMP69QAgZ65c/DlxOsZy/Y90NjI25qcuv3NwwVgklYqydZ3Jb1EM773rMStWiuKVYx+WR95e2FR30vjPfnz1LK/8bvMl/CMPLx4HoEHP/1GwaMlE76ULjI3l9Bo0gql/DkKlUlLfxRWrYiXZtnY5JUuXw76OI577tnP7ujfGcjm5c+dhwMhJANy7dZ3t61ZgLJdjJJPx29DR5M5rojetSbGoR1Vq2xQkX+6sXPmrEfMOPySLcaxfN154TtPKhWlbw5JopcSXaCUD1lwzuEZjuZxBw8cwakhsLDeJi+U1HksoU9aWOg6xsTxxVLxY/mcZq7fExvLQvj0AyJUrF6MnGSaW42v/bcgoJo8YgFKl4ucmrhQtXpLNq5dhU8aWGnUdObxnGzevXcHYWE7uPHkzRtUCGX8YsEySEm/XrVq1KtevX8fJyYldu3bRqFEjrl+/zuXLlxk1ahRnzpzR6gb+byN1KtgQ7Lr7Mr0lpAqxXI9hyGzL9YR9iUlvCammXOFcKRulQNFB+7W2fbHINc33Sy1J/nR+zcXz5s3D1dWVx48fU7duXUJCQrQa6iYQCATpQUYv6SaZdENCQtT9c1u3bk3Tpk2RJIls2bJx4sQJsSKwQCDIkGTapKtUKvn06RPf1z5EREToXZRAIBD8KJk26RYuXJgJEyYYUotAIBCknYydc1Ou0xUIBILMRKYt6Z48edKQOgQCgUAnGKXT5OTakmTSzZ8/vyF1CAQCgU7ItCVdgUAgyIxk8Jwrkq5AIPhvIUq6AoFAYEAyeM4VSVcgEPy3yLQNaf+fUWWy7nJKZebSC2As19+kSfoiRpXJ/JzJ5OoKkXQFAoHAgIjqBYFAIDAgGb0hLeOt/yEQCARpQJeTmPfq1Qtzc3PKly+f6PFNmzZRsWJFKlSoQJ06dbh582aK1xRJVyAQ/KeQybTfUqJHjx54enomebx48eKcOXOG27dvM378eK0WuRTVCwKB4D+FLhvSHBwcePbsWZLH69Spo/67Vq1aBAQEpHhNrUq6O3bsUC/DPmXKFNq0acP169e1OVUgEAgMii6rF1LDqlWrtFo5Xauk+/fff5MnTx7Onz/PiRMn6N27N/3790+zSIFAINA1qaleiL9yub29PR4eHj90z9OnT7Nq1SpmzpyZoq1W1QtfF6I8dOgQbm5uNGvWjHHjxv2QOIFAINAnqSnBurm5aVUPmxy3bt2iT58+HDlyhAIFCqRor1VJ18LCgr59+7Jt2zaaNm1KZGQkKpUqTUIFAoFAH+iyIS0lXrx4QZs2bdiwYQOlS5fW6hytSrrbt2/H09OT4cOHY2pqyqtXr5g9e3aaxAoEAoE+0GVdbefOnfHy8iI0NBRLS0smT55MdHQ0AP369eOvv/7izZs3/P777wDI5XJ8fHySvaZWSffVq1c0a9aMbNmy4eXlxa1bt+jevXsav452eF86z9IFM1EpVTRxbUPn7r01ju/csp7D+3djbGyMqWk+ho/9C0XhIgbRFp8Xd3y4uHU5kkpF2Z9cqNKkg8bxi9tW8PLBLQBioiL5HPaengt3EvYmiGNL/0ZSSaiUMZRv4IqtUzO96/336kXWL5+LSqmifpOWtOzYQ+P48YO7OH5gB0ZGRmTPkZM+Q8ZgaV2CmJgYPOZP4dmjByiVSn76uSmtOvXUu97vmdmpIg1szXnzKQqXWWcTHG9UXsEfTUqjkiRiVBJ/77mHz9N3Btd59fIFli+YiVKpokmL1nT8Ln53bVmP54E9GBsbY2Kajz/GTEZRuAiPfR+waPZUwiM+YWxkTKdf++D0s4tBtV/3vsDKxXNQKZU0ataatl00/5899+/k8N7tGBkZkSNHTn7/3zisipUwqMbE0GXvhS1btiR7fOXKlaxcuTJV19Qq6bZt2xYfHx8ePXqEm5sbLVu2pEuXLhw+fDhVN0stSqWSRXOnMdPdAzNzBQN6dabOT05YFy+ptrEpXZala7aQPXsO9u/ehseS+YyfYthSuEql5MLmJTQbNo1c+Qqye+oQilWqSb4i1mqbOh37qv++c3Ifof6PAchpkp9Wf87DOEtWor98ZvukflhXrkUu05Trhn5Yr1LJmiWzGDN9MQUKKhg76Feq1XLA0vrbA1O3fmMaNW8LgM+lM2xYMZ/R0xZx5ewJYqKjmLViK5FfvjDcrQN1nRpjVsiwP3S7vANYf/4Zc7tUTvT4Bd9Qjt8JAqBs4Tws/rUqP884Y0CFsfG7ZM40pruvoKC5gkG9u1Dru/gtWbosi1ZvJnv2HBzYvZ2VS+cz9u/ZZMuenRETpmBhZc2bkGAG9uqMfc065M6T12DaV7jPZPLspRQwUzCi3y/UqOOokVQdGrrg4toOAO8LZ1i9dC4TZy0xiL7kyOAD0rSr0zUyMkIul7N7924GDRrE7NmzefXqlb618fDeHYpYFqWIhSVZsmTB6WcXLpw9rWFTuVoNsmfPAUA5u4qEBgfpXdf3BD/1Ja9ZEfKaFcZYngWb6o48+/dykvaPrp7BpoYTAMbyLBhnyQqAMiYaDDDZzqOHdylUxApFYUvkWbJQ26kRPpc0E1LOXLnVf0d++fLtlU0mI/LLZ5TKGKKiviCXZyFHzlx61/w93k/e8j48OsnjEVFK9d85shqny9wvsfFrReF48XvpnJeGjWb8ViA0OBgAy6LFsLCK/dEuYGaOSb78fHhvuJK634M7FC5iSaEisdrrNWjMlQua2uPHyJcvnzPM8Nv06jKmLVqVdLNkycKWLVtYv349Bw4cAFDXa+iT0JAgzM0V6n0zcwUP7t5O0t7zwB6q166nd13fE/E+lNz5zdT7ufIVJPjpw0Rtw94EERb6miJlK6k/+/Q2hCMLJ/Ax5BU12/XWaykX4N2bEAqYffNrgYIKHj24k8Du2P7tHNq9mZjoaMbNWgZAzZ8acu3SGfp3bkLUly906zeM3HlN9Kr3R3GuoGBks7IUyJ2VXv9cNfj934QEY6YopN4vaGbOg3vJxO/BPVSvVTfB5w/u3SYmOprCFlZ60ZkYb0NDKGj+TXsBM3P87ieMkcN7trFv5yZioqP5e94Kg+lLjgyS+5NEq5LumjVruHTpEmPHjqV48eI8ffqUbt266VtbqjjheZCHD+7SoWuP9JaSLI+9z1C8aj2MjL5NbZg7vxntJy2j09RV+F48QcRHw9c9Joazawfc1+6lS+9B7Nm8GoDHD+9iZGTE0s1HcF+/j0O7NhH0KuVROOnBsdtB/DzjDH1XX+OPpmXSW06ynPQ8iN+De7T7Ln7fhIYw+6+x/G/sXxgZZbxR+01bd2TFpv10dxvMjg2pq9vUFxm9pKvV/6KtrS0LFy6kc+fOQOx441GjRiVpH7/D8aZ1P/4fUdBMQXC86oKQ4CAKmJknsLvmfZnNa//h71kLyZo16w/f70fJaVqQT29D1Pvh70KTLK3Gr1r4nlymBchvYc1rv4QlCl2Sr4AZb0K++fVNaBD5CpolaV/byRmfi14AXDjtSSX7OsjlckxM81PathJPfO/rVW9a8X7ylqIFcpIvVxaD3reAmTkhQa/V+6EhwRSM94bxletXL7Nl3Uomz3TXiN/w8E9MGD6QHm6DKFe+okE0fyV/QTNCg79pfxMSTP6CCZ+9r/yUSPVDevGfSLp+fn60a9cOW1tbSpQood6Sws3NDR8fH3x8fOj6a58fFlemnB2B/s959TKA6OhovE54UucnJ01tD++zYNZf/DV7Ifny6/e1PCnMi5XmQ/BLPoa8RhkTzaOrZ7CuVCuB3btX/kRGfEJRspz6s09vQ4iJigQgMjyM1373MFFY6lVvyTK2vA58QfDrQGKio7nkdZxqtRw0bF4FvlD/fcP7PIUsigJQ0KwQd/+NfVX/8uUzjx7coYhVMb3q/RGsC+ZU/21nmZesxka8S6YOWB+UKWdHYMALXseL31r1HDVsHj28z8KZfzN5ljum8eI3Ojqav/4cRsMmLfipQSOD6gYoVdaOV4H+BL0KJDo6mvOnjlKjjqb2lwHfYsTn8jmDVn8kh5GRTOstPdCqTrdnz55MnjyZYcOGcfr0adasWWOQwRHGcjmD/jeGP4f2R6VS4tK8FcVK2LDWYwmly9lS56f6eCyex+eICP4eOxwAc0Uh/p69SO/a4mNkbEy9Lv05vGAckqSkTF1n8ltYc3XfesysS1OscmwCfnz1DDbVHTV+Yd+/9ufS9n9iK6IkiYqN21DAsrhe9Roby+kxYCTTxwxGpVLi5OyKVbGS7Fi3nOKly2Ff25Fj+7dz+7o3crmcXLnz0n/4RACcXduzfO5fDP8ttkuco3MLrEuU0qvexHDvVplaNgXIlysrFyc2YIGnH3LjWL9uvvgCl4qFaFPdkhilii/RKgatN/xcIcZyOQP+GM2YYf1RKVU4x8Xvun+WULqsHbV/cuKfJfP5/DmCKeNGALHxO3nWQs6ePMrtf6/z8eMHjh/eD8DwsX9RsnRZw2g3lvPb4FFMHjkApUrFz01cKVq8JJtXL8OmjC016jpyeM82bl67grFcTu48eRny518G0ZYSGb1OVyZJKTeXV6tWjWvXrlGhQgVu376t8VlK+L+NTLtKA7PjTmB6S0gVTkULpreEVNPW/Vx6S0g1p8c1TG8JqeJzpDJlowxGuSJp7wnTYOElrW1PDa6d5vulFq1KutmyZUOlUlGqVCkWL16MhYUFnz590rc2gUAgSDUZvaSrVZ2uu7s7ERERLFy4kGvXrrFhwwbWrVunb20CgUCQaoxkMq239ECrkm716tUByJ07N2vWrNGrIIFAIEgLmXo1YFdX12RP3r9/v07FCAQCQVrJ4Dk3+aR76dIlrKys6Ny5MzVr1kSLNjeBQCBIVzLKcOSkSDbpvn79muPHj7NlyxY2b95Ms2bN6Ny5M3Z2dobSJxAIBKkig+fc5BvSjI2NcXFxYd26dVy+fBkbGxucnJxYvHixofQJBAJBqpCl4l96kGJDWmRkJIcOHWLLli08e/aMwYMH07p1a0NoEwgEglST0et0ky3pdu/endq1a3P9+nUmTpzI1atXGT9+PBYWFobSJxAIBKlCl8OAe/Xqhbm5OeXLl0/0uCRJDB48GBsbGypWrKjVKunJJt2NGzfi5+eHu7s7derUIW/evOTNm5c8efKQN69hJlMWCASC1KDLfro9evTA09MzyeNHjhzBz88PPz8/PDw8tFolPdnqBbH4pEAgyGzosiHNwcGBZ8+eJXl83759dO/eHZlMRq1atXj//j2vXr2icOHCSZ6T8SboFAgEgjRgyKkdAwMDsbL6NruapaUlgYHJz92i1Yi0tJA9q3HKRhmMfrX0O8uXrsno/RIT48Y0wy6yqAuyGmeuMkp41sw34Y0uSM3j4OHhgYeHh3rfzc0NNzc3Paj6ht6TrkAgEBgS41Rk3bQmWQsLC/z9/dX7AQEBKXY0yFw/3QKBQJAChqxecHV1Zf369UiSxOXLlzExMUm2PhdESVcgEPzH0GU/3c6dO+Pl5UVoaCiWlpZMnjxZvShvv379aNq0KYcPH8bGxoacOXNqNSFYikl38ODBKV4kb968TJkyRYuvIBAIBPpFl20cW7ZsSfFeS5YsSdU1U0y6+/bt46+/kl+GY8aMGSLpCgSCDEFGb1dOMekOGzaMX3/9NVmbd+8yxpLhAoFAkNF782i1RlpaCPkUo8/L64VcmaybW0YPssSIjMl83ZkyXZexTLhGmlmetDcz9dx6W2vbNZ0qpPl+qSXNdboLFy7UmRiBQCBIKxm9CJJi0q1WrZr674kTJzJ58mS9ChIIBIK0kF5rn2lLiu9Lv/76q3rLly+fxn5Kdb0/yuWL5+jcphkdW7qwYc0/CY7/e92HXl3a4VijIqdPHFV/7vfwPn17dOGX9q782rE1J48d0Yu+r1w4f45WLVxwberM6pUeCY5HRUUxavgwXJs6061LB14GBgBw5/YtOrZrRcd2rejQtiWnTh4H4PXrV/zWqzttWjajbavmbN64Xsd6z9KyeWNaNGmUpN6R/xtKiyaN+KVzewLj9L5//44+PbtRu3oVpk/VbFSNjo7ir0njcW3WmFYtXDhx/GiC66aFSxfO0b5lU9q2aMy61QljISoqirEj/6Bti8b0+qUjL+OGYHoeOsAvHVqrt1pV7PB9cF/j3OFDBtC5bfJLUv0ImS0u4qN+9lq5sGFtEs9e13Y41kzk2evZhV86uPJrJ/0/e8khk2m/pQepqkAxRN2hUqlk3oypzF/6D+YKBX26daSeY32Kl7BR2ygKFWbM5Kls2bBW49xs2XMw7q/pWBW1JjQkmN5d21Ojdl3y5NH9jGhKpZIZU/9imcdqFIUUdO3UHsf6DShZ8pvOvbt3kidvXvYfPobnkUO4z5/LzDnzKWlTik1bdyKXywkJCaZju1Y4ONbH2NiYP4aPopytHeHhn+jSsS01a9fRuGZa9E6f8hfL/1kTq7djuwR69+zeQd68eTlw5Diehw/hPm8Os+YuIFvWbAwYNIRHfn48euSncd1/Viwnf/787D90FJVKxYcP79OsNb7m2dOnsGj5SswVCnp07chPjvUpEU/z/j27yJM3L7sOHOWY52GWuM9l6qx5uDRrgUuzFgA88vNl5LBBlC5bTn3e6ZPHyZEjp860xtecmeLie+3zZk5l/pK4Z697R+o5JPLsTUri2Zsc79n7RX/PXkpk9DaODNcycP/ubSytrLCwtCJLlqz87NyU816nNWwKF7HAplSZBK8RRa2LYVXUGoCCZuaY5s/Pez31rLhz+xZWRYtiaRWrs3GTpnidPqlh43X6JC1cWwHwc6PGeF+5hCRJ5MiRA7k89vcuKjJKPYO9mZk55Wxjl0LKlSs3xYuXJCQoSId6rePpbYbXqe/0njpFi5axE9T/7BxPb86cVKlqT9Zs2RJcd9+eXfTu0xcAIyMj8uXLrxO9APfu3MbSqqg6Fho1bsJZr1MaNme9TtGsRSsAGvzszFXvywnW8jt25BCNGjdR70dEhLN5wzp6/tZXZ1q/ktniIj6JPntnknj2jNLv2UuJjF7STTHpfp07N0+ePNy6dUvvc+qGBAdhrvg2jM5MoSAkJPUBdu/OLWKiY7CwtErZ+AcIDg5CUeibToWiUIIHITg4mEJxNnK5nNy58/D+/XsAbt+6SdtWzWnfxpWxEyapH7avvAwM4OGD+5SvWElnegsVKhRPr4Lg4O/1BiWiN+kH5+PHjwAsWexOp/atGf7HYN6EhupE71c9iniazRWFCAkO1rAJCQ7CPM7mq+YPcT7+yoljnjg3aabeX7FkEV279yB79hw606qpOfPERXwSPHvmCkKCM96zlxLGRjKtt/QgxaQbFhbGx48fCQsLIyYmho8fP6r3vz50GY3QkBD+njCa0ZOmYGSU4QrzAFSoWIldew+ycesOVq/0IDIyUn0sIiKc4cMGM3zUaHLnzp2OKpNHqYwhKOg1lSpXYeuOPVSqVIV5c2amtywN7ty+Sfbs2SlpUwoA3wf3CQzwx6nBz+msLHEye1yEhsY9exPT79kz5NwLP0KKXqlWrRpDhgzB09OTL1++aHVRDw8P7O3tsbe3Z30ijR/JYWauIDjolXo/JCgIMzOF1ueHf/rEyCH9cft9MOUr6L408BVzcwVBr7/pDAp6jZlC8Z2NOa/jbGJiYvj0KQxTU1MNmxIlSpIzZ04ePfIFIDo6muHDBtOkWQsa/uysU72vX7+OpzcIc/Pv9SoS0ZsvyWuamuYje44cap2NnF24f/+eTjUHxdMcHPQaM3NzDRszcwXBcTZfNZvE8/FxzyM4uzRV79++dZP79+7QqsnPuPX8hRfPn9G/t+4ahDNbXMQnwbMXHISZecZ79lLCKBVbeulLlitXrtC6dWu8vLxwdHSkadOmuLu74+vrm+Q5bm5u+Pj44OPjQ/dev6VKUFnb8vj7v+BlYADR0VGcOHaYuo71tTo3OjqKMcMH49Lclfo/N07VfVOLXfkKvHj+nMCAWJ1HjxzGyamBho2jUwMO7N8LwInjR6leoxYymYzAgABiYmIHjbx8GcjTp08oUsQSSZKYPHEcxUuUpNuvPXWv98UzAgP84/QewrH+d3rrN+DAvj2xeo8dpXrNWsmWBmQyGY6O9fG5egWAK1cuUaJkSZ1pLmdXHv8Xz9WxcPzoERy+i4WfHOtz6MBeAE6dOIZ99ZpqzSqVipPHPGkUL+m27dCJQ8fPsPfICTzWbKSodTGWrVqnM82ZLS7ik+iz55CKZ2/EYFya6f/ZS4mMXtJN9Yi0ly9f4unpiaenJ48ePaJWrVosXbo0SfsfGZF26fxZ3OfOQKVU0axla37t3ZeVyxZR1taOeo4NuH/3NmOGDyHs40eyZstK/gIF2bhjP0cPH2DapHEUj/fgj500lVJlyiVzt4RoOyLt3NkzzJk1DZVSRcvWbenj1o+lixdia1cep/oNiIyMZNzokTx8cJ+8JibMmDUPSysrDh7Yx5pV/yCXyzEyMsKt7+/Ub/gzN65fo9evXSlVqjSyuFezgYOH8ZODY7I6tA2ec2fPMHvmNFRKJS1bt+W3vv1Zutg9Tm9DIiMjGTt6BA/vx+qdOXs+lnGz4jdxbkD4p09ER0eTJ28elnmspmRJG16+DGTc6JGEffxIvvz5mTxlOoULF0lRi7Yj0i6cO8P82TNQqVS0aNmanr/1Y8XSRZSztcPBKdbHk8aOwvfhffLmNWXKzDnqusRrV71ZsnAeqzdsTfTaLwMD+d/g/mzZtV8rLdqOSMsocfEjI9IunT+L+7y4Z8817tlbvoiy5eI9eyO+e/a2xz17k7979iam/tnTxYi0ofseaG27oGXZNN8vtaRpGLBKpeLSpUvUrVs3SRsxDFj/ZPQuMokhhgHrn/+vw4D/d+Ch1rZzW5RJ8/1SS4rf0NU1+c7j+/drV0oQCAQCQ5BOnRK0JsWke+nSJaysrOjcuTM1a9ZM0AdSIBAIMhIZ/cUvxfel169fM23aNO7cucOQIUM4fvw4BQsWxNHREUfH5OuUBAKBwNAYyWRabynh6elJmTJlsLGxYcaMGQmOv3jxgvr161OlShUqVqzI4cOHU9aXkoGxsTEuLi6sW7eOy5cvY2Njg5OTE4sXL07x4gKBQGBodNVlTKlUMmDAAI4cOcK9e/fYsmUL9+5pdomcMmUKHTp04MaNG2zdupXff/89RX1a1VpHRkZy6NAhtmzZwrNnzxg8eDCtW7fW5lSBQCAwKLqqXvD29sbGxoYSJUoA0KlTJ/bt24etrW28e8nUg8Q+fPhAkSIp99xJMel2796dO3fu0LRpUyZOnEj58uV/9DsIBAKB3tHV8N7AwECsrL4NZba0tOTKlSsaNpMmTcLZ2ZlFixYRHh7OiRMnUrxuitULGzduxM/PD3d3d+rUqaP3uRcEAoEgLRjJtN/ij561t7fHwyPhVJzJsWXLFnr06EFAQACHDx+mW7duqFSqZM9JsaSb0gUEAoEgI5GaSczd3Nxwc3NL9JiFhQX+/v7q/YCAACwsLDRsVq1ahaenJwC1a9fmy5cvhIaGYv7dcHUNfSmJqlq1aorCtbERCAQCQ6CrqR2rV6+On58fT58+JSoqiq1btyYYt1C0aFFOnoyduvP+/ft8+fIFMzOzZK+bYkn3/v37VKxYMcnjkiTx4cOHlC4jEAgEBkFXgyPkcjmLFy+mcePGKJVKevXqhZ2dHRMmTMDe3h5XV1fmzp3Lb7/9xvz585HJZKxduzbFEaIpDgN+/vw5hw4dwtHRkdy5c7No0SLu3LnDoEGD1I1qxsbGWFpaJnq+GAasf8QwYMMghgHrH10MA5528rHWtmMa6m6CJm1JMYqsra1Zvnw5dnZ2+Pv74+Pjw6BBg/jrr7+wtrbG2to6yYQrEAgEhkZupP2WLvq0MTI2ji35HTp0CDc3N5o1a8a4ceO0ukHubGn/5TI0EplrqHMmLOhmulIjgCpzhQV5cmS+Z08XZPQ3P60i38LCgr59+7Jt2zaaNm1KZGSk6NUgEAgyJKnpMpYu+rQx2r59O40bN+bo0aOYmpry9u1bZs+erW9tAoFAkGoy+sKUWr1/vHr1imbNmpEtWza8vLy4desW3bt317c2gUAgSDWp6aebHmhV0m3bti3GxsY8evQINzc3/P396dKli761CQQCQaoxNtJ+Sw+0uq2RkRFyuZzdu3czaNAgZs+ezatXr1I+USAQCAyMETKtt/RAq+qFLFmysGXLFtavX8+BAweA2NVJBQKBIKORwWsXtCvprlmzhkuXLjF27FiKFy/O06dP6datm761CQQCQarJ6L0X0rQwpTZ8zoQF4szWTzejNxwkhiqzdXol8/XTlRtnvrjIroOuxR6Xn2tt61bLOu03TCVafUU/Pz9Gjx7NvXv3+PLli/rzJ0+e6E2YQCAQ/AgZvQyiVfVCz5496d+/P3K5nNOnT9O9e3d++eUXnQq5cP4sLZs3pkWTRqxemXBOy6ioKEb+bygtmjTil87tCQwMAOD9+3f06dmN2tWrMH3qXxrnHD1ymPatW9CmZTMWzNN9v+IL58/RqrkLrk2ck9Q86n/DcG3iTLfOHXgZp/nyxQt06dCG9q1b0KVDG7yvXFafM6BvHzq0aUnbls2ZMnkiSmXaxs9fOHcW12aNae7SiFX/JK5xxP+G0tylEV07ffMrwKp/VtDcpRGuzRpz4fw59edNGjWgbasWdGjTks4d2qg/H/G/oXRo05IObVrSpFEDOrRpmSbtEOfjFi64Nk3Gx8OH4drUmW5dtPPxUc/DdGjjSttWzXGfNyfNGr/n4vlztGnhQstmzqxZlbjmP0cMo2UzZ7rH0/yVV69eUq9mVdavXQXErtzSvUt7OrVrSfvWzVm+ZGGaNRoyLh4+eEC3Lh1p26oFg37vx6dPn9KsPzmMjWRab+mCpAVVq1aVJEmSypcvn+CzlIiISnkL+xwjNWjQUPJ9/EL6EB4pNW/eQrp930/DZs36jdKYseOliChJ2r33oDRw0BApIkqS3rwPly5cviqt27BZGj9xstr+ZfBbycHBUQp4/UaKiJKkP4aPlE6fvaiVnvAoVYrbx8/RUoMGDaWHj59L78O/SM2at5Bu3ffVsFmzfqM0eux4KTxKJe3ae0AaOGiIFB6lkq7dvCM9DXglhUeppJt3H0h169VTnxP09qMUHqWSPkUqpX6/D5B27T2QopbP0VKi26cvMVKDhg0lvycvpI9xfr1z30/DZu36jdKYceOlz9GStHvfQWng4CHS52hJunPfT2revIX0ITxS8nv6QmrQsKH06UuM9Dlakpyc6ksvg98ked/P0ZL099Tp0nz3RUkeD49Upbh9jIjz8aPn0vtPcT6+56ths2ZdnI8j4/k4UiVd+/eO9NT/lRQeqZJu3onzcaRKCgx6Izk4OEr+r0Kl8EiV9MfwEdKpMxe00hP2JeXtfXi0VL9BQ+n+o+fS27BYzTfv+mrYrFobqznsi0raueeANGDQEI3j/X8fKPUfMEhasvwfKeyLSvr4WSkFvQ2Twr6opLdhkVLrNu2ki1eup6glo8RF69ZtpHMXr0ifoyVp87Yd0uy585PUpgvWeD/XeksPtCrpZsuWDZVKRalSpVi8eDF79uzR6a/Vndu3sCpqjaWVFVmyZKVxk2Z4nTqpYeN16hQtWsauy/azc2O8r1xCkiRy5MxJlar2ZM2WTcM+wN+fotbW5M+fH4BatWpz4vhRHWsuGk9z00Q0n6RFy1YJNJctZ4u5uQKAkjaliPwSSVRUFAC5c+cGICYmhpjo6DSNI79z+xZWVnF+zZoVl6bN8DqtqfH0qVO4xvm1kXNjvC/HavQ6fRKXps3ImjUrlpZWWFlZc+f2La3uK0kSx44eoUmz5j+sXa3/ex9/p9/r9ElauLYC4OdGKfs4MCBAIy5q1qrDyRPH0qQzPnfvxGm2jNXs7JJQ8xmvkzSP09wwnmaA06dOUMTCkpIlbdT2MpmMnDlzAXFxEROTpndoQ8fF8+fPqGZfHYDatety8rju/J0YMplM6y090Crpuru7ExERwcKFC7l27RobNmxg3bp1OhMRHBxEoUKF1PsKhYLg4KBEbAoDsfNc5s6dh/fv3yV5zaJFrXn27CmBgQHExMRw+tRJgl6/1qlmRZyeWM2FCEmgOTgRze81bE4cP0pZW1uyZs2q/ux3t940dKxLzly5+Nm58Y9rDAqiUOFvfjVXKAgKSsGveWL9GhQUhCL+/0khBcFfz5VBv99606l9G3Zu35bgvtev+VCgQAGsrYv9sPav2hL4OIF+LX1cLtbHVlZFefb0KS/VcXGCoNe663MeHBSEQpF8XIQEBatt4muOiAhn3ep/cOs/IMF1lUolndu3opFTXWrVrkOFipXSpNGQcVHSphSn4wokx4568lqH/k4MWSq29ECrhrTq1WN/pXLnzs2aNWv0KkhX5DUxYez4SYwaPgwjIyMqVa6Cv/+L9JalweNHfiycN5elHqs0Pl/qsYrIyEjGjBrO1SuXqVWnbjopTJy1G7agUCh48+YN/fr0pHiJEuqSDMCRwwdxaZq2Uq6uePzIj4Xzv/k4r4kJY8ZPZNSIP5DJZFSqXIWAeEuypCcrli6mS7ce6lJtfIyNjdmyYy9hHz/yv2EDeeTni02p0umgMmmSiovJf09lxvSpeCxfilP9BmTJkjXli6WBjN6bR6uSro+PD61bt6Zq1apUrFhRvSVF/MXeViXS+PE95uYKXscrhQYFBalfDTVtYn8hY2Ji+PQpDFPTfMle19GpARu37GD9pm1YFyue5pLX93ril5CCgl5jlkCzeSKaTWPtX7/mjyED+XvaTKyKFk1w/WzZsuFUv2GC175UaVQoeP3qm19jS2Ep+DUs1q8KhULjzSDodRDmced+vUaBAgVo8HMjjdfLmJgYTp44jotL0x/WHV9bAh8n0J+Cj4fG+djqm48dnRqwYfN21m/aRrFixbEuVizNWtV6FAqCgpKPCzOFudomvuY7t2+xcP5smrs0YPOm9axZ6cG2LRs1zs2TNy/21Wty8cI5fhRDx0XxEiVZ8c9qtu7YjUvTZljGW2FXH+iypOvp6UmZMmWwsbFhxowZidps374dW1tb7OzstJoeQauk27VrV3r27MmuXbs4cOCAeksKNzc3fHx88PHxoXefxBd9i49d+Qq8ePGMwAB/oqOjOHrkEI71G2jYONZvwIF9ewA4cewo1WvWSrFO5u2bNwB8/PCB7Vs306Zt+xS1aEus5ucEBgTEaT6MU6Ka9ybQHPbxI4N+78vgof+jcrz15SIiwgkJCQZiA/382TMUK14ijRqfERDgT3RUFJ6HE/rVqX4D9sf59fixo9SI0+hYvwGehw8RFRVFQIA/L148o3yFikRERBAe/ilObwSXLl7AxqaU+npXLl2kePESGq+gadL//DsfO33nY6cGHNi/F4itRqheI56PB8T5uIrmGn4acbFtC63btEuz1q/Y2lXAP57mY56HcUxE88E4zSfjaV61bhMHPU9x0PMUXbp2p2cfNzp2/oV3b98S9vEjAF++fOHKpYuZKi7exPlbpVLxz4pltO/Y6Ye1a4ORkUzrLTmUSiUDBgzgyJEj3Lt3jy1btnDv3j0NGz8/P6ZPn86FCxe4e/cuCxYsSFGfVtULZmZmCRZk0yVyuZw/x0ygf98+qJRKWrZui41NKZYudsfWrjxO9RvSuk07xo4eQYsmjchrYsLM2fPV5zdxbkD4p09ER0dz+tQJlnmspmRJG2bNmIrvwwcAuPUbgHWx4jrVPGrMeH7v2xuVUkXL1m0paVOKpYsXxmluQKs27Rg3eiSuTZzJa2LCjNnzANi6ZRP+/i/wWL4Uj+VLAVjmsQpJkhg68Heio6JQSRL2NWrQrsOPB6hcLmf02An0d+uDSqWkVZxflyxyx86uPE4NGtK6bTvG/jmC5i6xfp01J9avNjalcHZpQmvXphgbGzNm3ASMjY15++YNwwbH1jnGKJU0bdacuj85qO/peeQwLk2b/bDm7/WPGjOe3/tp4eOmcT6elYyPV6wif4ECzJo5Fd+HDwFw6/e7zuNi5JjxDOzfG6VSRctWsZqXLVmIrW15HOs3oGXrdowfM5KWzZwxMTFhWpzmpAgNDWHiuD9RKpVIKomfG7vg4Fg/TRoNGReehw+ydctmABr+3IhWrdv+sHZt0NU8Nt7e3tjY2FCiROwPXKdOndi3bx+2trZqm3/++YcBAwaQL1/sW3dyqwB/RasRaSdPnmTLli00bNiQbPF6CbRp0yaZs2IRI9L0T0avw0oMMSJN//x/HZG2/d+XWtt2qFwkyWM7d+7E09OTlStXArBhwwauXLnC4sWL1TatWrWidOnSXLhwAaVSyaRJk3BxcUn2nlp9xTVr1vDgwQOio6MxMor9HZHJZFolXYFAIDAkqfmp8fDwwMPjW7uTm5sbbm4pV4l+JSYmBj8/P7y8vAgICMDBwYHbt2+r2xUSQ6uke/XqVR7GvY4JBAJBRiY1/W+TS7IWFhb4x+vZEhAQgIWFhYaNpaUlNWvWJEuWLBQvXpzSpUvj5+en7vGVGFpVf9SpUydBBbJAIBBkRIxlMq235KhevTp+fn48ffqUqKgotm7dmqBtq1WrVnh5eQEQGhqKr6+vug44KbQq6V6+fJnKlStTvHhxsmXLhiRJyGQybt3SboSSQCAQGApd1WTL5XIWL15M48aNUSqV9OrVCzs7OyZMmIC9vT2urq40btyYY8eOYWtri7GxMbNnz6ZAgQLJ60upIU2SJM6dO4e1dcIp0BL77HtEQ5r+EQ1phiGzSf7/2pC277b2I09bVkh718bUkuJXlMlkDBgwgNu3bxtCj0AgEKSJ9FqGR1u0qtOtWrUqV69e1bcWgUAgSDP/iSXYr1y5wqZNm7C2tiZXrlyiTlcgEGRYZBm8pKtV0j16VHdTIgoEAoE+SalXQnqTbNL9+PEjefPmJU+ePIbSIxAIBGkig+fc5JNuly5dOHjwINWqVdPocPy1ekGskSYQCDIamTrpHjx4EICnT5/y9u1b/Pz8NBamFAgEgozGf6JOd+XKlbi7uxMQEEDlypW5fPkyderU4eTJlOd6ffnuc5pFGpoopSq9JaSKLMa6mlfJcIR/iUlvCakmRzbj9JaQKtJt4cU0UNIsR5qvkdG/ttbL9Vy9ehVra2tOnz7NjRs3MDEx0bc2gUAgSDVGMpnWW3qgVUk3e/bsZM+eHYhdDrps2bJiAhyBQJAh+U9UL1haWvL+/XtatWpFo0aNyJcvn1ZDgAUCgcDQZPTqBa0mMY/PmTNn+PDhAy4uLhor2CbF42BRp6tvRJ2uYRB1uvpHF3W653yTXiX8e34qnfw6i/og1dNLODo66kOHQCAQ6IRM3WVMIBAIMhsZPOeKpCsQCP5bZOphwAKBQJDpyNg5N+V+ukqlkq5duxpCi0AgEKQZWSr+pYSnpydlypTBxsaGGTNmJGm3a9cuZDIZPj4+KV4zxZKusbExz58/JyoqSqveCrrA58oFVrjPQqVS0bh5azr80kvj+O6tGzh6cA/GxsaYmOZj6OhJKArFLqXc3LEqxUrYAGCmKMzEGe4G0Xz9ygVWLp6DSqmkUbPWtO3aU+P4vu0bOX4oVnNe03wMGjkR8zjN61a4c+3SeQA6dO9DvQaN9a7X58oFPOJ87JyIj/ck4uOveoODXrFw5mRCgoOQIWPy7EUoClskdhud8u/Vi6xZOgeVSkXDJq1o1amHxvFjB3ZydP8OjIyMyZ4jB32HjcXSOna9qudP/PBYMI3PEeHIZDKmL1lP1qzZ9K752pUL/LNwNiqVikbNWtH+Oz/v3baBYwf3YGwsJ69pPob8GRsXt65fZeXiOWq7gBfPGDFxBrV/qq9XvT6Xv3v2umn/7AFEhH+i7y9tqP1TfX7/Y7RetSaFrmoXlEolAwYM4Pjx41haWlK9enVcXV2xtbXVsAsLC8Pd3Z2aNWtqdV2tqhdKlChB3bp1cXV1JVeuXOrP//jjj1R8Be1QKpUsnTedqfOXU9BMwdDfulKrriNFi5dU25QsXRb3lZvInj0Hh/ZsZ/WyBYyePAuArNmysXjNdp3rSknzCveZTJ6zlAJmCkb0+4UadR2xKvZtgboSpcowd8VGsmXPwZF9O1i3wp0RE2fic+kcT3wfMH/lFqKjoxk39Deq1qxLzly59ap32bzpTInz8bBEfFyidFkWfOfjP+N8PG/KODp270OV6rX5HBGBzABdk1RKJasWzWTczCUUKKhg9MDu2Nd2UCdVgHoNXHBu0Q4An4tnWLd8PmOnL0KpjGHRjPEMHPUXxUqWJuzje+TG+q9ZUyqVLJ8/g7/nLaOAmYI/3LpSs54jRYvF83Opssz7J9bPh/duZ80yd0ZNnknFqtVZuHobAGEfP+DW2ZUq1WvpXa/62TNXMLRPV2rVS+HZW7qA0X/NUh9f/88SyleqqledKaGraPT29sbGxka90GSnTp3Yt29fgqQ7fvx4Ro0axezZs7W6rlYdPEuWLEnz5s1RqVSEhYWpN33ge/8ORSysKFzEkixZsuDQsDGXzntp2FSqWp3s2WP785W1q0hocJBetGiL34M7FLawpFCc5noNGnPlgpeGTYUq1ckWp7mMbQXehAQD4P/8CbaVqmIsl5M9Rw6sS5biuvdFvepNzMeXtfTxi6ePUSqVVKleG4AcOXOq7fTJo4d3KVTECkVhS+RZslDHyZmrF89o2MT/ofry5bN6ZrybPpcpWqIUxUqWBiBPXlOMjPXf59bv/h0KW1ip48KhYWOufOfnivH8XMa2Im9CEsbyBa8TVKtZV+9+9r1/hyKWVhS2iNP7sxbPXjy9fg/u8f7dW6rWqK1XnSkiS8WWDIGBgVhZWan3LS0tCQwM1LC5fv06/v7+NGvWTGt5Wv3cT5w4UesLppU3IcEUNP+2WFxBMwUP7ye9PtvRQ3uwr1VPvR8VFcXgPl0wNjamfdee1HFooFe9AG9DQiho9k1zATNz/O7dSdL+xKG9VK1RF4BiJUuzbZ0HrTr8QuSXL9y54YOVdfJLOKeV1Pr4WDwfB/o/J1fuPEwZ+wdBrwKpXK0mPfoNwVjPSextaDAFzBTq/QIFzfF7kNDHnvu2c2jXJmJiYpgwaxkArwJfIAOm/jmQjx/eUcfJmZYdf9WrXoA3ocEUNI+n2UyBbzJxcfzQXqrVrJvg83Mnj9Ky4y960RifROPiXjLP3sE92NeMjQuVSsXKxXMZMWEaN3wu611rcqRmTgUPDw88PDzU+25ubri5uWl1rkql4o8//mDt2rWp0qdV0vX19WXOnDk8e/aMmJhvI4lOnTqVqpvpmlNHD+H34B6zFq1Sf7Z2x2EKmil49TKA0UN+o3jJUhS2sErmKobF69ghHj28x1T3lQBUqV6bRw/uMmpAT0xM81HGriJGRhlnhNlXH8+M87FSqeTurRssXL0Vc/NCzJg0ihNH9tO4eet0VhqLS8sOuLTswPlTnuzavIqBIyejVCp5cPcm0xevJ1u27Pw1sj8lSpWjQtUa6S1Xzem4uJi+cKXG529DQ3j2xC/9S4/foX72FsfGxaE927GvXU/jRya9SE31QnJJ1sLCAn9/f/V+QEAAFhbf2i7CwsK4c+cOTk5OALx+/RpXV1f279+Pvb19kvfUKum2b9+efv360adPH61KNPF/PVp36kGn7r21uQ0QW0oMDf62hHJoSBAFCponsLvhc5ltG1Yyc9EqssRr4CsYVxoqXMSSipXteez7QO9JN7+ZGaEh3zS/CQkmv1lCzTd9rrBz4yqmuK/U0Ny+Wx/ad+sDwNy/x1DESr/zWqTFxwXNFZSwKUPhIpYA1K5Xnwf3bgH6Tbr5C5prvHq/CQ0mfyKav1LHyZl/3KcDsaXichWqkNfEFIAqNery9NEDvSfdAgXNNaq+3oQEUcDMLIHdvz6X2b5+FdMXacYFwPnTx6nt0AC5PItetUIScZFIHN+4eplt61cyc/G3uLh/5yZ3b97g0J7tfPn8mejoaHLkyEnP/kP0rjsBOqrUrV69On5+fjx9+hQLCwu2bt3K5s2b1cdNTEwIDQ1V7zs5OTFnzpxkEy5oWacrl8vp378/NWrUoFq1auotKdzc3PDx8cHHxydVCRegdFk7Xga84PXLQKKjozl78ii16mkOPX7s+4BFs6cwYfoCTPPlV38eFvaR6KgoAD68f8e9O/9StJh+X9UBSpWx41WAP0GvYjWfP3WUGnU0NT/xe8DSeVMZM01Ts1Kp5OOH9wA8e+zL88d+VLHXb4NJ6bJ2BH7n45qJ+HhxIj4uVdaO8E9hfHj3FoCb170N4uOSZWx5FehP8KtAYqKjueh1DPvaDho2rwJeqP++fuU8hS2KAlDJvjb+Tx8R+eULSmUM929d12iA0xelEonlGnWdNGwe+z5gyZypjJ8+X8PPXzl70hOHhi561wpxz55/PL0njlKrbhLP3gzNuBg5cTrrdnuyducReg8YRkOX5umTcNFdlzG5XM7ixYtp3Lgx5cqVo0OHDtjZ2TFhwgT279//4/q0mfBm0qRJmJub07p1a7Jl+9bNJn/+hEHyPT8y4c3VS+dYEdfNxrlZSzp1/40NK5dSqqwtteo5MWZoX5498SN/gYLAt65h927/y6I5UzCSGaGSVLRq3/WHXnt/ZMIbn8vnWb14DkqVip+buNK+Wx82r16GTRlbatR1ZMIf/Xj+9BH58n/VXIix0xYQFRnJH25dAMiZMxf9/hhLiVJlUnXvH5nw5uqlc3iouzIl7uPnT/zI952PAW5cvcTKxfOQkLApXY5BIyeQJUvqSmI/MuHN9SvnWbdsHiqVkvqNXWnTtTfb1i6nZOly2NdxZM2SOdy+4Y2xsZzcefLQa+BIrOJ6Cpw9cZi9W9cik8WWdH/5LfUJ4UcmvPG5dI5/FsV2c/u5aUs6du/DxlVLKVXGlpr1nBg3rC/Pnzz65mfzQoyP83PQq5eMHNCDNTs9f6jK6UcmvLl66Rwr3OM9e79+FxdDEnn2Zmp2yzx+eB9+D+79UJcxXUx48+8L7Rv5Kxc1/PqPWiXd4sWLfzshXiW1NmukiVnG9I+YZcwwiFnG9I8uku5Nf+2TbiUrwyddrZ7WmTNncvPmTZ4+fUrPnj2pVKkSO3fu1Lc2gUAgSDW6HJGmD7RKulOmTCFv3rycP3+eU6dO0adPH/r3769vbQKBQJBqZDLtt/RAq6T7tcfCoUOH+O2332jWrBlRcQ1WAoFAkJHQ0dgIvaFV0rWwsKBv375s27aNpk2bEhkZiUqVueo9BQLB/xMyeNbVKulu376dxo0bc/ToUUxNTXn79q3W44wFAoHAkGT0Ot1Ur5GWWkTvBf0jei8YBtF7Qf/oovfC/ZfhWtuWK5IrZSMdIyYxFwgE/y0y+G+NSLoCgeA/RXpVG2iLSLoCgeA/RQZfIk0kXYFA8N8ig+dckXQFAsF/jAyedUXSFQgE/ylSM4l5eqD3pGuSU//zgOqayJjM1WUsT/bM99v5LFKZ3hJSjSJv9vSWkCpCwiLTW0K6kLFTrijpCgSC/xoZPOuKpCsQCP5TZPQuY5lvKJNAIBAkgy5nGfP09KRMmTLY2NgwY8aMBMfnzZuHra0tFStWpGHDhjx//jzFa4qkKxAI/lPoKukqlUoGDBjAkSNHuHfvHlu2bOHevXsaNlWqVMHHx4dbt27Rrl07Ro4cmaI+kXQFAsF/Cl1NeOPt7Y2NjQ0lSpQga9asdOrUiX379mnY1K9fn5w5cwJQq1YtAgICUtSXZJ3uqVOnaNCgAbt37070eJs2bVK8uEAgEBgaXfUYCwwMxMrq20rilpaWXLlyJUn7VatW0aRJkxSvm2TSPXPmDA0aNODAgQMJjslkMpF0BQJBhiQ1OdfDwwMPDw/1vpubG25ubqm+58aNG/Hx8eHMmTMp2iaZdCdPngzAmjVrUi1AIBAI0ovUlHSTS7IWFhb4+/ur9wMCArCwsEhgd+LECaZOncqZM2c0VktPihS7jEVGRrJr1y6ePXtGTMy3OVAnTJiQ4sUFAoHA8OimfqF69er4+fnx9OlTLCws2Lp1K5s3b9awuXHjBn379sXT0xNzc3Otrpti0m3ZsiUmJiZUq1ZNqyyuCy5fPMeCOTNQKZW0aNWWbj1/0zj+73Uf3OfM4PEjXyZPm039nxurj/0x0I27t29RsXJVZrsvNYheAO9L51k8byYqlZKmrm3o8msfjeM3b/iwZP4snjzyZfzfs3Bs6AzADR9vli6YpbZ78fwp46fMop5jQ51rvHjhHHNnTkOlUtGydTt69Nb0a1RUFBPHjuLB/XuYmJgybdY8isT9svv5PmT63xP59OkTRkZGrNu8g2zZshEdHcWs6VO4ftUbmZERvw8aSoOfnXWuHeCG90XWLJ2DSqWkYZNWtO7cU+P4sQM78dy3HSNjY7Jnz0HfP8ZhZV2C4NcvGdqrHUWsrAEoXa4CbkPH6EUjwKUL55g765uff+2V0M+Txn3z89SZ3/l5ykTC4/y8dlOsn48eOcTaVSuQyWQUNDPnr6mzMM2XT+fafa5cwMN9FiqVCufmrenwSy+N43u2buDowT0YGxtjYpqPoaMnYV6oCADBQa9YOHMyIcFByJAxefYiFIUTlgz1ja7mbpfL5SxevJjGjRujVCrp1asXdnZ2TJgwAXt7e1xdXRkxYgSfPn2iffv2ABQtWpT9+/cne90UV44oX748d+7c+WHhoZ9St0KAUqmkU+tmLFj6D+YKBX26dWTStNkUL2Gjtnn1MpDw8E9s2bCWeg5OGknXx/syX758Zt+uHT+cdFM7DFipVNK9fXNmL/LAzLwQ/Xt0YtzfsyhWoqTa5nWc5u2b1lHnJyd10o3Pxw8f6NauKdsOnCB7du1n0NdmGLBSqaStaxMWr1iFQqHg1y4dmDJjDiVKfvPrjm2beeTry+jxkzh25BCnT51g+uz5xMTE0K1TWyZPnUnpMmV5//4defLkxdjYmBVLF6FSKek/cCgqlYqPHz5olQyehURo/f2+6h/SozXjZy4lv5mC0QO6MWTsNKysS6htIsI/kTNXbgCuXjzD0f07GDdjMcGvXzJj3FDmrdyeqnt+j3XBnFrpbNeyCYuXr8JcoeDXrh2YMl3Tzzu3bcbPz5fR4yZxzPMQXqdOMG1WrJ+7d27LpCmafpYkiWaNHNm2+yCm+fKxcP5ssmfPgVv/gclqSe0wYKVSiVuXlkyZv5yCZgqG/daVkROnU7T4tzi+ef0qZWzLkz17Dg7t2c7tf334c3JsoeHPQb3p2L0PVarX5nNEBDIjWariGMDGPO0rR7z6oP2iuYVNsqb5fqklxS5jderU4fbt24bQAsD9u7extLLCwtKKLFmy0tC5Kee8TmvYFC5igU2pMsgSqbyxr1GLnDkNuwTHg3u3sbAsShELK7JkyUKDRk24eFZTc6EiFpQsVQajZH6Gz546Ro3a9VIdqNpw984trKyKYhnn10YuTTnjdUrz/qdP0cy1JQANGjXmqvdlJEniyqUL2JQqQ+kyZQEwNc2nXiF6/97d9OgVWydmZGSkl9IXwKOHdylUxApFEUuyZMlCXSdnfC54adh8TbgAkV8+Jxof+ubunVtYWhVVx69z46ac/c7PZ7xO0axFnJ9/1sLPkoSExOfPEUiSRHh4OGZm2r3Kpgbf+3coYmFF4TgfOzRszOXzXho2lapWV8dnWbuKhAYHAfDi6WOUSiVVqtcGIEfOnHqJY23I6GukpVhEOn/+PGvXrqV48eJky5YNSZKQyWTcunVLL4JCgoMwVxRW75srFNy9o5976YrQ4GDMFYXU+wXNFdy/m3rNp4570r5Ld11KUxMSHIyi0DeNCnMFd25ragwODkJRKNb3crmc3Lnz8OH9e54/f4ZMBoP69eHdu7c4uzSle88+hH38CMDyJQu55uONpVVRRoweR4ECBXWu/21oMAXMFer9/GYK/B4kfAPz3Ledgzs3EhMTw8TZy799t9eBjOjbhRy5ctG55++Uq1BF5xohoZ/NFQrufufnkCT8/OKrn/v34f27tzRqHOtneZYsjBozkS7tW5I9Rw6silozcvR4nWt/ExJMQfN4cWym4OH9pAtcxw7twb5WPQAC/Z+TK3cepoz9g6BXgVSuVpMe/Yaof5wNSsYeBZxySffIkSP4+flx7NgxDhw4wMGDBxPtRiZIG29CQ3j62I/qteqkt5QEKJVKbt64zt/TZ7Ny7Sa8Tp3A+8ollEolwUGvqVi5Chu37aZCxcq4z52V8gX1iEvLDizesJ+ufQaxa9NKAPLlL8iyTYeYvWIzv/b7A/dpY4kI/5SuOhNDqVTy743r/D1tNv+s2YTX6Vg/x0RHs2vHVjZs3c3h42cpVaoMa1d7pHxBPXLq6CH8Htyjbedf1drv3rpB7wF/sMBjE69fBXLiSPJ1m/oig6/AnnTS/RhXismTJ0+iW3J4eHhgb2+Pvb0961f/kypBZuYKgoNeqfeDg4IwM1Mkc0b6U9DcnOCg1+r90ODUa/Y6cZR6jg2Qy/UzFaaZuTlBr79pDAoOwkyhqdHcXEHQ61jfx8TE8OlTGCampijMFVSpZo9pvnxkz5GDOvUceHj/HiampmTPnoP6DRsB0NC5MQ/uaw6T1BX5C5rzJu5VFuBtSBAFCpglaV+3fmO846ofsmTNSh4TUwBKli6HorAlrwJe6EXn934ODgrCzFzxnU3ifjZXKKhS9Zuf68b52ffhAwAsrYoik8lo6OzC7X9v6Fx7ATNzQoPjxXFIEAUKJqzGuOFzmW0bVjJhhjtZssbWiRY0V1DCpgyFi1hiLJdTu159Hvve17lGbdDl3Av6IMmk26VLFwCqVauGvb091apVU2/29vbJXtTNzQ0fHx98fHzo/l3LbUqUtS1PgP8LXgYGEB0dxcljh6nnWD9V1zA0ZcuVJ9D/Oa9eBhAdHc2p40eo7eCUqmucOnaEBs5N9SMQsLWrwIsXzwkMiPXrcc/DOHzn15+c6nNof+wwx1PHj1K9Ri1kMhm16tbjkZ8vXz5/JiYmhuvXrlK8RElkMhk/OTpx7ao3AFevXNZoMNIlNmVseRXoT9CrQKKjo7ngdQz7Oo4aNvET6fUr5ylsWRSAD+/foVTGzt8b9DKAV4EvMNdTq7qtXQX8XzwnMC5+jx09zE/f+dnBsT6HDsT5+cRR7KvH+blOPR4/SuhnM3MFT5884t3btwB4X76o0UirK0qXtSMw4AWvX8b6+OzJo9Ssp+njx74PWDx7ChOmL8A0X37156XK2hH+KYwP72I13rzuTdFiJUgPZDKZ1lu66Eup90JaSW3vBYCL58+ycO4MlEoVzVu25tfeffln2SLK2trxk2MD7t+9zejhQwj7+JGs2bKSv0BBNu2IfZXp37sbL549JeJzBCYmpowe/xc169RL1f1/ZBLzyxfOsnT+LJQqJU1atOaXnm6sWbGY0uXsqOtQnwf37jBh5BA+hYWRNWtW8hUoyJqte4HYng2D3Lqzbf9xjIxSPx2GtpOYXzh3hnmzpqNUqXBt1YZev/Vj+ZKFlLMrj6NTAyIjI5k4dhQPH9wnb14Tps6ai6Vl7DDIwwf3s3aVBzKZjLo/OTB42AggtifJxLGjCAsLwzRffib+NZVChYukqCW1vRcgNpGuXToXlUpJfZeWtO3am61rl1GytC3V6ziyeslsbl/3xjiunrT3oFFYFSvJ5bMn2bZuOcZyOUYyGR1+7Yd9bYdU31+b3gsQ5+fZ01GpVLRoGevnFUsXUs62PA7x/Oz7MM7PM+diEefnI4e++blOvW9+3rVjK9s2b0Aul1OocBEm/DUNU9PkGy1/ZBLzq5fO4bFwNiqVikbNWtKp+29sWLmUUmVtqVXPiTFD+/L8iR/54urtzRSFmTjDHYAbVy+xcvE8JCRsSpdj0MgJZMmSujc3XfReSE3OKZjb8LPbpph0L1y4QOXKlcmVKxcbN27k+vXrDB06lKJFi2p1gx9JuumNWDlC//xI0k1vtE26GYXMuHKELpLum3Dtc06BXIZ/dlIsVvXv35+cOXNy8+ZN5s6dS8mSJenWrZshtAkEAkGqyehdxlJMunK5HJlMxr59+xg4cCADBgwgLCzMENoEAoEg1WT0hrQUy9Z58uRh+vTpbNiwgXPnzqFSqYiOjjaENoFAIEg1GXwx4JSTbqNGjYiJiWHNmjUUKlSIFy9eMGLECENoEwgEglST0ddISzHpKpVKtm/fzrFjx+jYsSPt27ene3f9jJoSCASCtJLRS7padxm7desW27ZtY9euXVhaWnLixAmtbiB6L+gf0XvBMIjeC/pHF70Xwr5o//zmyW74Fcu0flrNzc0pVKgQBQoUIDg4WJ+aBAKB4MfJ4CXdFNP80qVLcXJyomHDhrx584Z//vlHb5PdCAQCQVrJ6F3GUizp+vv7s2DBAipXrmwAOQKBQJA2dDWJub7IkMOA0xtRp6t/RJ2u/vn/WqcbEa19SsuZxfAZOvM9rQKBQJAMmb7LmEAgEGQmMnqXMaRMzIoVK9JbQqrIbHolKfNpzmx6JUlo/v+G4Tup6RAPj/SdPT+1ZDa9kPk0Zza9IDT/fyNTJ12BQCDIbIikKxAIBAYkUyddNze39JaQKjKbXsh8mjObXhCa/7+h9366AoFAIPhGpi7pCgQCQWYjUyTdXr16YW5uTvny5dWf7dixAzs7O4yMjPDx8UlHdYmTmOabN29Su3ZtKlSoQIsWLdTL3GcUihUrRoUKFahcubJ6xed///2XWrVqqT/z9vZOZ5WazJ8/Hzs7O8qXL0/nzp358uULPXr0oHjx4lSuXJnKlSvz77//prdMNe7u7pQvXx47OzsWLFgAZLy4SCx2R4wYQdmyZalYsSKtW7fm/fv3Gue8ePGC3LlzM2fOHAOrzYSkd581bThz5ox07do1yc7OTv3ZvXv3pAcPHkiOjo7S1atX01Fd4iSm2d7eXvLy8pIkSZJWrVoljRs3Lr3kJYq1tbUUEhKi8VmjRo2kw4cPS5IkSYcOHZIcHR3TQVniBAQESMWKFZMiIiIkSZKk9u3bS2vWrJF+/fVXaceOHemsLiG3b9+W7OzspPDwcCk6Olpq2LCh5Ofnl+HiIrHYPXr0qBQdHS1JkiSNHDlSGjlypMY5bdu2ldq1ayfNnj3boFozI5mipOvg4ED+/Pk1PitXrhxlypRJJ0Upk5hmX19fHBxil/5u1KgRu3btSg9pqUImk6lLXh8+fKBIkZSXVzckMTExfP78mZiYGCIiIjKcvvjcv3+fmjVrkjNnTuRyOY6OjuzevTvDxUVisevs7IxcHjuAtVatWgQEBKiP7d27l+LFi2NnZ2dQnZmVTJF0/yvY2dmxb98+ILZ6xN/fP50VaSKTyXB2dqZatWrqzu8LFixgxIgRWFlZMXz4cKZPn57OKr9hYWHB8OHDKVq0KIULF8bExARnZ2cAxo4dS8WKFRk2bBiRkRlj4pfy5ctz7tw53rx5Q0REBIcPH8bf3z/Dx8X3rF69miZNmgDw6dMnZs6cycSJE9NZVeZBJF0Dsnr1apYuXUq1atUICwsja9as6S1Jg/Pnz3P9+nWOHDnCkiVLOHv2LMuWLWP+/Pn4+/szf/58evfund4y1bx79459+/bx9OlTXr58SXh4OBs3bmT69Ok8ePCAq1ev8vbtW2bOnJneUoHYt7NRo0bh7OyMi4sLlStXxtjYOMPHRXymTp2KXC6na9euAEyaNIlhw4aRO3fudFaWiUjv+g1tefr0qUYd01cyap2uJCWtWZIk6eHDh1L16tUNrEh7Jk6cKM2ePVvKmzevpFKpJEmSJJVKJeXJkyedlX1j+/btUq9evdT769atk/r3769hc/r0aalZs2aGlqYVo0ePlpYsWaLxWUaJi8Rid82aNVKtWrWk8PBw9Wf16tWTrK2tJWtra8nExETKly+ftGjRIkPLzVSIkq4B+brMkUqlYsqUKfTr1y+dFX0jPDycsLAw9d/Hjh2jfPnyFClShDNnzgBw6tQpSpUqlZ4yNShatCiXL18mIiICSZI4efIk5cqV49WrVwBIksTevXs1WuHTm68x8OLFC3bv3k2XLl0ydFx8xdPTk1mzZrF//35y5vw2r/C5c+d49uwZz549Y+jQoYwZM4aBAwemo9KMT6aY2rFz5854eXkRGhqKpaUlkydPJn/+/AwaNIiQkBCaNWtG5cqVOXr0aHpLVZOY5k+fPrFkyRIA2rRpQ8+ePdNZ5TeCgoJo3bo1ENs41aVLF1xcXMidOzdDhgwhJiaG7NmzZ6iJTmrWrEm7du2oWrUqcrmcKlWq4ObmRpMmTQgJCUGSJCpXrszy5cvTW6qatm3b8ubNG7JkycKSJUswNTXF3d09Q8VFYrE7ffp0IiMjadSoERDbmJaR/JqZECPSBAKBwICI6gWBQCAwICLpCgQCgQERSVcgEAgMiEi6AoFAYEBE0hUIBAIDIpKuQCAQGBCRdAUCgcCAiKQrEAgEBuT/AJJy5GbYnjYiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.heatmap(MIs, annot=True, cmap='Blues')\n",
    "ax.yaxis.set_ticklabels(stellar_params)\n",
    "ax.xaxis.set_ticklabels(significant_dimensions)\n",
    "plt.gcf().set_facecolor('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35549e",
   "metadata": {},
   "source": [
    "### Now use our approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e4e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Input data contains invalid values (NaNs or infs), which were automatically clipped. [astropy.stats.sigma_clipping]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.520901841256569\n",
      "2 2.8222630985907355\n",
      "3 2.898247537658243\n",
      "4 2.9574070448665886\n",
      "5 2.9853569430280835\n",
      "6 3.0035054712677263\n",
      "7 3.0061952712773015\n",
      "8 3.009863829024806\n",
      "9 3.011170288181948\n",
      "10 3.013167661083923\n",
      "11 3.0135151025868563\n",
      "12 3.0169733033494412\n",
      "13 3.020761046864372\n",
      "14 3.0265998531905645\n",
      "Convergence reached at 14 components\n",
      "Total time to run the procedure: 429.43 s\n",
      "\n",
      "2 0 0.21545036394486192 0.01108717913522946\n",
      "\n",
      "1 2.779370543114035\n",
      "2 3.072632087045433\n",
      "3 3.2159475354550318\n",
      "4 3.2347049230548044\n",
      "5 3.254234007878999\n",
      "6 3.2812776536114967\n",
      "7 3.29018719471344\n",
      "8 3.295669394629392\n",
      "9 3.296795001755592\n",
      "10 3.3004103302445276\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 263.65 s\n",
      "\n",
      "2 1 0.16274478405580492 0.010948970001071973\n",
      "\n",
      "1 3.0094492109162356\n",
      "2 3.262698194676261\n",
      "3 3.3058490889140675\n",
      "4 3.333205976119237\n",
      "5 3.3544119325762263\n",
      "Convergence reached at 5 components\n",
      "Total time to run the procedure: 76.75 s\n",
      "\n",
      "2 2 0.10596539767142504 0.007045482748802046\n",
      "\n",
      "1 2.8991305673773895\n",
      "2 3.2004056483358596\n",
      "3 3.2375205159086153\n",
      "4 3.288412689220042\n",
      "5 3.3090548724115725\n",
      "6 3.311240013600201\n",
      "7 3.3224267382046926\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 136.34 s\n",
      "\n",
      "2 3 0.19330936552014244 0.010909693354400134\n",
      "\n",
      "1 3.207128465451716\n",
      "2 3.5338007822882425\n",
      "3 3.6009503760040373\n",
      "4 3.646954487643838\n",
      "5 3.6563034216832264\n",
      "6 3.662262081127808\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 98.87 s\n",
      "\n",
      "2 4 0.17782551505848396 0.012134186507631308\n",
      "\n",
      "1 2.5881006723692637\n",
      "2 2.873710966458327\n",
      "3 2.9216463573216154\n",
      "4 2.954015460609084\n",
      "5 2.9686942328563917\n",
      "6 2.973170099298723\n",
      "7 2.984454467765097\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 117.01 s\n",
      "\n",
      "2 5 0.15729452769604024 0.010119427969883374\n",
      "\n",
      "1 2.858589725614318\n",
      "2 3.1913178783640483\n",
      "3 3.2555188825238504\n",
      "4 3.275029961096442\n",
      "5 3.2934366437908538\n",
      "6 3.2979466228639214\n",
      "7 3.3006003940017385\n",
      "8 3.301033506465546\n",
      "9 3.30262943168456\n",
      "10 3.311449108577758\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 247.44 s\n",
      "\n",
      "2 6 0.21862550854569487 0.0102580584662924\n",
      "\n",
      "1 2.3655832448582266\n",
      "2 2.680248910970397\n",
      "3 2.7569446402473763\n",
      "4 2.8030539775428047\n",
      "5 2.8367289427795654\n",
      "6 2.8489043256698565\n",
      "7 2.8619666409846958\n",
      "8 2.8636076225721148\n",
      "9 2.8675092362467196\n",
      "10 2.871554388489543\n",
      "11 2.8731093980023807\n",
      "12 2.8773480165722702\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 288.49 s\n",
      "\n",
      "2 7 0.25126378516946957 0.013385156292535184\n",
      "\n",
      "1 2.915377190707691\n",
      "2 3.2104036971449292\n",
      "3 3.2544043483130793\n",
      "4 3.301746848046935\n",
      "5 3.3087101458549575\n",
      "6 3.323087999737478\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 106.17 s\n",
      "\n",
      "2 8 0.12735938567129632 0.010057961801906433\n",
      "\n",
      "1 2.320802325514\n",
      "2 2.622699925314465\n",
      "3 2.695189898493797\n",
      "4 2.7397782304687612\n",
      "5 2.7503453822701025\n",
      "6 2.759171853427965\n",
      "7 2.768054874475934\n",
      "8 2.7711446612669572\n",
      "9 2.7744284381099025\n",
      "10 2.77957028206912\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 212.58 s\n",
      "\n",
      "2 9 0.25367349925335 0.009848895679573061\n",
      "\n",
      "1 2.6111522876809747\n",
      "2 2.910792501715811\n",
      "3 2.9581156425790023\n",
      "4 3.006807513516639\n",
      "5 3.0230800206511597\n",
      "6 3.042070356194063\n",
      "7 3.054388707771094\n",
      "8 3.0607517823738895\n",
      "9 3.0660999341953317\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 182.54 s\n",
      "\n",
      "2 10 0.12859735639696415 0.008089170367114719\n",
      "\n",
      "1 -1.9210010157198907\n",
      "2 -1.6751479591901488\n",
      "3 -1.5973110732092024\n",
      "4 -1.5373612123969755\n",
      "5 -1.5178208170209715\n",
      "6 -1.5044813427586137\n",
      "7 -1.5000136665100492\n",
      "8 -1.4866851744436431\n",
      "9 -1.4835273893558292\n",
      "10 -1.471447319238231\n",
      "11 -1.4670553524803365\n",
      "12 -1.459988348009091\n",
      "13 -1.4410705040804768\n",
      "Convergence reached at 13 components\n",
      "Total time to run the procedure: 385.06 s\n",
      "\n",
      "2 11 0.1910707030989764 0.012324582743855438\n",
      "\n",
      "1 2.412860827407999\n",
      "2 2.721618459756639\n",
      "3 2.801919805586429\n",
      "4 2.8602219749426614\n",
      "5 2.894277114636221\n",
      "6 2.9019732350020297\n",
      "7 2.909486808390794\n",
      "8 2.910414093308342\n",
      "9 2.9212207658288425\n",
      "10 2.923987142994957\n",
      "11 2.9307275794630203\n",
      "12 2.93172679104627\n",
      "13 2.932755547113397\n",
      "14 2.933101162500128\n",
      "Convergence reached at 14 components\n",
      "Total time to run the procedure: 401.72 s\n",
      "\n",
      "2 12 0.25094256303999873 0.01084183644534748\n",
      "\n",
      "1 2.5193215808746707\n",
      "2 2.8071026305334392\n",
      "3 2.8448103506484563\n",
      "4 2.8893024866788397\n",
      "5 2.8963875225571307\n",
      "6 2.900662542950384\n",
      "7 2.9118003207203955\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 119.81 s\n",
      "\n",
      "2 13 0.16182191671367302 0.009261370989224594\n",
      "\n",
      "1 2.6616318537129433\n",
      "2 2.874988660211551\n",
      "3 2.9358244955648103\n",
      "4 2.9745894760474916\n",
      "5 2.99570735841924\n",
      "6 3.005377065569777\n",
      "7 3.0194371599298626\n",
      "8 3.0234753560247505\n",
      "9 3.0294385256852014\n",
      "10 3.0301829117241184\n",
      "11 3.0330901141307813\n",
      "12 3.0362715973796797\n",
      "13 3.0379452297374048\n",
      "Convergence reached at 13 components\n",
      "Total time to run the procedure: 389.89 s\n",
      "\n",
      "2 14 0.1498572216986834 0.009816866839152949\n",
      "\n",
      "1 2.7905127804449177\n",
      "2 3.0393529531003356\n",
      "3 3.1847216660980617\n",
      "4 3.2478000678068724\n",
      "5 3.262790811501119\n",
      "6 3.2676642643796896\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 93.28 s\n",
      "\n",
      "2 15 0.23416606314266822 0.010505857246894722\n",
      "\n",
      "1 2.420221072789881\n",
      "2 2.730522273062375\n",
      "3 2.8796613121355548\n",
      "4 2.9139491715039054\n",
      "5 2.9451563274442\n",
      "6 2.9591286465280526\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 68.42 s\n",
      "\n",
      "2 16 0.23048587390479672 0.01252305401672121\n",
      "\n",
      "1 2.8978998193264616\n",
      "2 3.184462861926825\n",
      "3 3.325626434189139\n",
      "4 3.358206041355723\n",
      "5 3.383358003526457\n",
      "6 3.3968528484038316\n",
      "7 3.4125188501453976\n",
      "8 3.4236992835387654\n",
      "9 3.4316166999573823\n",
      "10 3.4346580601177834\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 190.47 s\n",
      "\n",
      "2 17 0.3023461902757793 0.014249927984543092\n",
      "\n",
      "1 2.9242285390579905\n",
      "2 3.2150189797963264\n",
      "3 3.34067797016108\n",
      "4 3.358497632862577\n",
      "5 3.377167448720325\n",
      "6 3.3914983429411976\n",
      "7 3.394459332840166\n",
      "8 3.395687492884235\n",
      "9 3.404479404216453\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 205.19 s\n",
      "\n",
      "2 18 0.2691935280570564 0.014089981665257425\n",
      "\n",
      "1 -1.0383256201543265\n",
      "2 -0.17730803918540103\n",
      "3 0.1006042110034024\n",
      "4 0.14411228493100006\n",
      "5 0.20473368790496083\n",
      "6 0.23519679883419073\n",
      "7 0.242099073965068\n",
      "8 0.2421698862772456\n",
      "9 0.26187099451887336\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 119.55 s\n",
      "\n",
      "2 19 0.7121446875946773 0.016258431222956227\n",
      "\n",
      "1 2.565825316049163\n",
      "2 2.908804743406149\n",
      "3 3.00378259698015\n",
      "4 3.038013189488577\n",
      "5 3.061563986071814\n",
      "6 3.0807135397282495\n",
      "7 3.0876861548929746\n",
      "8 3.093034144386231\n",
      "9 3.0954442533967086\n",
      "10 3.10421862620745\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 191.86 s\n",
      "\n",
      "2 20 0.2452775807768656 0.01260155944220038\n",
      "\n",
      "1 2.4661378399229847\n",
      "2 2.7192106712694737\n",
      "3 2.7705038480773685\n",
      "4 2.8368876106650993\n",
      "5 2.8600658801158523\n",
      "6 2.864398801709598\n",
      "7 2.8691443845620093\n",
      "8 2.873137571588922\n",
      "9 2.876334676493904\n",
      "10 2.87933894891018\n",
      "11 2.880214638857646\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 319.10 s\n",
      "\n",
      "2 21 0.20198079446392103 0.010809267212485698\n",
      "\n",
      "1 2.7717886724458864\n",
      "2 3.002322031083492\n",
      "3 3.087583873360716\n",
      "4 3.1371263774018945\n",
      "5 3.157293926138305\n",
      "6 3.165882959787043\n",
      "7 3.1760181664113367\n",
      "8 3.178174829629281\n",
      "9 3.180998354492102\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 215.69 s\n",
      "\n",
      "2 22 0.1995639562663042 0.011089383820455363\n",
      "\n",
      "1 2.7236191619166665\n",
      "2 2.9391505529882895\n",
      "3 2.9757020750949525\n",
      "4 3.019176225162742\n",
      "5 3.033459253152922\n",
      "6 3.0389253197884543\n",
      "7 3.045796264634564\n",
      "8 3.0538696690570006\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 150.64 s\n",
      "\n",
      "2 23 0.09302229393219014 0.008696720725302757\n",
      "\n",
      "1 2.552019005586681\n",
      "2 2.840251321808356\n",
      "3 2.920537927416635\n",
      "4 2.9492870747085544\n",
      "5 2.9789279965431086\n",
      "6 2.9839730950317187\n",
      "7 2.9917594357509514\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 112.88 s\n",
      "\n",
      "2 24 0.15272362145007523 0.010626197097983616\n",
      "\n",
      "1 2.6018671110633274\n",
      "2 2.9178016435572025\n",
      "3 2.9866308786702565\n",
      "4 3.020761512697509\n",
      "5 3.0472913532789363\n",
      "6 3.0722521518404666\n",
      "7 3.081679876823884\n",
      "8 3.093948980484067\n",
      "9 3.100196870338253\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 199.11 s\n",
      "\n",
      "2 25 0.18472803631483664 0.00960035688339896\n",
      "\n",
      "1 2.4020355750307014\n",
      "2 2.70307284708962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2.8250373877738473\n",
      "4 2.8619373202161356\n",
      "5 2.869342672244238\n",
      "6 2.8833813674635693\n",
      "7 2.8975878499501557\n",
      "8 2.9108350415311492\n",
      "9 2.9153068357603473\n",
      "10 2.9216527292465826\n",
      "11 2.93245275921834\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 245.37 s\n",
      "\n",
      "2 26 0.2804498554960532 0.01381854855216966\n",
      "\n",
      "1 2.6432719365155926\n",
      "2 2.9689449212141343\n",
      "3 3.0254853267361628\n",
      "4 3.050797618652594\n",
      "5 3.072478673136929\n",
      "6 3.0813732415466357\n",
      "7 3.089291218953306\n",
      "8 3.0899786202411277\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 142.89 s\n",
      "\n",
      "2 27 0.30357704364250515 0.011902532514455519\n",
      "\n",
      "1 2.813131369464178\n",
      "2 3.089187573848976\n",
      "3 3.188565210378249\n",
      "4 3.211580725145282\n",
      "5 3.241487631349236\n",
      "6 3.253296424435643\n",
      "7 3.2548545039981236\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 110.80 s\n",
      "\n",
      "2 28 0.14431869916196796 0.009713948490994566\n",
      "\n",
      "1 2.9842626600419297\n",
      "2 3.1886162720306497\n",
      "3 3.2873456161763195\n",
      "4 3.315514582593927\n",
      "5 3.3364091230261494\n",
      "6 3.3408949361374947\n",
      "7 3.3501239269878123\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 119.54 s\n",
      "\n",
      "2 29 0.10587914373225361 0.010246771480338077\n",
      "\n",
      "1 2.5147564476807895\n",
      "2 2.7576588748714825\n",
      "3 2.8079915451769764\n",
      "4 2.8288099242591778\n",
      "5 2.851399092997354\n",
      "6 2.8670022335378085\n",
      "7 2.87141754486154\n",
      "8 2.872446359155912\n",
      "9 2.881543729947911\n",
      "10 2.883143175176676\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 262.41 s\n",
      "\n",
      "2 30 0.11124812183771354 0.009890197620610086\n",
      "\n",
      "1 2.8432043768380866\n",
      "2 3.063804813529901\n",
      "3 3.121422049890219\n",
      "4 3.1433986867329016\n",
      "5 3.1479598307192513\n",
      "6 3.1528423888814516\n",
      "7 3.156889645967837\n",
      "8 3.15866549741027\n",
      "9 3.16160650898031\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 181.78 s\n",
      "\n",
      "2 31 0.1086246994125224 0.008973508082296393\n",
      "\n",
      "1 2.962316663533666\n",
      "2 3.2424023039969074\n",
      "3 3.2627915678518833\n",
      "4 3.303952084390834\n",
      "5 3.3191683360180604\n",
      "6 3.339660224760286\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 110.91 s\n",
      "\n",
      "2 32 0.14527036730833592 0.010017671250978043\n",
      "\n",
      "1 2.6033825934758887\n",
      "2 2.882187818839737\n",
      "3 2.938763460694691\n",
      "4 2.967349685114741\n",
      "5 2.9900282052043443\n",
      "6 3.00788930409658\n",
      "7 3.012130875080539\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 148.13 s\n",
      "\n",
      "2 33 0.14611471996271735 0.010993480978740738\n",
      "\n",
      "1 2.7939414996031053\n",
      "2 3.1027752091591547\n",
      "3 3.158220458932117\n",
      "4 3.1838999522375473\n",
      "5 3.20002652248111\n",
      "6 3.2203086238070053\n",
      "7 3.2248911975519685\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 130.49 s\n",
      "\n",
      "2 34 0.19601999103742695 0.01179042338234413\n",
      "\n",
      "1 2.9165144325265735\n",
      "2 3.1651311419134647\n",
      "3 3.2380329526821527\n",
      "4 3.2700452735163608\n",
      "5 3.283931893881593\n",
      "6 3.310031805798545\n",
      "7 3.320009247978702\n",
      "8 3.3213686847183284\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 153.91 s\n",
      "\n",
      "2 35 0.15277801956724382 0.009400537364158523\n",
      "\n",
      "1 2.6230273094148395\n",
      "2 2.899121264576918\n",
      "3 2.9888667318122377\n",
      "4 3.029230601339513\n",
      "5 3.0687996923387364\n",
      "6 3.0984196377958155\n",
      "7 3.1109135217586754\n",
      "8 3.1145249215292528\n",
      "9 3.11818767048514\n",
      "10 3.1190211190290817\n",
      "11 3.119655663764337\n",
      "12 3.121301289866587\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 360.76 s\n",
      "\n",
      "2 36 0.09168189144345332 0.007300760833899759\n",
      "\n",
      "1 3.1151156779660583\n",
      "2 3.354147934771643\n",
      "3 3.40682831779939\n",
      "4 3.450430601584447\n",
      "5 3.4597816520226843\n",
      "6 3.4741481940958234\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 104.22 s\n",
      "\n",
      "2 37 0.10294450186064111 0.011902727546697396\n",
      "\n",
      "1 2.7662623382420595\n",
      "2 3.028195884368877\n",
      "3 3.07343893888449\n",
      "4 3.130787210382321\n",
      "5 3.150104041981764\n",
      "6 3.154377566310282\n",
      "7 3.166530261289296\n",
      "8 3.1674871022389475\n",
      "9 3.1752746506981837\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 187.26 s\n",
      "\n",
      "2 38 0.14788888603151218 0.009079648363548416\n",
      "\n",
      "1 2.6917292658380543\n",
      "2 2.962447020546565\n",
      "3 3.0317939415903727\n",
      "4 3.07083441414968\n",
      "5 3.115045393721683\n",
      "6 3.1229628164579757\n",
      "7 3.1355182243172197\n",
      "8 3.1427798374996265\n",
      "9 3.1457362992122984\n",
      "10 3.146808127705301\n",
      "11 3.1528919493554746\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 299.06 s\n",
      "\n",
      "2 39 0.17624220179120148 0.011059008274465766\n",
      "\n",
      "1 2.8893876121595596\n",
      "2 3.1137296380890302\n",
      "3 3.1651280590452413\n",
      "4 3.1995683736620264\n",
      "5 3.2268848343457406\n",
      "6 3.230951253579376\n",
      "7 3.247194793764395\n",
      "8 3.2521209587223048\n",
      "9 3.2590257528986406\n",
      "10 3.259605199785382\n",
      "11 3.2609623421254095\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 289.77 s\n",
      "\n",
      "2 40 0.28231006184353796 0.011190538989182854\n",
      "\n",
      "1 2.9782768980629992\n",
      "2 3.2191873175806704\n",
      "3 3.288569322242061\n",
      "4 3.3347165762317883\n",
      "5 3.364971824696297\n",
      "6 3.372877364384267\n",
      "7 3.3776210390022547\n",
      "8 3.3844137874806237\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 163.84 s\n",
      "\n",
      "2 41 0.10615519322164355 0.007512908724479755\n",
      "\n",
      "1 2.828186677156633\n",
      "2 3.1146988132616156\n",
      "3 3.1629438957393177\n",
      "4 3.222184545525463\n",
      "5 3.23767127664583\n",
      "6 3.24612564819545\n",
      "7 3.2601960155692686\n",
      "8 3.262274564026392\n",
      "9 3.269794205980574\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 165.27 s\n",
      "\n",
      "2 42 0.19517706896006776 0.011175956973011577\n",
      "\n",
      "1 2.682367014781685\n",
      "2 2.9445834029288793\n",
      "3 3.008147963314672\n",
      "4 3.053420563550189\n",
      "5 3.0695344571917444\n",
      "Convergence reached at 5 components\n",
      "Total time to run the procedure: 71.39 s\n",
      "\n",
      "2 43 0.22317237549489868 0.011086785617981631\n",
      "\n",
      "1 2.7423517296772837\n",
      "2 3.0463385756122228\n",
      "3 3.118926059743479\n",
      "4 3.143209834457924\n",
      "5 3.1868327861991386\n",
      "6 3.187350841945974\n",
      "7 3.1951850239474218\n",
      "8 3.1956449742615667\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 155.85 s\n",
      "\n",
      "2 44 0.1619177150118505 0.009210283096565778\n",
      "\n",
      "1 2.8682537177935594\n",
      "2 3.1057072872312355\n",
      "3 3.238323586681201\n",
      "4 3.2533074251422462\n",
      "5 3.2890144340801357\n",
      "6 3.3054086506392246\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 104.05 s\n",
      "\n",
      "2 45 0.12252376808070792 0.009417068292964797\n",
      "\n",
      "1 2.660306111302678\n",
      "2 2.957315965317887\n",
      "3 3.018715347431025\n",
      "4 3.042421973884301\n",
      "5 3.052239658252741\n",
      "6 3.055338618998883\n",
      "7 3.0589336164697554\n",
      "8 3.0605056078234156\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 166.84 s\n",
      "\n",
      "2 46 0.19900462045860784 0.010427205458496217\n",
      "\n",
      "1 2.2794211927274577\n",
      "2 2.5805094652153033\n",
      "3 2.6654830578217097\n",
      "4 2.7066907150972335\n",
      "5 2.7267215961490443\n",
      "6 2.7367478205320466\n",
      "7 2.749959579395842\n",
      "8 2.7591081944389835\n",
      "9 2.760925894827153\n",
      "10 2.766420081468215\n",
      "11 2.770324763262426\n",
      "12 2.771738814233908\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 294.78 s\n",
      "\n",
      "2 47 0.3225414594212625 0.012163055632616068\n",
      "\n",
      "1 2.6572430261557183\n",
      "2 3.056341875880536\n",
      "3 3.1326615940546394\n",
      "4 3.20358082556494\n",
      "5 3.22629387056756\n",
      "6 3.2483906997898533\n",
      "7 3.2598485671062907\n",
      "8 3.2696918739983154\n",
      "9 3.2780969746941238\n",
      "10 3.280823999830762\n",
      "11 3.293114023005341\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 242.75 s\n",
      "\n",
      "2 48 0.3732841947057792 0.011909019983980319\n",
      "\n",
      "1 2.6908339011980584\n",
      "2 2.9323023168590985\n",
      "3 3.01281958776096\n",
      "4 3.025116812377045\n",
      "5 3.0412255945076274\n",
      "6 3.044914466673882\n",
      "7 3.0490712884575353\n",
      "8 3.056392154910105\n",
      "9 3.0629838759743997\n",
      "10 3.06743586597189\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 287.56 s\n",
      "\n",
      "2 49 0.15083824428958895 0.01144513955571689\n",
      "\n",
      "1 2.4654264913818085\n",
      "2 2.8337082125651807\n",
      "3 3.0011547091585045\n",
      "4 3.0429715082904623\n",
      "5 3.0866484394757374\n",
      "6 3.091063686277408\n",
      "7 3.0995985104648525\n",
      "8 3.1123323169810013\n",
      "9 3.12794867729386\n",
      "10 3.137063138793124\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 212.32 s\n",
      "\n",
      "2 50 0.3169535407987691 0.014180142487941635\n",
      "\n",
      "1 2.9990487134849864\n",
      "2 3.220109806400536\n",
      "3 3.2698014544082596\n",
      "4 3.284234689935348\n",
      "5 3.289115798956397\n",
      "6 3.2993492706869745\n",
      "7 3.310266825875354\n",
      "8 3.3183769955482885\n",
      "9 3.318821144425824\n",
      "10 3.320519619865991\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 252.90 s\n",
      "\n",
      "2 51 0.108868179144814 0.007722750918201608\n",
      "\n",
      "1 2.452994534197906\n",
      "2 2.779057205516009\n",
      "3 2.839861614116931\n",
      "4 2.8825856040068767\n",
      "5 2.888546812364652\n",
      "6 2.896176314923236\n",
      "7 2.904709122194026\n",
      "8 2.9077374888547047\n",
      "9 2.908673608438333\n",
      "10 2.916528066189995\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 218.17 s\n",
      "\n",
      "2 52 0.24989069112269535 0.012260434365558714\n",
      "\n",
      "1 2.6713408692678855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2.9217064292015156\n",
      "3 2.9826180591886153\n",
      "4 3.052982001866249\n",
      "5 3.072651684365818\n",
      "6 3.0925645124315317\n",
      "7 3.0978844607492406\n",
      "8 3.107037121249989\n",
      "9 3.111094854904349\n",
      "10 3.1127633780635544\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 240.53 s\n",
      "\n",
      "2 53 0.13522601687566815 0.009690233301036879\n",
      "\n",
      "1 2.7280355656210715\n",
      "2 3.078292272261496\n",
      "3 3.1289338775375697\n",
      "4 3.1605959278986226\n",
      "5 3.1753633225845856\n",
      "6 3.178460309715383\n",
      "7 3.1784799489313236\n",
      "8 3.1844101530785807\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 144.65 s\n",
      "\n",
      "2 54 0.24521337786338399 0.011660787899724015\n",
      "\n",
      "1 2.4533005012595166\n",
      "2 2.6916573914036603\n",
      "3 2.7473201330463417\n",
      "4 2.7955786748154208\n",
      "5 2.8057471404500625\n",
      "6 2.8157453218167015\n",
      "7 2.8309481323870123\n",
      "8 2.8349985528265074\n",
      "9 2.840349553463812\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 190.20 s\n",
      "\n",
      "2 55 0.09150281903175936 0.008172221982505272\n",
      "\n",
      "1 2.2142081424477786\n",
      "2 2.594165548909826\n",
      "3 2.701824564544882\n",
      "4 2.7345500310197175\n",
      "5 2.753860089204576\n",
      "6 2.7698841522921476\n",
      "7 2.7884504114642668\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 102.81 s\n",
      "\n",
      "2 56 0.3414391023674439 0.015055528169651645\n",
      "\n",
      "1 2.525189152263607\n",
      "2 2.8562518076924905\n",
      "3 2.9571361268324217\n",
      "4 2.981137740137793\n",
      "5 3.0357300604834414\n",
      "6 3.0459431627157536\n",
      "7 3.0662758112263244\n",
      "8 3.068614601672335\n",
      "9 3.074112442540722\n",
      "10 3.086628730944804\n",
      "11 3.089580360135164\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 240.82 s\n",
      "\n",
      "2 57 0.3180759632621161 0.013476139798569523\n",
      "\n",
      "1 -0.7035595931322339\n",
      "2 0.48473097378656327\n",
      "3 0.859627392089986\n",
      "4 0.9115782599194034\n",
      "5 0.927944840632458\n",
      "6 0.9387522583726214\n",
      "7 0.9470831226469422\n",
      "8 0.9501307419802424\n",
      "9 0.95339178073371\n",
      "10 0.9569376147073868\n",
      "11 0.9584779458696472\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 223.30 s\n",
      "\n",
      "2 58 0.36120186071560995 0.0139262165121232\n",
      "\n",
      "1 2.3054845358896467\n",
      "2 2.6637911919991426\n",
      "3 2.80418753029538\n",
      "4 2.8306499913510987\n",
      "5 2.8417027136534094\n",
      "6 2.850730142231361\n",
      "7 2.8586276908632784\n",
      "8 2.8699532706200084\n",
      "9 2.8713439998954793\n",
      "10 2.8765973007964267\n",
      "11 2.8846884209978545\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 262.25 s\n",
      "\n",
      "2 59 0.2994698822523466 0.013437589612971463\n",
      "\n",
      "1 2.414550706129551\n",
      "2 2.7323469788904156\n",
      "3 2.8377804213307534\n",
      "4 2.8558124668728766\n",
      "5 2.872812884275822\n",
      "Convergence reached at 5 components\n",
      "Total time to run the procedure: 67.99 s\n",
      "\n",
      "2 60 0.2142729004511956 0.012357371191218113\n",
      "\n",
      "1 2.9774009885857073\n",
      "2 3.1944593396359338\n",
      "3 3.2367697600497958\n",
      "4 3.273971760827548\n",
      "5 3.284922373065303\n",
      "6 3.2934409267725946\n",
      "7 3.3012775334737507\n",
      "8 3.3058511714300542\n",
      "9 3.30645563673045\n",
      "10 3.31831825622241\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 301.12 s\n",
      "\n",
      "2 61 0.11301177464684063 0.010037199777829492\n",
      "\n",
      "1 2.8100934512685996\n",
      "2 3.097321321274556\n",
      "3 3.215442377896762\n",
      "4 3.242775228680474\n",
      "5 3.2487222484943477\n",
      "6 3.256287335311713\n",
      "7 3.2598565232997867\n",
      "8 3.2622371806148904\n",
      "9 3.263476492556427\n",
      "10 3.2663920777580597\n",
      "11 3.2712447229377024\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 273.24 s\n",
      "\n",
      "2 62 0.24404125532285345 0.0119302051504208\n",
      "\n",
      "1 2.530475828367145\n",
      "2 2.7809987253567616\n",
      "3 2.8635903298912773\n",
      "4 2.8876637985168894\n",
      "5 2.91085847635073\n",
      "6 2.917941175544875\n",
      "7 2.926692336389852\n",
      "8 2.9295273683375194\n",
      "9 2.9399684903640733\n",
      "10 2.9541326259711718\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 241.06 s\n",
      "\n",
      "2 63 0.11467503277191961 0.011507970043708132\n",
      "\n",
      "1 3.117867860425777\n",
      "2 3.3353893503883363\n",
      "3 3.3664482302500773\n",
      "4 3.384125479324202\n",
      "5 3.4071620676406895\n",
      "6 3.4205497814449743\n",
      "7 3.423947280221506\n",
      "8 3.4306631439226436\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 163.73 s\n",
      "\n",
      "2 64 0.08046354026113127 0.007918954753309483\n",
      "\n",
      "1 2.5321810868997336\n",
      "2 2.823215113581634\n",
      "3 2.892237554019444\n",
      "4 2.9382350618900848\n",
      "5 2.9583033876082268\n",
      "6 3.0213700095826312\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 77.18 s\n",
      "\n",
      "2 65 0.16833624325302643 0.011754390675047315\n",
      "\n",
      "1 2.636138270422999\n",
      "2 2.9475302040874443\n",
      "3 2.9973204611471282\n",
      "4 3.025897026917727\n",
      "5 3.040197109126515\n",
      "6 3.058431706996918\n",
      "7 3.0626839877959404\n",
      "8 3.0715164457635384\n",
      "9 3.0719784940562085\n",
      "10 3.079225193291613\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 245.04 s\n",
      "\n",
      "2 66 0.21431276285437445 0.011294341235459353\n",
      "\n",
      "1 2.3656432599443034\n",
      "2 2.7274250472541044\n",
      "3 2.8858263035216942\n",
      "4 2.911603119990152\n",
      "5 2.934660868437671\n",
      "6 2.952033833845072\n",
      "7 2.961225714978918\n",
      "8 2.970957459909394\n",
      "9 2.978448741815931\n",
      "10 2.980152963353586\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 203.64 s\n",
      "\n",
      "2 67 0.3854986655514424 0.01448758679482499\n",
      "\n",
      "1 2.6715012615684657\n",
      "2 2.9172546949299316\n",
      "3 2.967033016930159\n",
      "4 3.011771889349966\n",
      "5 3.051297111974444\n",
      "6 3.0586001114175683\n",
      "7 3.0703085972907993\n",
      "8 3.075798433788343\n",
      "9 3.0810591419823816\n",
      "10 3.0887350406839524\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 232.69 s\n",
      "\n",
      "2 68 0.14068762748621938 0.01164977216160542\n",
      "\n",
      "1 2.755525657194081\n",
      "2 3.1110961496332727\n",
      "3 3.2388212906418414\n",
      "4 3.2712346817394624\n",
      "5 3.282620985789439\n",
      "6 3.30994199062677\n",
      "7 3.3134392479142107\n",
      "8 3.324125718843829\n",
      "9 3.3314541477660295\n",
      "10 3.3340556228330134\n",
      "11 3.334850152322897\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 229.24 s\n",
      "\n",
      "2 69 0.32922068994987846 0.014578792783306788\n",
      "\n",
      "1 2.6730019657053745\n",
      "2 2.9280014265066945\n",
      "3 2.950033304449438\n",
      "4 2.9943973507335766\n",
      "5 2.997580049975364\n",
      "6 2.9981820658440577\n",
      "7 2.9995572933096004\n",
      "8 3.003616489997178\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 175.82 s\n",
      "\n",
      "2 70 0.2229372664825534 0.01012075740560179\n",
      "\n",
      "1 2.7391093596981846\n",
      "2 3.0732802027862847\n",
      "3 3.1782825133693167\n",
      "4 3.1954776185624785\n",
      "5 3.207539924819219\n",
      "6 3.2127378006688283\n",
      "7 3.2138003377352753\n",
      "8 3.2243508540294723\n",
      "9 3.2310081758429945\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 182.43 s\n",
      "\n",
      "2 71 0.34015983025719754 0.01290247558233485\n",
      "\n",
      "1 2.8773485758066584\n",
      "2 3.166060695351908\n",
      "3 3.251156273542788\n",
      "4 3.267440115455224\n",
      "5 3.2909159958401553\n",
      "6 3.299505713091491\n",
      "7 3.3087240272872065\n",
      "8 3.3140243299067236\n",
      "9 3.3142758168432684\n",
      "10 3.314354316951672\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 214.24 s\n",
      "\n",
      "2 72 0.21089882216948422 0.011223509376766378\n",
      "\n",
      "1 2.5597411121220532\n",
      "2 2.904565761316562\n",
      "3 3.05103244895709\n",
      "4 3.09398460621885\n",
      "5 3.122052400064083\n",
      "6 3.132469375347132\n",
      "7 3.142016923461371\n",
      "8 3.153298637445342\n",
      "9 3.1600438550827925\n",
      "10 3.1618836401958688\n",
      "11 3.164523186048775\n",
      "12 3.1683089254134225\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 304.78 s\n",
      "\n",
      "2 73 0.3409018432855522 0.012724507228459744\n",
      "\n",
      "1 3.1262753351227865\n",
      "2 3.423767233914693\n",
      "3 3.4934546264654798\n",
      "4 3.5254002829561775\n",
      "5 3.551981235823058\n",
      "6 3.5753077073405364\n",
      "7 3.585098772335709\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 120.65 s\n",
      "\n",
      "2 74 0.24767807056243446 0.013082622222470155\n",
      "\n",
      "1 2.5665154568684927\n",
      "2 2.880683568588347\n",
      "3 2.971324114913255\n",
      "4 2.9993006784440794\n",
      "5 3.0231765844941774\n",
      "6 3.040935185710562\n",
      "7 3.0476962970688892\n",
      "8 3.0527410326149167\n",
      "9 3.0624426169401677\n",
      "10 3.0752705008500434\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 213.35 s\n",
      "\n",
      "2 75 0.2547200038688851 0.015008538358879931\n",
      "\n",
      "1 2.4428545638953185\n",
      "2 2.8047331488301963\n",
      "3 2.9061532082843513\n",
      "4 2.94590163188032\n",
      "5 2.9883193325500237\n",
      "6 3.002817504635473\n",
      "7 3.014962330785847\n",
      "8 3.018923813413158\n",
      "9 3.0260014074889625\n",
      "10 3.03127667361767\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 202.86 s\n",
      "\n",
      "2 76 0.38590125767995936 0.015052243009963884\n",
      "\n",
      "1 2.8112137151988867\n",
      "2 3.0842596007139442\n",
      "3 3.1463959689797654\n",
      "4 3.1955932583719537\n",
      "5 3.2583549069213738\n",
      "6 3.2717357248242673\n",
      "7 3.296287983562412\n",
      "8 3.3038169621748072\n",
      "9 3.3052524294796473\n",
      "10 3.3070798633751455\n",
      "11 3.310842847555037\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 248.39 s\n",
      "\n",
      "2 77 0.14933135086045793 0.007775284314461085\n",
      "\n",
      "1 2.7211063573869847\n",
      "2 3.004151902332891\n",
      "3 3.0289688824404943\n",
      "4 3.0734310955477473\n",
      "5 3.0855915094122572\n",
      "6 3.09161658896139\n",
      "7 3.0966964837860083\n",
      "8 3.1015754847608297\n",
      "9 3.104741874341954\n",
      "10 3.105787471972724\n",
      "11 3.106114494253999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 3.1087483990553584\n",
      "13 3.1108519612535397\n",
      "Convergence reached at 13 components\n",
      "Total time to run the procedure: 422.92 s\n",
      "\n",
      "2 78 0.1645716071458423 0.010966412250805017\n",
      "\n",
      "1 2.7730561998528294\n",
      "2 3.007491019278895\n",
      "3 3.0702297074809137\n",
      "4 3.132993865002909\n",
      "5 3.139774656695233\n",
      "6 3.153119821043305\n",
      "7 3.162114553916041\n",
      "8 3.1762135969267056\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 158.74 s\n",
      "\n",
      "2 79 0.1378218625559832 0.010341493585430333\n",
      "\n",
      "1 3.046751857669417\n",
      "2 3.3377642851840155\n",
      "3 3.4038299135949566\n",
      "4 3.426317079355473\n",
      "5 3.437252935326048\n",
      "6 3.4379969796413303\n",
      "7 3.4411694375505077\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 112.55 s\n",
      "\n",
      "2 80 0.15557091142438298 0.009657498445402368\n",
      "\n",
      "1 3.0542117969746596\n",
      "2 3.3164905618975737\n",
      "3 3.3706124688684436\n",
      "4 3.386005308017998\n",
      "5 3.404871674820123\n",
      "6 3.410753731610257\n",
      "7 3.429672730965366\n",
      "8 3.4338740625078703\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 171.39 s\n",
      "\n",
      "2 81 0.14738208540061182 0.00947170475063132\n",
      "\n",
      "1 2.6872903776772787\n",
      "2 2.9765251025018897\n",
      "3 3.0502073093956548\n",
      "4 3.0659477546495935\n",
      "5 3.082478389170791\n",
      "6 3.0929681865536107\n",
      "7 3.1027992221050087\n",
      "8 3.109924382610783\n",
      "9 3.112585025156377\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 184.89 s\n",
      "\n",
      "2 82 0.19039383320505399 0.01093379235509718\n",
      "\n",
      "1 2.682728687819772\n",
      "2 2.9258528369257655\n",
      "3 2.9590334803504406\n",
      "4 3.0014361684331483\n",
      "5 3.0318742685557614\n",
      "6 3.0416764868797497\n",
      "7 3.048389868329694\n",
      "8 3.053538359554386\n",
      "9 3.0537059638198905\n",
      "10 3.062229359010702\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 228.81 s\n",
      "\n",
      "2 83 0.1501848190709508 0.010090063151063127\n",
      "\n",
      "1 2.5879411034146997\n",
      "2 3.06630426313377\n",
      "3 3.260645210652978\n",
      "4 3.310985955423106\n",
      "5 3.3322570629790107\n",
      "6 3.3442055707193057\n",
      "7 3.348713021691898\n",
      "8 3.365338621433415\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 136.25 s\n",
      "\n",
      "2 84 0.4126405556160097 0.014697300531696515\n",
      "\n",
      "1 -1.3976527043589053\n",
      "2 -0.750541612460446\n",
      "3 -0.6599332846630795\n",
      "4 -0.5732712646445276\n",
      "5 -0.543454294110805\n",
      "6 -0.5105383390966715\n",
      "7 -0.5048484704269202\n",
      "8 -0.49849482760738156\n",
      "9 -0.4971014118311286\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 151.75 s\n",
      "\n",
      "2 85 1.3160916645359848 0.01970310246525324\n",
      "\n",
      "1 2.5577766652770877\n",
      "2 2.7591973345599903\n",
      "3 2.809117662196172\n",
      "4 2.845675660305648\n",
      "5 2.8618155163479084\n",
      "6 2.8692180717663835\n",
      "7 2.869462285297858\n",
      "8 2.8759693542283316\n",
      "9 2.877998878275033\n",
      "10 2.8800833836754642\n",
      "11 2.8802100878293424\n",
      "12 2.881162827430298\n",
      "13 2.881216129191755\n",
      "Convergence reached at 13 components\n",
      "Total time to run the procedure: 364.05 s\n",
      "\n",
      "2 86 0.11697419788855226 0.010499089589715556\n",
      "\n",
      "1 2.731979425455483\n",
      "2 2.9835667774519465\n",
      "3 3.039975214233131\n",
      "4 3.048274587515287\n",
      "5 3.0789422226728598\n",
      "Convergence reached at 5 components\n",
      "Total time to run the procedure: 72.13 s\n",
      "\n",
      "2 87 0.15976502768192558 0.00989694108445522\n",
      "\n",
      "1 2.6589467180229036\n",
      "2 2.968845751986795\n",
      "3 3.1550501433428217\n",
      "4 3.194161154339597\n",
      "5 3.221058565006864\n",
      "6 3.2311617920973377\n",
      "7 3.2573078193783185\n",
      "8 3.2786630002864516\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 122.48 s\n",
      "\n",
      "2 88 0.25961416961167083 0.012262464281214443\n",
      "\n",
      "1 2.5578189155399653\n",
      "2 2.8535340723193836\n",
      "3 2.9344802111208064\n",
      "4 2.949176669383886\n",
      "5 2.9866574766399894\n",
      "6 2.9998522475903635\n",
      "7 3.005335422162117\n",
      "8 3.0104501478678944\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 138.80 s\n",
      "\n",
      "2 89 0.2419645367384457 0.013098215001516885\n",
      "\n",
      "1 3.225959114357512\n",
      "2 3.4424113800760536\n",
      "3 3.4922439711267628\n",
      "4 3.5245928036604117\n",
      "5 3.5363034555868693\n",
      "6 3.545741575525536\n",
      "7 3.5493181973732404\n",
      "8 3.554424718024111\n",
      "9 3.5548804615391862\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 238.77 s\n",
      "\n",
      "2 90 0.07238841091009668 0.006870103985288845\n",
      "\n",
      "1 2.6999752934922046\n",
      "2 3.0032823670878765\n",
      "3 3.033565169094912\n",
      "4 3.061683326275754\n",
      "5 3.0790438745113953\n",
      "6 3.0867194314923623\n",
      "7 3.0951774965361274\n",
      "8 3.0956584639788853\n",
      "9 3.098613966602901\n",
      "10 3.1021884825557664\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 281.46 s\n",
      "\n",
      "2 91 0.18257651603436517 0.009650280166172583\n",
      "\n",
      "1 2.7813741579449194\n",
      "2 3.1073316287029455\n",
      "3 3.17552808604\n",
      "4 3.2051999226981582\n",
      "5 3.241275836014797\n",
      "6 3.2655414642269327\n",
      "7 3.2701880074191347\n",
      "8 3.2793270460821824\n",
      "9 3.285748070488213\n",
      "10 3.287283630738522\n",
      "11 3.2915171656955646\n",
      "12 3.2928652410460884\n",
      "13 3.3015652159864466\n",
      "Convergence reached at 13 components\n",
      "Total time to run the procedure: 348.33 s\n",
      "\n",
      "2 92 0.3250790166168237 0.014081935035189737\n",
      "\n",
      "1 2.638886058272696\n",
      "2 3.1021533998216473\n",
      "3 3.2757760034222545\n",
      "4 3.3227348466448774\n",
      "5 3.3465544892881334\n",
      "6 3.3497091004433392\n",
      "7 3.373164175264884\n",
      "8 3.373633970453955\n",
      "9 3.396948495074495\n",
      "10 3.399015022803089\n",
      "11 3.400259970331208\n",
      "12 3.4096733124678686\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 321.29 s\n",
      "\n",
      "2 93 0.44198149895423755 0.013754510784360552\n",
      "\n",
      "1 2.393079509853752\n",
      "2 2.7371328229098784\n",
      "3 2.792840236678963\n",
      "4 2.8310940159750344\n",
      "5 2.843939915363411\n",
      "6 2.8538377517823963\n",
      "7 2.858516560829893\n",
      "8 2.8616932885772095\n",
      "9 2.8646081154058876\n",
      "10 2.869931530358253\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 219.96 s\n",
      "\n",
      "2 94 0.24817655782938458 0.011917386403595458\n",
      "\n",
      "1 2.511939307774979\n",
      "2 2.8347948963626917\n",
      "3 2.976041304551193\n",
      "4 2.999979536178808\n",
      "5 3.0218544405051304\n",
      "6 3.0396802479940512\n",
      "7 3.0692526544976704\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 104.73 s\n",
      "\n",
      "2 95 0.3129469468889505 0.01672348806258665\n",
      "\n",
      "1 2.6864383006886325\n",
      "2 2.9319476189259106\n",
      "3 3.02167619671523\n",
      "4 3.070143227140125\n",
      "5 3.1189123065689297\n",
      "6 3.128376336335284\n",
      "7 3.1373124270129886\n",
      "8 3.148200608261167\n",
      "9 3.152533952562489\n",
      "10 3.1595450413946495\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 253.17 s\n",
      "\n",
      "2 96 0.11931962966839368 0.010965972105961971\n",
      "\n",
      "1 2.685159478921939\n",
      "2 2.9079635375210615\n",
      "3 2.9547308955753837\n",
      "4 2.9789330880870373\n",
      "5 2.9902558390992087\n",
      "6 3.006417482152417\n",
      "7 3.0086590873860164\n",
      "8 3.0144137339903643\n",
      "9 3.018253761725228\n",
      "10 3.0204993899805026\n",
      "11 3.0216275041881233\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 368.76 s\n",
      "\n",
      "2 97 0.12205107299220033 0.009089449385316513\n",
      "\n",
      "1 2.53806323125492\n",
      "2 2.831738825381757\n",
      "3 2.8767182365099013\n",
      "4 2.9106509398680553\n",
      "5 2.9299829844897265\n",
      "6 2.946144321337785\n",
      "7 2.9493125491934493\n",
      "8 2.9568994828126374\n",
      "9 2.961508286265474\n",
      "10 2.9676775748951556\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 250.77 s\n",
      "\n",
      "2 98 0.21709777357332294 0.00976702944737351\n",
      "\n",
      "1 -2.1461652668595503\n",
      "2 -1.9390529569256045\n",
      "3 -1.8749262322730849\n",
      "4 -1.8200925158178853\n",
      "5 -1.8024562395924537\n",
      "6 -1.7538306370098633\n",
      "7 -1.7328051087362557\n",
      "8 -1.6876661960927022\n",
      "9 -1.6831162234220434\n",
      "10 -1.671831597003819\n",
      "11 -1.6380974643478439\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 252.11 s\n",
      "\n",
      "2 99 0.15888542388259416 0.013207535203680058\n",
      "\n",
      "1 2.89951636150138\n",
      "2 3.3371654838119134\n",
      "3 3.47107221915732\n",
      "4 3.5116581148345127\n",
      "5 3.5370699801693246\n",
      "6 3.5413906146903784\n",
      "7 3.5516075016870907\n",
      "8 3.561036618275305\n",
      "9 3.562031148714086\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 167.73 s\n",
      "\n",
      "2 100 0.3591201509814387 0.010887945838779455\n",
      "\n",
      "1 2.5723076525113076\n",
      "2 2.901110751413371\n",
      "3 3.013820155768133\n",
      "4 3.030669253474358\n",
      "5 3.06199169993956\n",
      "6 3.081525052025888\n",
      "7 3.087992748532821\n",
      "8 3.0884496953311333\n",
      "9 3.0896793289823954\n",
      "10 3.1018590496724756\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 225.38 s\n",
      "\n",
      "2 101 0.2665962701082902 0.013410299261465605\n",
      "\n",
      "1 2.6032646008349385\n",
      "2 2.8439747472679717\n",
      "3 2.899554649297199\n",
      "4 2.944564868463102\n",
      "5 2.956907511760438\n",
      "6 2.960723453800583\n",
      "7 2.969959474546378\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 131.82 s\n",
      "\n",
      "2 102 0.1396625353669867 0.012670703216740188\n",
      "\n",
      "1 2.50880628283046\n",
      "2 2.782348752567554\n",
      "3 2.8417998751073834\n",
      "4 2.8675905853373505\n",
      "5 2.875229215575363\n",
      "6 2.8866690725529067\n",
      "7 2.8919869721296405\n",
      "8 2.8971336588635244\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 173.55 s\n",
      "\n",
      "2 103 0.1499820445415706 0.009077453175329087\n",
      "\n",
      "1 2.6810492799114414\n",
      "2 2.9927949526845263\n",
      "3 3.082530214228758\n",
      "4 3.133712467995808\n",
      "5 3.1428186891726013\n",
      "6 3.148145528311277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 3.163932213797866\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 116.07 s\n",
      "\n",
      "2 104 0.25406991709867355 0.012685896770536505\n",
      "\n",
      "1 2.8790652399963643\n",
      "2 3.0916428804378087\n",
      "3 3.1217411045491232\n",
      "4 3.1486707241026166\n",
      "5 3.1752979726435577\n",
      "6 3.178397912585348\n",
      "7 3.186549697529243\n",
      "8 3.191786310894709\n",
      "9 3.194808116570727\n",
      "10 3.19487489155012\n",
      "11 3.1972294701637245\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 322.17 s\n",
      "\n",
      "2 105 0.13738274203800352 0.010397435665309011\n",
      "\n",
      "1 2.561089769357396\n",
      "2 2.8056262924348325\n",
      "3 2.846565465468465\n",
      "4 2.882453657482954\n",
      "5 2.892390239772883\n",
      "6 2.8953686411243074\n",
      "7 2.89767439755999\n",
      "8 2.9028586083979295\n",
      "9 2.907963967720159\n",
      "10 2.9090105879768284\n",
      "11 2.9132686505863092\n",
      "12 2.9176323119860306\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 435.30 s\n",
      "\n",
      "2 106 0.1339393559895503 0.010743992614569972\n",
      "\n",
      "1 2.5641220687442337\n",
      "2 2.810375615085134\n",
      "3 2.901264299427801\n",
      "4 2.938934635022033\n",
      "5 2.960994706610498\n",
      "6 2.976133378167648\n",
      "7 2.9790552509239236\n",
      "8 2.9861287592149597\n",
      "Convergence reached at 8 components\n",
      "Total time to run the procedure: 160.85 s\n",
      "\n",
      "2 107 0.11043074593293627 0.009031485308303572\n",
      "\n",
      "1 2.5937118673855752\n",
      "2 2.880353633640104\n",
      "3 2.913852779808584\n",
      "4 2.949051788873105\n",
      "5 2.9660171743565495\n",
      "6 2.9742204689313425\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 119.59 s\n",
      "\n",
      "2 108 0.18426681067367967 0.009817778139126121\n",
      "\n",
      "1 2.851830469958147\n",
      "2 3.092981679656674\n",
      "3 3.13410972452181\n",
      "4 3.135750329572088\n",
      "5 3.14483934330489\n",
      "6 3.152530027811896\n",
      "7 3.155127310639376\n",
      "8 3.156992545455768\n",
      "9 3.1605169993909517\n",
      "10 3.1627692386358155\n",
      "11 3.1654998025631973\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 352.89 s\n",
      "\n",
      "2 109 0.09638277723328251 0.007847358552062266\n",
      "\n",
      "1 2.5149171726738846\n",
      "2 2.8083060173527374\n",
      "3 2.8888888824862033\n",
      "4 2.9139175577994965\n",
      "5 2.9214192520893625\n",
      "6 2.927844825891237\n",
      "7 2.9328262536571335\n",
      "8 2.9388343870284754\n",
      "9 2.9430831813449934\n",
      "10 2.9434349708566394\n",
      "11 2.94535767022996\n",
      "12 2.9453594114903434\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 317.79 s\n",
      "\n",
      "2 110 0.32283622196010703 0.011937212751872666\n",
      "\n",
      "1 2.514405579722507\n",
      "2 2.903840317266351\n",
      "3 2.9746303479076204\n",
      "4 3.0294681348124115\n",
      "5 3.0472599272088794\n",
      "6 3.064645667342598\n",
      "Convergence reached at 6 components\n",
      "Total time to run the procedure: 95.57 s\n",
      "\n",
      "2 111 0.2703765929064415 0.015553723567527522\n",
      "\n",
      "1 2.6770991352235107\n",
      "2 2.980790805174633\n",
      "3 3.087283210537459\n",
      "4 3.149340469526394\n",
      "5 3.1755373165449825\n",
      "6 3.184081678040973\n",
      "7 3.196849751097121\n",
      "8 3.2011384485326957\n",
      "9 3.202712039470466\n",
      "10 3.2046712221971343\n",
      "11 3.2080988241567927\n",
      "12 3.212047108424971\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 298.71 s\n",
      "\n",
      "2 112 0.22025302398327742 0.011102900557801054\n",
      "\n",
      "1 2.504009103339564\n",
      "2 2.8501183629487468\n",
      "3 2.909466769534834\n",
      "4 2.97430220434059\n",
      "5 3.0005528988281642\n",
      "6 3.008765832756689\n",
      "7 3.0228587483389986\n",
      "8 3.0262703439017833\n",
      "9 3.0317356681910983\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 174.17 s\n",
      "\n",
      "2 113 0.24218365643421322 0.014490571578170254\n",
      "\n",
      "1 2.7153595372937853\n",
      "2 3.0240906151461235\n",
      "3 3.057151192884806\n",
      "4 3.105272461789939\n",
      "5 3.1297013130606195\n",
      "6 3.1743296230099722\n",
      "7 3.182997322154144\n",
      "Convergence reached at 7 components\n",
      "Total time to run the procedure: 147.09 s\n",
      "\n",
      "2 114 0.11027056005683379 0.008867044907402246\n",
      "\n",
      "1 2.7462634150060996\n",
      "2 3.094652381812484\n",
      "3 3.2131751108629416\n",
      "4 3.267866741360708\n",
      "5 3.3036949589351017\n",
      "6 3.331062148478346\n",
      "7 3.3443354617708994\n",
      "8 3.3527295380848403\n",
      "9 3.362608896100521\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 181.60 s\n",
      "\n",
      "2 115 0.1796998911727417 0.011908045682061387\n",
      "\n",
      "1 3.057612990949204\n",
      "2 3.2894173708174392\n",
      "3 3.3483690827557253\n",
      "4 3.357749495237728\n",
      "5 3.412879370267074\n",
      "6 3.4286625608311847\n",
      "7 3.4330809897326304\n",
      "8 3.439908374223037\n",
      "9 3.4464496508982574\n",
      "Convergence reached at 9 components\n",
      "Total time to run the procedure: 201.46 s\n",
      "\n",
      "2 116 0.16878358772632251 0.011019494169996522\n",
      "\n",
      "1 2.384202357154963\n",
      "2 2.7195548894464623\n",
      "3 2.823688909722718\n",
      "4 2.8404400410314476\n",
      "5 2.864954438236248\n",
      "6 2.8742554279015313\n",
      "7 2.8759994501460864\n",
      "8 2.885927101284816\n",
      "9 2.8908624478714358\n",
      "10 2.9007594622557087\n",
      "11 2.9050756726856393\n",
      "12 2.907801001349263\n",
      "Convergence reached at 12 components\n",
      "Total time to run the procedure: 317.52 s\n",
      "\n",
      "2 117 0.2956045448845887 0.012312162780574232\n",
      "\n",
      "1 2.507552988257062\n",
      "2 2.7951954017045644\n",
      "3 2.8647968312117746\n",
      "4 2.893620179460028\n",
      "5 2.9248364603633834\n",
      "6 2.9307009456908304\n",
      "7 2.937660433687089\n",
      "8 2.939832026823183\n",
      "9 2.953326793344033\n",
      "10 2.9553741355147856\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 216.56 s\n",
      "\n",
      "2 118 0.19959141581972742 0.012223973242479202\n",
      "\n",
      "1 2.4401600089437907\n",
      "2 2.7208940880953008\n",
      "3 2.776669526159115\n",
      "4 2.7985466116927173\n",
      "5 2.812367477891195\n",
      "6 2.8215384539067756\n",
      "7 2.830104525177384\n",
      "8 2.830893105008897\n",
      "9 2.839117950451632\n",
      "10 2.8452218193447822\n",
      "11 2.853940192780653\n",
      "Convergence reached at 11 components\n",
      "Total time to run the procedure: 294.85 s\n",
      "\n",
      "2 119 0.1688888285537917 0.013146106743553649\n",
      "\n",
      "1 2.732271534059357\n",
      "2 3.0300124435806617\n",
      "3 3.0693177062763013\n",
      "4 3.106523123803278\n",
      "5 3.111174117619884\n",
      "6 3.159867618822405\n",
      "7 3.1619914172404138\n",
      "8 3.1638565514956736\n",
      "9 3.1696552785337446\n",
      "10 3.1701170111607837\n",
      "Convergence reached at 10 components\n",
      "Total time to run the procedure: 291.56 s\n",
      "\n",
      "2 120 0.09157777032358823 0.009995972919112707\n",
      "\n",
      "1 3.0284277276150404\n",
      "2 3.2926799487120526\n",
      "3 3.3100364255973935\n",
      "4 3.351159260105398\n",
      "5 3.363051367652225\n",
      "6 3.3710445437338543\n",
      "7 3.3740594588506294\n",
      "8 3.3778982227266154\n",
      "9 3.3807614219388054\n"
     ]
    }
   ],
   "source": [
    "n_inits = 5\n",
    "n_folds = 3\n",
    "init_type = 'random_sklearn'\n",
    "n_bootstrap = 100\n",
    "MC_samples = 1e5\n",
    "tol = 1e-5\n",
    "reg_covar = 1e-13\n",
    "components_range = 200\n",
    "        \n",
    "MI_all = np.zeros((len(stellar_params), 128, n_bootstrap))\n",
    "\n",
    "for li,stellar_param in enumerate(stellar_params):\n",
    "    if li <= 1:\n",
    "        continue\n",
    "    label = labels.loc[:,stellar_param].values\n",
    "    \n",
    "    ind_mask = ~np.isnan(label)\n",
    "    label_ = sigma_clip(label,sigma=5,masked=True)\n",
    "\n",
    "    ind_mask = ind_mask & (~label_.mask)\n",
    "    samples1 = label_.data[ind_mask]    \n",
    "\n",
    "    for latbin2 in range(128):\n",
    "        codes_ = codes.iloc[:,latbin2].values\n",
    "        samples2 = codes_[ind_mask]\n",
    "\n",
    "        X = np.stack((samples1, samples2), axis=0).T\n",
    "\n",
    "        # now we do this for many components, from 1 to 15\n",
    "\n",
    "        all_MI_estimates = np.zeros((components_range, n_bootstrap))\n",
    "\n",
    "        best_val = -np.inf\n",
    "\n",
    "        initial_time = time.time()\n",
    "        for n_components in range(1, components_range+1):\n",
    "            current_seed, current_val, _ = MI_procedure_diffconvergence(X, n_components=n_components, n_folds=n_folds, \n",
    "                                                               init_type=init_type, n_inits=n_inits, tol=tol, reg_covar=reg_covar)\n",
    "\n",
    "            # check if convergence has been reached based on val score\n",
    "            if current_val > best_val:\n",
    "                best_val = current_val\n",
    "                best_seed = current_seed\n",
    "                print(n_components, best_val)\n",
    "            else:\n",
    "                # if val score has not increased, then we should stop and calculate MI with the previous parameters\n",
    "                best_components = n_components-1\n",
    "                print(f'Convergence reached at {best_components} components') \n",
    "                w_init, m_init, c_init, p_init = initialize_parameters(X, best_seed, n_components=best_components, init_type=init_type)\n",
    "                MI_estimates = np.zeros(n_bootstrap)\n",
    "\n",
    "                # bootstrap available samples\n",
    "                for i in range(n_bootstrap):\n",
    "                    # we use i to change the seed so that the results will be fully reproducible\n",
    "                    rng = np.random.default_rng(i)\n",
    "                    X_bs = rng.choice(X, X.shape[0])\n",
    "                    gmm = my_GMM(n_components=best_components, reg_covar=reg_covar, \n",
    "                                tol=tol, max_iter=10000, \n",
    "                                random_state=best_seed, weights_init=w_init, \n",
    "                                means_init=m_init, precisions_init=p_init).fit(X_bs)\n",
    "\n",
    "                    # in case of \"warm start\", uncomment next line\n",
    "                    #w_init, m_init, c_init, p_init = gmm.weights_, gmm.means_, gmm.covariances_, gmm.precisions_\n",
    "\n",
    "                    current_MI_estimate = gmm.estimate_MI_MC(MC_samples=MC_samples)\n",
    "                    MI_estimates[i] = current_MI_estimate\n",
    "                break\n",
    "\n",
    "        print(f'Total time to run the procedure: {time.time()-initial_time:.2f} s')\n",
    "        print()\n",
    "        MI_all[li, latbin2] = MI_estimates\n",
    "        print(li, latbin2, np.mean(MI_estimates), np.std(MI_estimates))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11015804",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./MI_all_3.npy', MI_all[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "543cd8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.15535582, 0.15996983, 0.15833833, ..., 0.17448079,\n",
       "         0.15516543, 0.17735675],\n",
       "        [0.16619129, 0.16063663, 0.16554687, ..., 0.17021597,\n",
       "         0.16495773, 0.15557986],\n",
       "        [0.14061817, 0.14238371, 0.14714331, ..., 0.1543773 ,\n",
       "         0.16281572, 0.14820693],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI_all[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abbacf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
